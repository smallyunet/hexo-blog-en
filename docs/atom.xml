<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>smallyu‘s Blog</title>
  <icon>https://en.smallyu.net/favicon.png</icon>
  <subtitle>smallyu&#39;s Blog</subtitle>
  <link href="https://en.smallyu.net/atom.xml" rel="self"/>
  <link href="https://pubsubhubbub.appspot.com/" rel="hub"/>
  <link href="https://en.smallyu.net/"/>
  <updated>2025-08-09T09:05:26.061Z</updated>
  <id>https://en.smallyu.net/</id>
  
  <author>
    <name>smallyu</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Analysis of the 0G Project</title>
    <link href="https://en.smallyu.net/2025/08/06/Analysis%20of%20the%200G%20Project/"/>
    <id>https://en.smallyu.net/2025/08/06/Analysis%20of%20the%200G%20Project/</id>
    <published>2025-08-06T05:08:00.000Z</published>
    <updated>2025-08-09T09:05:26.061Z</updated>
    
    <content type="html"><![CDATA[<p>First of all, I’m not very optimistic about the technical depth of 0G, mainly because it’s a project developed by a Chinese team. 0G is in the AI sector and posted job listings on TinTinLand in March. It’s likely planning a token launch around September. My guess is that the AI aspect is more hype than substance. I’ve recently joined a study group on TinTinLand that’s collaborating with 0G on community courses, so I got slightly interested and decided to analyze the project.</p><p>The official website of 0G is <a href="https://0g.ai/">0g.ai</a>, and it tries its best to flaunt buzzwords like “the next generation,” “decentralized AI,” “DeAIOS,” and “RWA.” The more extravagant the terminology, the more suspicious it tends to be.</p><h3 id="Project-Background"><a href="#Project-Background" class="headerlink" title="Project Background"></a>Project Background</h3><p>0G released its <a href="https://4134984757-files.gitbook.io/~/files/v0/b/gitbook-x-prod.appspot.com/o/spaces%2FsEYMfeKUqxaOUwhkw6AT%2Fuploads%2Fgit-blob-6f0538c70e09bf3180519342bfc516355c7a12c0%2F0g-whitepaper.pdf?alt=media">whitepaper</a> in August 2024. Judging from the table of contents and the length, things don’t look very promising. The structure is rather simple, with only 20 pages. While page count is a superficial measure (Bitcoin’s whitepaper is only 9 pages), the overly simplistic structure gives a rough-and-ready impression for a project that’s supposed to be AI-tech-driven.</p><img src="1.png" width="50%"><p>Let’s look at the abstract. 0G aims to solve transparency issues in the AI model training process:</p><img src="2.png" width="70%"><p>Honestly, seeing the term “modular” gave me a bad feeling—especially when I saw “DA” (Data Availability). I wondered if they were using Celestia. Coupled with the claim on the homepage of 2500 TPS, what chain can even achieve that? Cosmos seems like a candidate. But at this point, it’s still unclear what the “8K validators” mentioned on the homepage means—Cosmos can’t do that.</p><img src="3.png" width="80%"><p>Thankfully, it’s not Celestia. The whitepaper doesn’t detail the tech stack but clearly positions itself alongside Celestia. They’ve built their own chain called 0G DA.</p><p>The whitepaper explains the PoRA (Proof of Random Access) mining mechanism in detail. This is where there’s actual technical depth. Unlike Filecoin’s cold storage model, 0G Storage emphasizes on-chain data that’s immediately accessible. It sets an 8TB mining window, requiring miners to quickly verify data integrity within this range.</p><p>PoRA’s limitation lies in its inability to prove the uniqueness of stored data. It verifies whether miners <em>have</em> the data but not whether it’s <em>unique</em>, unlike Filecoin’s PoRep. This aligns with 0G’s focus on data availability rather than proof of replication. Its economic model assumes that bad actors can’t profit, so the mechanism works under these assumptions. Filecoin, on the other hand, rewards based on computing power and faces different challenges.</p><p>From the project’s first <a href="https://0g.ai/blog/introduction">blog post</a>, we can see more clearly that 0G consists of two key components: 0G Storage and 0G DA. Essentially, it’s solving the DA problem and applying this capability to AI scenarios, which is why it falls into the AI category. In essence, it’s a distributed storage blockchain project.</p><p>0G raised $30 million in seed funding last year, which shows decent capital backing.</p><p>On the engineering side, the <a href="https://github.com/0glabs/0g-storage-node/blob/main/Cargo.toml#L31">0G Storage code</a> is based on Conflux node code, with additional development layered on top:</p><img src="6.png" width="70%"><p>I won’t delve too deep into the PoRA implementation.</p><h3 id="Project-Architecture"><a href="#Project-Architecture" class="headerlink" title="Project Architecture"></a>Project Architecture</h3><p>So far, we’ve discussed 0G Storage and 0G DA. In addition, the 0G project includes two other components: 0G Chain and 0G Compute Network. These weren’t mentioned in the whitepaper, possibly because they were added later.</p><p>0G Chain is a blockchain node developed using the Cosmos SDK (finally, Cosmos appears!). It uses evmos to ensure Ethereum smart contract compatibility:</p><img src="4.png" width="80%"><p>The last code commit to the 0G Chain repo was five months ago, suggesting that the Cosmos SDK route may have been abandoned. A more active repo recently is <a href="https://github.com/0glabs/0g-geth">0g-geth</a>, which appears to be a Geth fork with added support for 0G DA via precompiled contracts.</p><img src="5.png" width="40%"><p>The 0G Compute Network is the component truly related to AI model training. It currently supports the use of some <a href="https://docs.0g.ai/developer-hub/building-on-0g/compute-network/sdk#discover-available-services">pre-trained models</a>. User interactions are straightforward—similar to OpenAI’s SDK: send a request and get a response. It’s essentially a client-layer SDK.</p><p>The nodes providing computing power to train models in the 0G Compute Network are called Providers. The repo is <a href="https://github.com/0glabs/0g-serving-broker">0g-serving-broker</a>, and it includes training code. For example, the <a href="https://github.com/0glabs/0g-serving-broker/blob/main/api/fine-tuning/execution/transformer/transformer/finetune.py">finetune.py</a> script fine-tunes text models using Transformer. The Docker container uses <a href="https://github.com/0glabs/0g-serving-broker/blob/main/api/fine-tuning/execution/transformer/Dockerfile#L2">pytorch 2.5.1-cuda12.4-cudnn9-devel</a> as the base image.</p><p>So from the LLM training perspective, 0G has some engineering-level technical work. But what 0G is doing is fine-tuning—i.e., training pre-trained models further with smaller compute to perform specific tasks. By contrast, giants like OpenAI or Grok train from scratch with massive datasets (e.g., 1 TB tokens)—that’s pre-training.</p><p>For example, if OpenAI were to release a GPT-3 model (not open-sourced in reality), 0G Compute Network could fine-tune it using its own dataset to create a customized version of GPT-3. That’s the idea.</p><p>More precisely, 0G Compute Network offers a “training ground” with integrated blockchain-based economic models and incentives. It allows some users to provide compute for fine-tuning and earn rewards, while others can use the fine-tuned models.</p><p>The interaction between Providers and smart contracts is straightforward. 0G uses Solidity-based contracts in <a href="https://github.com/0glabs/0g-serving-contract">0g-serving-contract</a>. Contract interactions follow the usual Ethereum ecosystem norms. What 0G needs to do is to write contracts that handle fine-tuning results, task distribution, reward records, penalty mechanisms, etc., and integrate these into off-chain compute nodes.</p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>All in all, I have to revise my initial opinion—0G does have some technical substance, particularly in engineering. Whether it’s blockchain DA or AI model fine-tuning, both parts are decently executed. The business logic forms a relatively complete loop.</p><p>That said, analyzing the 0G project was less straightforward than other projects I’ve covered. The whitepaper and documentation are not very complete, and the technical roadmap isn’t very unified. As a result, there’s no clear top-down resource outlining the full project structure. Still, I believe the analysis above provides a reasonably comprehensive technical breakdown of the 0G project.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;First of all, I’m not very optimistic about the technical depth of 0G, mainly because it’s a project developed by a Chinese team. 0G is</summary>
        
      
    
    
    
    
    <category term="Project Analysis" scheme="https://en.smallyu.net/tags/Project-Analysis/"/>
    
  </entry>
  
  <entry>
    <title>Analysis of the Arcium Network Project</title>
    <link href="https://en.smallyu.net/2025/08/05/Analysis%20of%20the%20Arcium%20Network%20Project/"/>
    <id>https://en.smallyu.net/2025/08/05/Analysis%20of%20the%20Arcium%20Network%20Project/</id>
    <published>2025-08-05T09:29:59.000Z</published>
    <updated>2025-08-09T09:05:26.061Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Project-Background"><a href="#Project-Background" class="headerlink" title="Project Background"></a>Project Background</h3><p><a href="https://www.arcium.com/">Arcium Network</a> is the first project in the Solana ecosystem focused on privacy computing. In May this year, it secured $50 million in funding led by GreenField, as announced in this <a href="https://x.com/ArciumHQ/status/1788557786537689447">funding post</a>.</p><p>According to Arcium’s <a href="https://www.arcium.com/articles/arcium-purplepaper">Purplepaper</a>, the project is a decentralized privacy computing protocol composed mainly of two core components: MPC and its economic model:</p><img src="1.png" width="80%"><p>The overall structure of Arcium is not difficult to grasp, especially its integration with blockchain—it directly uses Solana smart contracts:</p><img src="2.png" width="80%"><p>However, Arcium is built on a strong foundation of hardcore technologies. For instance, in this <a href="https://www.arcium.com/articles/eli5-mpc">blog post</a>, Arcium explains the principles of MPC (Secure Multi-Party Computation) through simplified examples.</p><p>MPC is not a new concept—it has been around for many years. A well-known application is MPC wallets, used by Binance and OKX. From a learning standpoint, it’s useful to distinguish between MPC, multisig, MPC wallets, TSS (Threshold Signature Scheme), and BLS aggregated signatures—terms that are related but often confused.</p><p>In Arcium’s simplified example: suppose three parties a, b, and c are computing values +1, +2, +3, and they each add salts of +10, +20, +30 respectively. The total becomes 66. Removing the combined salt (60) results in the final value of 6.</p><p>The desalinization process is sequential—each party removes its salt in turn. No single party knows the entire execution sequence. According to protocol design, such information is not public.</p><p>In reality, MPC is a complex interactive protocol that requires significant engineering. Arcium is working to expand the practical applications of this cryptographic technology—a worthwhile direction.</p><p>Arcium is exploring various technical areas, such as the <a href="https://www.arcium.com/articles/confidential-spl-token">Confidential SPL Token</a>, which combines Solana’s SPL token standard, <a href="https://github.com/solana-program/token-2022">Token-2022</a>, and Arcium’s MPC aggregation architecture to create a privacy-enabled token. They’ve also developed Dapps like on-chain Dark Pools—technically impressive.</p><h3 id="Project-Architecture"><a href="#Project-Architecture" class="headerlink" title="Project Architecture"></a>Project Architecture</h3><p>Arcium’s <a href="https://docs.arcium.com/getting-started/architecture-overview">architecture</a> may look complex at first glance, with terms like MXEs, arxOS, and Arcis. This is a typical “concept invention” tactic—naming internal components with fancy terms rather than using widely understood technical names.</p><p>A better understanding comes from the developer-focused <a href="https://docs.arcium.com/developers/computation-lifecycle">documentation</a>. As a developer using Arcium, you are essentially writing Solana smart contracts. You create your own contract (an MXE program) to describe the computation task, such as an addition operation (a + b &#x3D; c). This logic is deployed on-chain, then calls an official Arcium contract (Arcium Program) to submit the task into Arcium’s task pool:</p><img src="3.png" width="80%"><p>The Arcium Program detects the task, and the MPC Cluster (arxOS) observes this on-chain event and initiates computation. Once complete, the result is submitted back to the Arcium Program on-chain. Your MXE program includes a callback function to receive the result and notify the client:</p><img src="4.png" width="80%"><p>The types of computations you can implement (e.g., addition, subtraction, division) depend on what Arcium’s framework supports.</p><p>Stripping away the fancy terms, Arcium’s process is: submit computation tasks via on-chain contracts, let off-chain nodes compute, and return results on-chain. Their real strength lies in mastering MPC and providing a developer-friendly contract framework.</p><h3 id="Economic-Model"><a href="#Economic-Model" class="headerlink" title="Economic Model"></a>Economic Model</h3><p>Arcium calls its computation nodes <a href="https://docs.arcium.com/getting-started/network-stakeholders">StakHodlers</a>. It’s a bit complex, but in short: you can either provide hardware and go through setup to participate as a computation node and earn rewards, or you can delegate your ARX tokens to nodes to earn interest.</p><p>The economic model is described in the Purplepaper. The total supply of ARX tokens adjusts automatically based on network usage to maintain balance:</p><img src="5.png" width="80%"><p>The idea is to balance staking at 50%—if it drops below 50%, the protocol mints more ARX; if it exceeds 50%, it burns ARX. This favors active participants and node operators. However, it may be unfavorable for non-stakers, since minting doesn’t benefit them and burning reduces supply. It amplifies some issues found in Ethereum’s PoS model.</p><p>That said, Arcium’s burn model differs from Ethereum’s. Arcium collects protocol fees in SOL and uses Dutch auctions to convert SOL into ARX, which is then burned. This introduces a more complex dynamic to supply that warrants closer observation.</p><p>In summary, both the technical architecture and the economic model of Arcium are well thought out and form a complete system. There’s significant potential here. Arcium Network is currently in its testnet phase, with its roadmap still outlining mainnet launch plans.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h3 id=&quot;Project-Background&quot;&gt;&lt;a href=&quot;#Project-Background&quot; class=&quot;headerlink&quot; title=&quot;Project Background&quot;&gt;&lt;/a&gt;Project Background&lt;/h3&gt;&lt;p&gt;&lt;a</summary>
        
      
    
    
    
    
    <category term="Project Analysis" scheme="https://en.smallyu.net/tags/Project-Analysis/"/>
    
  </entry>
  
  <entry>
    <title>Analysis of the Psyche Network Project</title>
    <link href="https://en.smallyu.net/2025/08/01/Analysis%20of%20the%20Psyche%20Network%20Project/"/>
    <id>https://en.smallyu.net/2025/08/01/Analysis%20of%20the%20Psyche%20Network%20Project/</id>
    <published>2025-08-01T06:33:21.000Z</published>
    <updated>2025-08-09T09:05:26.061Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Project-Background"><a href="#Project-Background" class="headerlink" title="Project Background"></a>Project Background</h3><p><a href="https://psyche.network/runs">Psyche Network</a> is a project at the intersection of AI and Web3, developed by the <a href="https://nousresearch.com/">Nous Research</a> team. Two months ago, it secured $50 million in <a href="https://cointelegraph.com/news/nous-research-raises-50m-paradigm-decentralized-ai-solana">Series A funding</a> led by Paradigm.</p><p>The project’s background is detailed in this <a href="https://nousresearch.com/nous-psyche/">official article</a>. The Nous Research team developed a decentralized algorithm called DeMo, which enables large language model (LLM) training across a distributed network without the need for tightly coupled cluster infrastructure. It’s somewhat analogous to how mining pools distribute large tasks to individual miners—though the underlying algorithms are fundamentally different. This is just a conceptual comparison.</p><p>For the technical details of how DeMo splits and merges training tasks, refer to the <a href="https://blog.lambdaclass.com/introducing-demo-decoupled-momentum-optimization-for-efficient-distributed-llm-training/">official explanation</a>. It involves vectors, weights, loss functions, etc. As for preventing nodes from submitting fraudulent results, those mechanisms are assumed to be handled algorithmically and won’t be further discussed here.</p><p>The <a href="https://arxiv.org/pdf/2411.19870">DeMo paper</a> describes training experiments using 100 billion tokens. To put that in perspective, <a href="https://github.com/deepseek-ai/DeepSeek-V3?tab=readme-ov-file#4-evaluation-results">DeepSeek-V3</a> used about 15 TB of tokens, showing that DeMo is still far from commercial-grade scale. Here’s a comparison of various models’ token counts:</p><table><thead><tr><th>Model</th><th>Parameters</th><th>Pretraining Tokens</th><th>Source</th></tr></thead><tbody><tr><td>GPT-3</td><td>175 B</td><td>≈ 499 B</td><td>Paper and summaries</td></tr><tr><td>GPT-3.5</td><td>175 B</td><td>~1 T (estimated)</td><td>—</td></tr><tr><td>GPT-4</td><td>1.7 T</td><td>≈ 13 T tokens</td><td>SemiAnalysis &#x2F; The Decoder</td></tr><tr><td>Llama 3</td><td>70 B</td><td>&gt; 15 T tokens</td><td>Meta official card</td></tr><tr><td>DeMo OLMo</td><td>1 B</td><td>0.1 T tokens (100 B)</td><td>DeMo paper</td></tr></tbody></table><p>Psyche Network uses DeMo’s algorithm combined with blockchain to build a distributed network. Its first-stage goal is to train a model with 40 billion parameters and 20 trillion tokens. My understanding is: <code>parameters</code> are fixed at the start of training, while <code>tokens</code> represent the volume of training data, and DeMo focuses on the distributed computation of tokens. The Psyche Network website shows real-time training progress—currently over 1 TB of tokens processed:</p><img src="1.png" width="80%"><p>Once trained, the model could approach GPT-3 level. Though the token count is higher than GPT-3’s, the parameter count is lower, so performance might be slightly inferior.</p><h3 id="Project-Structure"><a href="#Project-Structure" class="headerlink" title="Project Structure"></a>Project Structure</h3><p>The <a href="https://docs.psyche.network/explain/index.html">Psyche Network documentation</a> outlines a fairly straightforward architecture. A centralized Coordinator creates training tasks, and Client nodes receive and submit results. Without blockchain, communication is handled via direct TCP connections. With blockchain, messages between Coordinator and Clients are transmitted via smart contracts:</p><img src="2.png" width="40%"><p>In the <a href="https://github.com/PsycheFoundation/psyche/tree/main/architectures">codebase</a>, both <code>centralized</code> and <code>decentralized</code> architectures are maintained. This isn’t ideal, as it implies the system was originally centralized and is now undergoing decentralization—meaning full decentralization may be limited.</p><p>In the decentralized version, Psyche Network uses Solana to run smart contracts, likely because the project is built in Rust.</p><p>Under the <code>decentralized</code> directory, you’ll find Solana contracts responsible for creating training tasks, calculating client rewards, and distributing rewards.</p><p>Currently, Psyche Network is in its testnet phase, with on-chain transactions running on Solana Devnet. Contract addresses are hardcoded, e.g., the Coordinator contract’s address is <code>HR8RN2TP9E9zsi2kjhvPbirJWA1R6L6ruf4xNNGpjU5Y</code>, and you can view transaction history on the <a href="https://solscan.io/account/HR8RN2TP9E9zsi2kjhvPbirJWA1R6L6ruf4xNNGpjU5Y?cluster=devnet">Solana block explorer</a>.</p><p>Reward calculation is fairly simple due to the centralized Coordinator. After verifying the result from a Client, the Coordinator sends a transaction to assign points. The relevant logic is in <a href="https://github.com/PsycheFoundation/psyche/blob/main/architectures/decentralized/solana-coordinator/programs/solana-coordinator/src/instance_state.rs#L146-L149">these two lines of code</a>:</p><img src="3.png" width="80%"><p>Each Client’s score is stored on-chain. To claim rewards, Clients call the treasurer contract, which calculates and transfers tokens based on score and exchange rate.</p><p>Which token is used? The Coordinator specifies it when creating the task, and any standard SPL token is acceptable, as shown <a href="https://github.com/PsycheFoundation/psyche/blob/main/architectures/decentralized/solana-treasurer/programs/solana-treasurer/src/logic/run_create.rs#L34">here</a>:</p><img src="4.png" width="70%"><p>In summary, Psyche Network uses Solana blockchain to store task metadata, calculate rewards, and distribute tokens. As long as Clients can join permissionlessly, the project achieves its advertised goal: decentralized compute for LLM training.</p><p>While token-based rewards are standard in blockchain projects, they add transparency and traceability. Psyche Network will likely launch its own token eventually. It could evolve into a full-fledged LLM training task platform where third parties can create tasks and issue rewards—similar to EigenLayer’s model.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h3 id=&quot;Project-Background&quot;&gt;&lt;a href=&quot;#Project-Background&quot; class=&quot;headerlink&quot; title=&quot;Project Background&quot;&gt;&lt;/a&gt;Project Background&lt;/h3&gt;&lt;p&gt;&lt;a</summary>
        
      
    
    
    
    
    <category term="Project Analysis" scheme="https://en.smallyu.net/tags/Project-Analysis/"/>
    
  </entry>
  
  <entry>
    <title>How to Develop a Bitcoin Runes Protocol</title>
    <link href="https://en.smallyu.net/2025/07/15/How%20to%20Develop%20a%20Bitcoin%20Runes%20Protocol/"/>
    <id>https://en.smallyu.net/2025/07/15/How%20to%20Develop%20a%20Bitcoin%20Runes%20Protocol/</id>
    <published>2025-07-15T14:00:00.000Z</published>
    <updated>2025-08-06T11:32:56.217Z</updated>
    
    <content type="html"><![CDATA[<p>Technically, Bitcoin Runes are simple and easy to understand. Implementing Runes only requires the use of the <code>OP_RETURN</code> opcode in Bitcoin Script. Precisely because of this simplicity, Runes are relatively clean from a technical perspective and not as complex as Inscriptions or RGB in terms of off-chain state management. The power of Runes lies in how it sparked an ecosystem around it. Though that hype has cooled down, we’re not focused on market trends here—we’ll look at Runes from a purely technical angle and develop a simplified version of the Runes protocol step-by-step. Once we fully understand Runes, we can dive into more complex projects like Alkanes, a protocol supporting WASM smart contracts on Bitcoin.</p><p>This tutorial builds on concepts covered in <a href="/2025/07/10/%E6%AF%94%E7%89%B9%E5%B8%81%E8%84%9A%E6%9C%AC%E5%BC%80%E5%8F%91%E6%95%99%E7%A8%8B/">Bitcoin Script Development Tutorial</a>. If you’re unfamiliar with Bitcoin Script, it’s recommended to read that first.</p><h3 id="1-Define-the-Data-Structure"><a href="#1-Define-the-Data-Structure" class="headerlink" title="1. Define the Data Structure"></a>1. Define the Data Structure</h3><p>We define Runes operations as JSON-formatted structures. Language choice is flexible—this example uses Rust. To keep the tutorial simple, we skip some practical details (e.g., the <code>transfer</code> structure only supports one target address):</p><pre><code class="rust">struct IssueRune &#123;    op: u8,          // Always 0 = Issue    symbol: String,  // Rune name    supply: String,  // Total supply&#125;struct TransferRune &#123;    op: u8,          // Always 1 = Transfer    id: u64,         // rune_id    vout: u32,       // Output index of the receiving address    amount: String,  // Amount to transfer&#125;</code></pre><p>Why <code>vout</code> instead of address? In Runes, to save space, transfers target an output index (<code>vout</code>) in the same transaction:</p><pre><code class="json">tx &#123;  vin:   [...]  vout:  [    &#123; vout: 0, scriptPubKey: OP_RETURN &lt;json_data&gt; &#125;,    &#123; vout: 1, scriptPubKey: OP_0 &lt;recipient_1&gt; &#125;,    &#123; vout: 2, scriptPubKey: OP_0 &lt;recipient_2&gt; &#125;  ]&#125;</code></pre><p>Add serialization functions to convert the structs into JSON strings:</p><pre><code class="rust">impl IssueRune &#123;    fn toJson(&amp;self) -&gt; String &#123;        format!(            &quot;&#123;&#123;\"op\":&#123;&#125;,\"symbol\":\"&#123;&#125;\",\"supply\":\"&#123;&#125;\"&#125;&#125;&quot;,            self.op, self.symbol, self.supply        )    &#125;&#125;impl TransferRune &#123;    fn toJson(&amp;self) -&gt; String &#123;        format!(            &quot;&#123;&#123;\"op\":&#123;&#125;,\"id\":&#123;&#125;,\"vout\":&#123;&#125;,\"amount\":\"&#123;&#125;\"&#125;&#125;&quot;,            self.op, self.id, self.vout, self.amount        )    &#125;&#125;</code></pre><h3 id="2-Issue-Runes"><a href="#2-Issue-Runes" class="headerlink" title="2. Issue Runes"></a>2. Issue Runes</h3><p>Using a local <code>regtest</code> node, confirm the wallet is loaded and has balance. Define the Rune issuance:</p><pre><code class="rust">fn issue_rune() &#123;    let issue = IssueRune &#123;        op: 0,        symbol: &quot;Doge&quot;.to_string(),        supply: &quot;1000&quot;.to_string(),    &#125;;    println!(&quot;Issue Doge JSON: &#123;&#125;&quot;, issue.toJson());&#125;</code></pre><p>Output:</p><pre><code class="bash">Issue Doge JSON: &#123;&quot;op&quot;:0,&quot;symbol&quot;:&quot;Doge&quot;,&quot;supply&quot;:&quot;1000&quot;&#125;</code></pre><p>Convert JSON to hex:</p><pre><code class="bash">echo -n &#39;&#123;&quot;op&quot;:0,&quot;symbol&quot;:&quot;Doge&quot;,&quot;supply&quot;:&quot;1000&quot;&#125;&#39; | xxd -p -c 999</code></pre><p>Hex:</p><pre><code class="bash">7b6f703a302c73796d626f6c3a446f67652c737570706c793a313030307d</code></pre><p>Pick a UTXO (must be unspent):</p><pre><code class="bash">bitcoin-cli -datadir=./ -regtest listunspent</code></pre><p>Example UTXO:</p><pre><code class="json">&#123;  &quot;txid&quot;: &quot;8bfd524e9fc150dab11289d7e6d07860b2b5d6acb54b278a5dc1d1d7631bc8fa&quot;,  &quot;vout&quot;: 0,  &quot;amount&quot;: 50.00000000&#125;</code></pre><p>Generate a change address:</p><pre><code class="bash">bitcoin-cli -datadir=./ getrawchangeaddress legacy</code></pre><p>My address: <code>n4Ybvvzm9vRQepuMpXBnTWWbYuTgsPSZCV</code></p><p>Create the raw transaction:</p><pre><code class="bash">bitcoin-cli -datadir=./ createrawtransaction \  &#39;[&#123;&quot;txid&quot;:&quot;...&quot;,&quot;vout&quot;:0&#125;]&#39; \  &#39;[&#123;&quot;data&quot;:&quot;7b6f703a302c73796d626f6c3a446f67652c737570706c793a313030307d&quot;&#125;,&#123;&quot;n4Ybvvzm9vRQepuMpXBnTWWbYuTgsPSZCV&quot;:49.99&#125;]&#39;</code></pre><p>Sign the transaction, then broadcast it. Finally, mine a block:</p><pre><code class="bash">bitcoin-cli -datadir=./ signrawtransactionwithwallet &lt;rawtx&gt;bitcoin-cli -datadir=./ sendrawtransaction &lt;signed_tx&gt;bitcoin-cli -datadir=./ generatetoaddress 1 &lt;your_mining_address&gt;</code></pre><p>Decode the transaction to confirm <code>OP_RETURN</code> content.</p><h3 id="3-Transfer-Runes"><a href="#3-Transfer-Runes" class="headerlink" title="3. Transfer Runes"></a>3. Transfer Runes</h3><p>Calculate the Rune ID from the issuance transaction:</p><pre><code class="rust">fn calc_run_idby_txid() &#123;    let txid = &quot;e2061d0b8b2f98ee47ba6564c1e7409872432354c7617d278fe0e8c4485ff04a&quot;.to_string();    let mut bytes = hex::decode(txid).unwrap();    bytes.reverse();    let run_id = u64::from_le_bytes(bytes[0..8].try_into().unwrap());    println!(&quot;Run ID: &#123;&#125;&quot;, run_id);&#125;</code></pre><p>Output: <code>10367542271932362826</code></p><p>Prepare a transfer structure:</p><pre><code class="rust">fn transfer_rune() &#123;    let transfer = TransferRune &#123;        op: 1,        id: 10367542271932362826,        vout: 1,        amount: &quot;1000&quot;.to_string(),    &#125;;    println!(&quot;Transfer Rune JSON: &#123;&#125;&quot;, transfer.toJson());&#125;</code></pre><p>Convert to hex:</p><pre><code class="bash">echo -n &#39;&#123;&quot;op&quot;:1,&quot;id&quot;:10367542271932362826,&quot;vout&quot;:1,&quot;amount&quot;:&quot;1000&quot;&#125;&#39; | xxd -p -c 999</code></pre><p>Create new address for receiving:</p><pre><code class="bash">bitcoin-cli -datadir=./ getnewaddress</code></pre><p>Create and sign a transaction with the new OP_RETURN and outputs (Runes transfer + BTC output + change). Broadcast and mine a block.</p><h3 id="4-Parse-Runes-Transactions"><a href="#4-Parse-Runes-Transactions" class="headerlink" title="4. Parse Runes Transactions"></a>4. Parse Runes Transactions</h3><p>Runes are entirely on-chain but stateless. Parsing must be done off-chain.</p><p>Add dependencies in <code>Cargo.toml</code>:</p><pre><code class="toml">[dependencies]hex              = &quot;0.4&quot;bitcoin          = &quot;0.31&quot;bitcoincore-rpc  = &quot;0.18&quot;serde            = &#123; version = &quot;1.0&quot;, features = [&quot;derive&quot;] &#125;anyhow           = &quot;1.0&quot;</code></pre><p>Fetch and decode transaction data via RPC:</p><pre><code class="rust">fn parse_tx() &#123;    let mut cookie = PathBuf::from(&quot;/Users/yourname/bitcoin-regtest&quot;);    cookie.push(&quot;regtest/.cookie&quot;);    let rpc = Client::new(        &quot;http://127.0.0.1:18443&quot;,        Auth::CookieFile(cookie),    ).unwrap();    let txid = Txid::from_str(&quot;...&quot;).unwrap();    let hex = rpc.get_raw_transaction_hex(&amp;txid, None).unwrap();    parse_op_return(hex);&#125;</code></pre><p>Parse the OP_RETURN data:</p><pre><code class="rust">fn parse_op_return(tx_str: String) &#123;    let tx: Transaction = bitcoin::consensus::deserialize(&amp;hex::decode(tx_str).unwrap()).unwrap();    let script = tx.output[0].script_pubkey.clone();    let mut iter = script.instructions();    if let (Some(Ok(_)), Some(Ok(bitcoin::blockdata::script::Instruction::PushBytes(bytes)))) =        (iter.next(), iter.next())    &#123;        let json_str = std::str::from_utf8(bytes.as_ref()).unwrap();        println!(&quot;&#123;&#125;&quot;, json_str);    &#125;&#125;</code></pre><p>Sample output:</p><pre><code class="bash">&#123;op:0,symbol:Doge,supply:1000&#125;&#123;&quot;op&quot;:1,&quot;id&quot;:10367542271932362826,&quot;vout&quot;:1,&quot;amount&quot;:&quot;1000&quot;&#125;</code></pre><p>This concludes the core of the Runes protocol. The rest involves building an off-chain indexer to track rune IDs, balances, and link related transactions—exactly how Runes works under the hood.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Technically, Bitcoin Runes are simple and easy to understand. Implementing Runes only requires the use of the &lt;code&gt;OP_RETURN&lt;/code&gt;</summary>
        
      
    
    
    
    
    <category term="BTC" scheme="https://en.smallyu.net/tags/BTC/"/>
    
    <category term="Tutorial" scheme="https://en.smallyu.net/tags/Tutorial/"/>
    
  </entry>
  
  <entry>
    <title>Bitcoin Script Development Tutorial</title>
    <link href="https://en.smallyu.net/2025/07/10/Bitcoin%20Script%20Development%20Tutorial/"/>
    <id>https://en.smallyu.net/2025/07/10/Bitcoin%20Script%20Development%20Tutorial/</id>
    <published>2025-07-09T16:42:10.000Z</published>
    <updated>2025-08-06T11:31:19.934Z</updated>
    
    <content type="html"><![CDATA[<p>Bitcoin Script is a bit like the elephant in the room—everyone knows it exists, but few can see it clearly or care enough. This tutorial starts from the basics to help you understand how Bitcoin Script works and learn to write your own scripts. Since Bitcoin Script is not Turing-complete, the development process involves a lot of command-line operations and observing output.</p><h3 id="1-Start-a-Local-Node"><a href="#1-Start-a-Local-Node" class="headerlink" title="1. Start a Local Node"></a>1. Start a Local Node</h3><p>Run this command to install the <code>bitcoind</code> binary, then test the installation with <code>bitcoind --help</code>:</p><pre><code class="bash">brew install bitcoin</code></pre><p>Create a directory for testing, such as <code>bitcoin-regtest</code>:</p><pre><code class="bash">mkdir ./bitcoin-regtestcd ./bitcoin-regtest</code></pre><p>In this directory, create a <code>bitcoin.conf</code> file and add the following config:</p><pre><code class="conf">regtest=1txindex=1fallbackfee=0.0001</code></pre><p>This configuration sets up a local development node. The <code>regtest=1</code> setting enables the local regression test network, starting from block height 0 and avoiding syncing with the public blockchain. <code>txindex=1</code> enables transaction indexing for easier lookup, and <code>fallbackfee</code> sets the default transaction fee.</p><p>While in the directory with this config file, start the node:</p><pre><code class="bash">bitcoind -datadir=./ -daemon</code></pre><p>If successful, you’ll see “Bitcoin Core starting”. Check if the node is running:</p><pre><code class="bash">bitcoin-cli -datadir=./ getblockchaininfo</code></pre><p>To verify further, check the log:</p><pre><code class="bash">cat ./regtest/debug.log</code></pre><p>To stop the node:</p><pre><code class="bash">bitcoin-cli -datadir=./ stop</code></pre><p>Note: <code>bitcoind</code> starts the server, while <code>bitcoin-cli</code> is the client.</p><p>If you restart the node and find the wallet isn’t working, use this to load it:</p><pre><code class="bash">bitcoin-cli -datadir=./ loadwallet learn-script </code></pre><h3 id="2-Create-a-Wallet"><a href="#2-Create-a-Wallet" class="headerlink" title="2. Create a Wallet"></a>2. Create a Wallet</h3><p>Create a Bitcoin wallet:</p><pre><code class="bash">bitcoin-cli -datadir=./ createwallet &quot;learn-script&quot;</code></pre><p>This will create a folder under <code>./regtest/wallets</code> named <code>learn-script</code>.</p><p>Generate a new wallet address:</p><pre><code class="bash">bitcoin-cli -datadir=./ getnewaddress</code></pre><p>My sample address: <code>bcrt1q6c8d9vw62rdee72xcqx3d97w8qh8mfg8ky8zjw</code></p><p>Mine 101 blocks to this address:</p><pre><code class="bash">bitcoin-cli -datadir=./ generatetoaddress 101 bcrt1q6c8d9vw62rdee72xcqx3d97w8qh8mfg8ky8zjw</code></pre><p>Check the wallet balance (should be 50):</p><pre><code class="bash">bitcoin-cli -datadir=./ getbalance</code></pre><h3 id="3-Send-a-Transaction"><a href="#3-Send-a-Transaction" class="headerlink" title="3. Send a Transaction"></a>3. Send a Transaction</h3><p>Generate a new receiving address:</p><pre><code class="bash">bitcoin-cli -datadir=./ getnewaddress</code></pre><p>Example: <code>bcrt1qgq99zusgk3ekrzucs9uyqv5vpxnh66cjtwl6zc</code></p><p>Check the balance (should be 0):</p><pre><code class="bash">bitcoin-cli -datadir=./ getreceivedbyaddress bcrt1qgq99zusgk3ekrzucs9uyqv5vpxnh66cjtwl6zc 0</code></pre><p>Send 0.01 BTC to it:</p><pre><code class="bash">bitcoin-cli -datadir=./ sendtoaddress bcrt1qgq99zusgk3ekrzucs9uyqv5vpxnh66cjtwl6zc 0.01</code></pre><p>Get transaction details:</p><pre><code class="bash">bitcoin-cli -datadir=./ gettransaction &lt;txid&gt;</code></pre><p>Mine one block to confirm the transaction:</p><pre><code class="bash">bitcoin-cli -datadir=./ generatetoaddress 1 bcrt1q6c8d9vw62rdee72xcqx3d97w8qh8mfg8ky8zjw</code></pre><h3 id="4-Inspect-the-Script"><a href="#4-Inspect-the-Script" class="headerlink" title="4. Inspect the Script"></a>4. Inspect the Script</h3><p>Use <code>getrawtransaction</code> and <code>decoderawtransaction</code> to view the transaction script:</p><pre><code class="bash">bitcoin-cli -datadir=./ getrawtransaction &lt;txid&gt;bitcoin-cli -datadir=./ decoderawtransaction &lt;hex&gt;</code></pre><p>You’ll see <code>txinwitness</code> (signature and pubkey) and <code>scriptPubKey</code> (locking script). <code>OP_0</code> in the script means an empty push (used in SegWit).</p><h3 id="5-Debug-with-btcdeb"><a href="#5-Debug-with-btcdeb" class="headerlink" title="5. Debug with btcdeb"></a>5. Debug with btcdeb</h3><p>Use <code>btcdeb</code> to debug opcodes. Example:</p><pre><code class="bash">btcdeb OP_0</code></pre><p>And for a simple calculation:</p><pre><code class="bash">btcdeb &#39;[OP_2 OP_3 OP_ADD]&#39;</code></pre><p>Use <code>step</code> to execute each operation and watch the stack.</p><h3 id="6-Write-Bitcoin-Script-1"><a href="#6-Write-Bitcoin-Script-1" class="headerlink" title="6. Write Bitcoin Script (1)"></a>6. Write Bitcoin Script (1)</h3><p>Write this simple script (insecure, for demo only):</p><pre><code>[OP_2 OP_3 OP_ADD OP_5 OP_EQUAL]</code></pre><p>Convert to hex: <code>5253935587</code></p><p>Generate P2SH address:</p><pre><code class="bash">bitcoin-cli -datadir=./ decodescript 5253935587</code></pre><p>Get descriptor:</p><pre><code class="bash">bitcoin-cli -datadir=./ getdescriptorinfo &quot;addr(&lt;p2sh-address&gt;)&quot;</code></pre><p>Create a watch-only wallet:</p><pre><code class="bash">bitcoin-cli -datadir=./ createwallet &quot;arith-watch&quot; true true &quot;&quot; true</code></pre><p>Import the script:</p><pre><code class="bash">bitcoin-cli -datadir=./ -rpcwallet=arith-watch importdescriptors &#39;[&#123;&quot;desc&quot;:&quot;addr(&lt;p2sh-address&gt;)#&lt;checksum&gt;&quot;,&quot;timestamp&quot;:&quot;now&quot;,&quot;label&quot;:&quot;arith-2+3=5&quot;&#125;]&#39;</code></pre><p>Send BTC to the script address:</p><pre><code class="bash">bitcoin-cli -datadir=./ -rpcwallet=learn-script sendtoaddress &lt;p2sh-address&gt; 0.01</code></pre><p>Mine a block to confirm:</p><pre><code class="bash">bitcoin-cli -datadir=./ generatetoaddress 1 &lt;your-address&gt;</code></pre><h3 id="7-Write-Bitcoin-Script-2"><a href="#7-Write-Bitcoin-Script-2" class="headerlink" title="7. Write Bitcoin Script (2)"></a>7. Write Bitcoin Script (2)</h3><p>Create a new address:</p><pre><code class="bash">bitcoin-cli -datadir=./ -rpcwallet=learn-script getnewaddress</code></pre><p>Use <code>createrawtransaction</code>, <code>fundrawtransaction</code>, <code>signrawtransactionwithwallet</code>, and <code>sendrawtransaction</code> to construct and broadcast a transaction spending from the script.</p><p>Mine another block to confirm:</p><pre><code class="bash">bitcoin-cli -datadir=./ generatetoaddress 1 &lt;your-address&gt;</code></pre><p>Check if the UTXO is spent:</p><pre><code class="bash">bitcoin-cli -datadir=./ gettxout &lt;txid&gt; 0</code></pre><h3 id="8-Troubleshooting"><a href="#8-Troubleshooting" class="headerlink" title="8. Troubleshooting"></a>8. Troubleshooting</h3><p>Environment used:</p><pre><code class="text">OS: MacOSbitcoind: v29.0.0btcdeb: 5.0.24</code></pre>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Bitcoin Script is a bit like the elephant in the room—everyone knows it exists, but few can see it clearly or care enough. This tutorial</summary>
        
      
    
    
    
    
    <category term="BTC" scheme="https://en.smallyu.net/tags/BTC/"/>
    
    <category term="Tutorial" scheme="https://en.smallyu.net/tags/Tutorial/"/>
    
  </entry>
  
  <entry>
    <title>Blockchain Technical Interview Questions (2025 Edition)</title>
    <link href="https://en.smallyu.net/2025/07/06/Blockchain%20Technical%20Interview%20Questions%20(2025%20Edition)/"/>
    <id>https://en.smallyu.net/2025/07/06/Blockchain%20Technical%20Interview%20Questions%20(2025%20Edition)/</id>
    <published>2025-07-06T10:38:03.000Z</published>
    <updated>2025-08-06T11:30:06.687Z</updated>
    
    <content type="html"><![CDATA[<p>Compared to the 2023 version of <a href="/2023/07/12/%E5%8C%BA%E5%9D%97%E9%93%BE%E6%8A%80%E6%9C%AF%E9%9D%A2%E8%AF%95%E9%A2%98/">Blockchain Technical Interview Questions</a>, which focused more on a macro perspective, this edition leans slightly more toward engineering practice and includes more technical details. These two versions complement each other—they’re not upgrades. The questions here are purely based on my personal experience, just like many interviewers who only ask what they themselves know and won’t ask about things they don’t understand. So the scope and depth of these questions are inevitably limited by my own level of knowledge:</p><ol><li>Why is the Ethereum client divided into execution layer and consensus layer?</li><li>How does Ethereum’s PoS process work, and how do you initialize a PoS network?</li><li>What are the soft fork and recovery mechanisms in Ethereum PoS? Is Cardano’s PoS the same as Ethereum’s?</li><li>What types of Ethereum nodes exist, and what are their use cases?</li><li>Why is EVM execution single-threaded? Why has no team in the world succeeded in building a “parallel EVM”?</li><li>Does the Solidity language have garbage collection (GC)? How does it handle dynamic memory allocation?</li><li>In what scenarios is inline assembly necessary in Solidity?</li><li>Are you familiar with the PBFT consensus? What’s its general process?</li><li>What is the formula for PBFT fault tolerance, and why that number specifically?</li><li>Why does PBFT require a second round of voting?</li><li>What is Solana’s consensus mechanism like? Is TowerBFT voting on blocks?</li><li>Why can Solana’s smart contracts be executed in parallel while Ethereum’s cannot?</li><li>What is the upgrade process for Cosmos nodes? How is it different from Ethereum’s? What are the risks of this model?</li><li>What is the general flow of an Op Rollup? Which part does ZK Rollup optimize based on Op Rollup’s model?</li><li>How does asset bridging work between Ethereum L2s? Technically, how does it differ from bridging assets across entirely different networks?</li><li>Ethereum recently had a major upgrade introducing EIP-7702—what is it for? How is it related to Account Abstraction (AA) wallets?</li><li>What interesting blockchain-related technical topics have you personally explored?</li></ol><p>That’s all the questions I can think of at the moment. For more in-depth, engineering-oriented topics, I only have a general idea of the direction—I haven’t personally worked on them. Still, my experiences over the past couple of years have been relatively rich. Comparing the two versions of the question list reveals a lot of changes. I hope I can continue to improve and not lose my way.</p><p>If you’re a job seeker in the blockchain industry—especially if you’re a relatively inexperienced engineer—don’t be intimidated by the questions above. In real interviews, you’ll rarely encounter such deep and thought-provoking questions. More commonly asked questions include things like: “What are the common fields in an Ethereum transaction?”, “How do you cancel a transaction that’s already been sent?”, “What is a reentrancy attack in Solidity?”, “What components make up the Op Stack?”, “What is <code>create2</code> in Ethereum contracts?”, etc. Go confidently into job hunting—there aren’t that many people who truly understand the technology deeply.</p><p>There’s currently an issue in the blockchain industry: there is no systematic theoretical framework, only some fragmented, frontier engineering efforts. For example, compare this with the field of programming languages—from Church and Turing’s models of computation, to functional programming languages, compilers, type systems, and so on—after decades of development in academia and industry, there’s both highly abstract theoretical support and practical industrial applications. It’s relatively mature. But blockchain is quite new—it originated in 2008 and started entering the public eye around 2013. In just a few years, there hasn’t been enough time to build a solid academic system. Instead, each project team goes its own way, creating their own standards and defining their</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Compared to the 2023 version of &lt;a</summary>
        
      
    
    
    
    
    <category term="Blockchain" scheme="https://en.smallyu.net/tags/Blockchain/"/>
    
    <category term="Interview Questions" scheme="https://en.smallyu.net/tags/Interview-Questions/"/>
    
  </entry>
  
  <entry>
    <title>One &quot;Over-Optimization&quot; in Rust That Often Confuses Beginners</title>
    <link href="https://en.smallyu.net/2025/06/30/One%20%22Over-Optimization%22%20in%20Rust%20That%20Often%20Confuses%20Beginners/"/>
    <id>https://en.smallyu.net/2025/06/30/One%20%22Over-Optimization%22%20in%20Rust%20That%20Often%20Confuses%20Beginners/</id>
    <published>2025-06-29T18:05:25.000Z</published>
    <updated>2025-08-06T11:29:31.854Z</updated>
    
    <content type="html"><![CDATA[<p>Suppose we want to write some code. Just use <code>cargo new</code> to create a project, and then define a function called <code>append</code>. The function is straightforward—it concatenates two input strings. The first parameter is a reference to a string, and the second is also a string. For example, given the parameters <code>Hello</code> and <code>, world</code>, the function will return <code>Hello, world</code>. Here’s the function:</p><pre><code class="rust">fn append(s1: &amp;String, s2: &amp;String) -&gt; String &#123;    return s1.clone() + s2.clone().as_str();&#125;</code></pre><p>Don’t worry about the syntax after <code>return</code>; that’s not our focus here. In the <code>main</code> function, we call <code>append</code>, run the code, and the output will be as expected—<code>Hello, world</code>:</p><pre><code class="rust">fn main() &#123;    let s1: String = String::from(&quot;Hello&quot;);    let s2: String = String::from(&quot;, world&quot;);    println!(&quot;&#123;&#125;&quot;, append(&amp;s1, &amp;s2));&#125;</code></pre><p>Now, keep the <code>append</code> function exactly the same, but change the string definitions in <code>main</code>. The <code>main</code> function becomes:</p><pre><code class="rust">fn main() &#123;    let s1: Box&lt;String&gt; = Box::new(String::from(&quot;Hello&quot;));    let s2: Box&lt;String&gt; = Box::new(String::from(&quot;, world&quot;));    println!(&quot;&#123;&#125;&quot;, append(&amp;s1, &amp;s2));&#125;</code></pre><p>Our initial instinct might be that this should cause a compile-time error, since <code>s1</code> is of type <code>Box&lt;String&gt;</code>, and passing <code>&amp;s1</code> means the type is <code>&amp;Box&lt;String&gt;</code>, which doesn’t match the <code>append</code> function’s parameter type of <code>&amp;String</code>. So why does this compile successfully and output <code>Hello, world</code> as expected? (Ignore what <code>Box</code> is for now; it’s just another type.)</p><p>Let’s take it further and modify <code>main</code> like this:</p><pre><code class="rust">fn main() &#123;    use std::rc::Rc;    let s1: Rc&lt;String&gt; = Rc::new(String::from(&quot;Hello&quot;));    let s2: Rc&lt;String&gt; = Rc::new(String::from(&quot;, world&quot;));    println!(&quot;&#123;&#125;&quot;, append(&amp;s1, &amp;s2));&#125;</code></pre><p>Will this compile? Will it run correctly? The <code>append</code> function definition hasn’t changed. Here, <code>s1</code> is of type <code>Rc&lt;String&gt;</code>, and the arguments passed into <code>append</code> are of type <code>&amp;Rc&lt;String&gt;</code>. So why doesn’t the compiler complain, and why does it still print <code>Hello, world</code>? (Again, ignore what <code>Rc</code> is—just treat it as a type.)</p><p>From the above code snippets, we observe a phenomenon: when the function parameters are of type <code>&amp;String</code>, it accepts not only <code>&amp;String</code> but also <code>&amp;Box&lt;String&gt;</code> and <code>&amp;Rc&lt;String&gt;</code>.</p><p>Let’s push this further. What happens if we change <code>main</code> to:</p><pre><code class="rust">fn main() &#123;    let s1: Box&lt;Box&lt;Box&lt;Box&lt;String&gt;&gt;&gt;&gt; = Box::new(Box::new(Box::new(Box::new(String::from(&quot;Hello&quot;)))));    let s2: Box&lt;Box&lt;Box&lt;Box&lt;String&gt;&gt;&gt;&gt; = Box::new(Box::new(Box::new(Box::new(String::from(&quot;, world&quot;)))));    println!(&quot;&#123;&#125;&quot;, append(&amp;s1, &amp;s2));&#125;</code></pre><p>Or like this:</p><pre><code class="rust">fn main() &#123;    use std::rc::Rc;        let s1: Rc&lt;Rc&lt;Rc&lt;Rc&lt;String&gt;&gt;&gt;&gt; = Rc::new(Rc::new(Rc::new(Rc::new(String::from(&quot;hello&quot;)))));    let s2: Rc&lt;Rc&lt;Rc&lt;Rc&lt;String&gt;&gt;&gt;&gt; = Rc::new(Rc::new(Rc::new(Rc::new(String::from(&quot;, world&quot;)))));    println!(&quot;&#123;&#125;&quot;, append(&amp;s1, &amp;s2));&#125;</code></pre><p>The result: both versions of <code>main</code> compile and run normally, printing <code>Hello, world</code>.</p><p>To explore the type behavior further, let’s define two more <code>append</code> functions. <code>append2</code> takes <code>&amp;Box&lt;String&gt;</code>, and <code>append3</code> takes <code>&amp;Rc&lt;String&gt;</code>:</p><pre><code class="rust">fn append2(s1: &amp;Box&lt;String&gt;, s2: &amp;Box&lt;String&gt;) -&gt; Box&lt;String&gt; &#123;    let mut result = (**s1).clone();    result.push_str(s2);    Box::new(result)&#125;use std::rc::Rc;fn append3(s1: &amp;Rc&lt;String&gt;, s2: &amp;Rc&lt;String&gt;) -&gt; Rc&lt;String&gt; &#123;    let mut result = (**s1).clone();    result.push_str(s2);    Rc::new(result)&#125;</code></pre><p>Now, consider the following <code>main</code> function. On which line will the compiler report an error?</p><pre><code class="rust">fn main() &#123;    let s1: Box&lt;Box&lt;Rc&lt;Rc&lt;String&gt;&gt;&gt;&gt; = Box::new(Box::new(Rc::new(Rc::new(String::from(&quot;hello&quot;)))));    let s2: Box&lt;Box&lt;Rc&lt;Rc&lt;String&gt;&gt;&gt;&gt; = Box::new(Box::new(Rc::new(Rc::new(String::from(&quot;, world&quot;)))));    println!(&quot;&#123;&#125;&quot;, append(&amp;s1, &amp;s2));    println!(&quot;&#123;&#125;&quot;, append2(&amp;s1, &amp;s2));    println!(&quot;&#123;&#125;&quot;, append3(&amp;s1, &amp;s2));&#125;</code></pre><p>What if we expand the types even further? Will the compiler still complain, and where?</p><pre><code class="rust">fn main() &#123;    let s1: Box&lt;Box&lt;Rc&lt;Rc&lt;Box&lt;Box&lt;String&gt;&gt;&gt;&gt;&gt;&gt; = Box::new(Box::new(Rc::new(Rc::new(Box::new(Box::new(String::from(&quot;hello&quot;)))))));    let s2: Box&lt;Box&lt;Rc&lt;Rc&lt;Box&lt;Box&lt;String&gt;&gt;&gt;&gt;&gt;&gt; = Box::new(Box::new(Rc::new(Rc::new(Box::new(Box::new(String::from(&quot;, world&quot;)))))));    println!(&quot;&#123;&#125;&quot;, append(&amp;s1, &amp;s2));    println!(&quot;&#123;&#125;&quot;, append2(&amp;s1, &amp;s2));    println!(&quot;&#123;&#125;&quot;, append3(&amp;s1, &amp;s2));&#125;</code></pre><p>Rust calls this ergonomic design, meant to reduce the developer’s burden. However, when it comes to things like frequent ownership moves or needing to annotate lifetimes with <code>&#39;</code>, Rust drops ergonomic considerations in favor of memory safety. Arguably, that’s not wrong—after all, memory safety is Rust’s non-negotiable priority.</p><p>Finally, let’s raise the difficulty. In a real-world scenario, suppose there’s a function called <code>do_something</code> that takes generic parameters. The original logic looks like this:</p><pre><code class="rust">fn do_something&lt;T1, T2&gt;(t1: T1, t2: T2) &#123;    println!(&quot;&#123;&#125;&quot;, append(&amp;t1, &amp;t2));&#125;</code></pre><p>Now let’s add some extra processing:</p><pre><code class="rust">fn do_something&lt;T1, T2&gt;(t1: T1, t2: T2) &#123;    // Add a function to process t1    handle_t1(&amp;t1);      println!(&quot;&#123;&#125;&quot;, append(&amp;t1, &amp;t2));&#125;</code></pre><p>So here’s the question: What is the type of parameter <code>t1</code>? How should the <code>handle_t1</code> function be defined? In the original logic, <code>t1</code> is passed to <code>append</code>, so does that mean <code>t1</code> is of type <code>&amp;String</code>? If not, what could <code>t1</code>’s type be?</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Suppose we want to write some code. Just use &lt;code&gt;cargo new&lt;/code&gt; to create a project, and then define a function called</summary>
        
      
    
    
    
    
    <category term="Programming Language" scheme="https://en.smallyu.net/tags/Programming-Language/"/>
    
    <category term="Rust" scheme="https://en.smallyu.net/tags/Rust/"/>
    
  </entry>
  
  <entry>
    <title>Solana Smart Contract Development Tutorial</title>
    <link href="https://en.smallyu.net/2025/06/24/Solana%20Smart%20Contract%20Development%20Tutorial/"/>
    <id>https://en.smallyu.net/2025/06/24/Solana%20Smart%20Contract%20Development%20Tutorial/</id>
    <published>2025-06-24T13:51:06.000Z</published>
    <updated>2025-08-12T15:22:29.934Z</updated>
    
    <content type="html"><![CDATA[<p>This is a beginner-friendly series that teaches Solana smart contract development from the ground up. It has 3 parts:</p><ul><li><a href="#Development-Tutorial-1">Part 1</a>: Install the basics, deploy a HelloWorld program, and call it on-chain</li><li><a href="#Development-Tutorial-2">Part 2</a>: Implement a minimal USDT-like program with custom data structures and methods</li><li><a href="#Development-Tutorial-3">Part 3</a>: Reuse functionality via the official SPL library to issue a standards-compliant token</li></ul><br><h2 id="Development-Tutorial-1"><a href="#Development-Tutorial-1" class="headerlink" title="Development-Tutorial-1"></a>Development-Tutorial-1</h2><p>We’ll start from first principles. You only need general programming knowledge—concepts like OOP are enough. You don’t need prior smart contract experience on other networks, nor do you need to know Rust beforehand.</p><h3 id="1-Install-the-toolchain"><a href="#1-Install-the-toolchain" class="headerlink" title="1. Install the toolchain"></a>1. Install the toolchain</h3><p>Follow Solana’s official installation guide: <a href="https://solana.com/docs/intro/installation">https://solana.com/docs/intro/installation</a></p><p>There’s a one-liner to install everything, and also a detailed step-by-step guide. Note that the Solana CLI requires editing your shell’s environment file. After installation, the <code>solana</code> command should be available:</p><pre><code>solana --help</code></pre><h3 id="2-Initialize-a-project"><a href="#2-Initialize-a-project" class="headerlink" title="2. Initialize a project"></a>2. Initialize a project</h3><p>Use the <code>anchor</code> CLI to initialize a new smart contract project. This tool was installed in the previous step. Don’t worry yet about the generated folder structure:</p><pre><code>anchor init hello_solcd hello_sol</code></pre><h3 id="3-Write-the-program-code"><a href="#3-Write-the-program-code" class="headerlink" title="3. Write the program code"></a>3. Write the program code</h3><p>In <code>programs/hello_sol/src</code> there’s a <code>lib.rs</code>. The <code>.rs</code> extension means it’s a Rust source file. Paste the following. Note: the value inside <code>declare_id</code> is generated for your project during initialization—you’ll already have your own; you don’t need to copy the one below verbatim.</p><pre><code>use anchor_lang::prelude::*;declare_id!(&quot;3Zbdw1oWu1CiMiQr3moQeT4XzMgeqmCvjH5R5wroDWQH&quot;);#[program]pub mod hello_sol &#123;    use super::*;    pub fn say_hello(ctx: Context&lt;Hello&gt;) -&gt; Result&lt;()&gt; &#123;        msg!(&quot;Hello, world!&quot;);        Ok(())    &#125;&#125;#[derive(Accounts)]pub struct Hello &#123;&#125;</code></pre><h3 id="4-Build-the-smart-contract"><a href="#4-Build-the-smart-contract" class="headerlink" title="4. Build the smart contract"></a>4. Build the smart contract</h3><p>Use <code>anchor</code> to compile the program you just pasted. Make sure it compiles successfully. You may see some warnings—that’s fine. Rust is strict and will warn on small issues. If all goes well, there should be no errors in the output:</p><pre><code>anchor build</code></pre><h3 id="5-Set-the-default-local-cluster"><a href="#5-Set-the-default-local-cluster" class="headerlink" title="5. Set the default local cluster"></a>5. Set the default local cluster</h3><p>Run this to make the <code>solana</code> CLI default to devnet. Devnet is for developers—it lets you test without spending real SOL:</p><pre><code>solana config set --url https://api.devnet.solana.com</code></pre><h3 id="6-Create-a-local-keypair"><a href="#6-Create-a-local-keypair" class="headerlink" title="6. Create a local keypair"></a>6. Create a local keypair</h3><p>This creates a local Solana account used to deploy programs. Deploying costs fees, which must be paid from an account:</p><pre><code>solana-keygen new -o ~/.config/solana/id.json  </code></pre><p>In the output, look for the line starting with <code>pubkey:</code>—that’s your local account address. Since you set devnet as the default network, you can check your balance directly:</p><pre><code>solana balance</code></pre><p>You can also open the devnet <a href="https://explorer.solana.com/?cluster=devnet">explorer</a> and search for your address. The URL will look like:<a href="https://explorer.solana.com/address/75sFifxBt7zw1YrDfCdPjDCGDyKEqLWrBarPCLg6PHwb?cluster=devnet">https://explorer.solana.com/address/75sFifxBt7zw1YrDfCdPjDCGDyKEqLWrBarPCLg6PHwb?cluster=devnet</a></p><p>You’ll see the balance is <code>0 SOL</code>.</p><h3 id="7-Request-a-devnet-airdrop"><a href="#7-Request-a-devnet-airdrop" class="headerlink" title="7. Request a devnet airdrop"></a>7. Request a devnet airdrop</h3><p>Run this to receive 2 SOL (the <code>2</code> parameter is the amount). Due to faucet limits, 2 is the max per request—but it’s enough for the steps ahead.</p><pre><code>solana airdrop 2</code></pre><h3 id="8-Deploy-to-devnet"><a href="#8-Deploy-to-devnet" class="headerlink" title="8. Deploy to devnet"></a>8. Deploy to devnet</h3><p>You have the program code, a local account, and some SOL. Time to deploy:</p><pre><code>anchor deploy --provider.cluster devnet </code></pre><p>On success you’ll see <code>Deploy success</code>. Also look for <code>Program Id:</code>—that’s your program’s address. You can search it on the devnet explorer. For example, here’s a page like this (the <code>3Zbd...DWQH</code> is the program ID deployed in my example):<a href="https://explorer.solana.com/address/3Zbdw1oWu1CiMiQr3moQeT4XzMgeqmCvjH5R5wroDWQH?cluster=devnet">https://explorer.solana.com/address/3Zbdw1oWu1CiMiQr3moQeT4XzMgeqmCvjH5R5wroDWQH?cluster=devnet</a></p><h3 id="9-Call-the-on-chain-program"><a href="#9-Call-the-on-chain-program" class="headerlink" title="9. Call the on-chain program"></a>9. Call the on-chain program</h3><p>In <code>hello_sol/app</code>, create a file <code>app.js</code> and paste the following. In short, it loads your default local keypair and uses your Solana account to send a transaction that calls the on-chain program. Each run creates one transaction:</p><pre><code>const anchor = require(&#39;@coral-xyz/anchor&#39;);const fs     = require(&#39;fs&#39;);const os     = require(&#39;os&#39;);const path   = require(&#39;path&#39;);const &#123; Keypair, Connection &#125; = anchor.web3;const RPC_URL    = process.env.RPC_URL;const connection = new Connection(RPC_URL, &#123; commitment: &#39;confirmed&#39; &#125;);const secretKey = Uint8Array.from(  JSON.parse(    fs.readFileSync(      path.join(os.homedir(), &#39;.config/solana/id.json&#39;),      &#39;utf8&#39;,    ),  ),);const wallet   = new anchor.Wallet(Keypair.fromSecretKey(secretKey));const provider = new anchor.AnchorProvider(connection, wallet, &#123;  preflightCommitment: &#39;confirmed&#39;,&#125;);anchor.setProvider(provider);const idlPath = path.resolve(__dirname, &#39;../target/idl/hello_sol.json&#39;);const idl     = JSON.parse(fs.readFileSync(idlPath, &#39;utf8&#39;));const program = new anchor.Program(idl, provider);(async () =&gt; &#123;  try &#123;    const sig = await program.methods.sayHello().rpc();    console.log(&#39;✅ tx&#39;, sig);    console.log(`🌐 https://explorer.solana.com/tx/$&#123;sig&#125;?cluster=devnet`);  &#125; catch (err) &#123;    console.error(&#39;❌&#39;, err);  &#125;&#125;)();</code></pre><p>Back at the project root (<code>hello_sol</code>), install the Node.js deps:</p><pre><code>npm init -y npm install @coral-xyz/anchor</code></pre><p>Still at the project root, run the script to call your deployed program on devnet:</p><pre><code>export RPC_URL=https://api.devnet.solana.comnode app/app.js</code></pre><p><code>RPC_URL</code> is the endpoint used by the script. Since Node.js doesn’t go through a system proxy by default, if your network is restricted you’ll want a better endpoint than the public RPC—for example, <a href="https://www.helius.dev/">Helius</a> offers free accounts. If you see an error like below, it’s most likely a network issue—switch to a more reliable RPC:</p><pre><code>❌ Error: failed to get recent blockhash: TypeError: fetch failed    at Connection.getLatestBlockhash (/Users/smallyu/work/github/hello_sol/node_modules/@solana/web3.js/lib/index.cjs.js:7236:13)    at process.processTicksAndRejections (node:internal/process/task_queues:95:5)    at async AnchorProvider.sendAndConfirm (/Users/smallyu/work/github/hello_sol/node_modules/@coral-xyz/anchor/dist/cjs/provider.js:89:35)    at async MethodsBuilder.rpc [as _rpcFn] (/Users/smallyu/work/github/hello_sol/node_modules/@coral-xyz/anchor/dist/cjs/program/namespace/rpc.js:15:24)    at async /Users/smallyu/work/github/hello_sol/app/app.js:40:17</code></pre><p>You might wonder why we didn’t specify the program address—how does the script know which program you deployed? Notice the <code>idlPath</code> variable. Open <code>target/idl/hello_sol.json</code> and you’ll find metadata about the compiled program, including the program ID. That’s right—the address is generated offline; the program has a unique address even before deployment.</p><p>If the script runs without errors, the terminal will print the transaction signature and a browser URL you can open. For example:<a href="https://explorer.solana.com/tx/2fnPgKkv3tGKKq72hhRxmW6WFSXuofMzXfY2UYoFZXTdJi37btdESy9NzS2gjpWzXX4CL5F7QfxugpctBVaMcBFY?cluster=devnet">https://explorer.solana.com/tx/2fnPgKkv3tGKKq72hhRxmW6WFSXuofMzXfY2UYoFZXTdJi37btdESy9NzS2gjpWzXX4CL5F7QfxugpctBVaMcBFY?cluster=devnet</a></p><p>At the bottom of that transaction page you’ll see <code>Program logged: &quot;Hello, world!&quot;</code>, which is the <code>msg!</code> we wrote in the program.</p><h3 id="10-Troubleshooting"><a href="#10-Troubleshooting" class="headerlink" title="10. Troubleshooting"></a>10. Troubleshooting</h3><p>If you hit errors, first suspect version mismatches. The blockchain space iterates quickly and incompatibilities are common. Here are my local versions:</p><pre><code>rustup: rustup 1.28.2 (e4f3ad6f8 2025-04-28)rustc: rustc 1.90.0-nightly (706f244db 2025-06-23)solana: solana-cli 2.2.18 (src:8392f753; feat:3073396398, client:Agave)archor: anchor-cli 0.31.1node: v24.2.0@coral-xyz/anchor(nodejs): ^0.31.1</code></pre><p><br><br></p><h2 id="Development-Tutorial-2"><a href="#Development-Tutorial-2" class="headerlink" title="Development-Tutorial-2"></a>Development-Tutorial-2</h2><p>We’ve learned how to create, deploy, and call a program. Now let’s go deeper into program structure and logic by implementing a simple USDT-like token program, reading through the code while learning Solana’s style of smart contracts.</p><h3 id="1-Create-a-project"><a href="#1-Create-a-project" class="headerlink" title="1. Create a project"></a>1. Create a project</h3><p>Use the command you already know:</p><pre><code>anchor init usdt_clone</code></pre><h3 id="2-Config-file"><a href="#2-Config-file" class="headerlink" title="2. Config file"></a>2. Config file</h3><p>Check <code>programs/usdt_clone/Cargo.toml</code>. Cargo is Rust’s package manager, and <code>Cargo.toml</code> declares dependencies and versions. The autogenerated config contains:</p><pre><code>[dependencies]anchor-lang = &quot;0.31.1&quot;</code></pre><p>Anchor’s macros are key to Solana programs—things like <code>#[program]</code> and <code>#[account]</code> tell Solana’s SVM where the entrypoints and data structures are. Without the Anchor dependency, this would be a normal Rust project and Solana wouldn’t know how to interpret it. That’s how Solana leverages Rust to implement smart contracts.</p><h3 id="3-Program-address"><a href="#3-Program-address" class="headerlink" title="3. Program address"></a>3. Program address</h3><p>Open <code>usdt_clone/programs/usdt_clone/src/lib.rs</code>. The first line imports common Anchor types, which is fine as-is:</p><pre><code>use anchor_lang::prelude::*;</code></pre><p>The second line calls <code>declare_id</code> to set the Program ID (the address). As mentioned earlier, Solana program addresses can be generated offline.</p><pre><code>declare_id!(&quot;CFmGdHuqDymqJYBX44fyNjrFoJx6wRkZPkYgZqfkAQvT&quot;);</code></pre><p>This is a random-looking value, but not arbitrary—it’s an Ed25529 public key. If you change the last character <code>T</code> to <code>t</code>, the string is no longer a valid public key. So while it can be randomly generated, you can’t just tweak it freely. Where’s the private key, then? During initialization, a keypair is created at <code>target/deploy/usdt_clone-keypair.json</code>. It’s an array of bytes; the <code>declare_id</code> public key is derived from that private key.</p><h3 id="4-Stored-data-structures"><a href="#4-Stored-data-structures" class="headerlink" title="4. Stored data structures"></a>4. Stored data structures</h3><p>Add your logic below <code>declare_id</code>:</p><pre><code>#[account]pub struct Mint &#123;    pub decimals: u8,    pub mint_authority: Pubkey,&#125;</code></pre><p>You can think of <code>#[account]</code> as defining on-chain data structures. Anchor’s “magic” wires things so you can read&#x2F;write these structures on-chain. Here we define a <code>Mint</code> with two fields: <code>decimals</code> for token precision, and <code>mint_authority</code> for who can mint.</p><p>Define another struct to store per-user balances. <code>owner</code> is the user address, <code>balance</code> is their balance:</p><pre><code>#[account]pub struct TokenAccount &#123;    pub owner: Pubkey,    pub balance: u64,&#125;</code></pre><h3 id="5-Account-constraint-structs"><a href="#5-Account-constraint-structs" class="headerlink" title="5. Account constraint structs"></a>5. Account constraint structs</h3><p>At the bottom of the template you’ll see <code>#[derive(Accounts)]</code>—this macro lets you specify constraints for accounts. You can define functions within a <code>#[derive(Accounts)]</code> block and then use <code>#[account]</code> to define structures; those structures gain behavior akin to methods.</p><p>Remove the original <code>Initialize</code>:</p><pre><code>#[derive(Accounts)]pub struct Initialize &#123;&#125;    // delete</code></pre><p>Add your own:</p><pre><code>#[derive(Accounts)]pub struct InitMint&lt;&#39;info&gt; &#123;    #[account(        init,         payer = authority,        space = 8 + 1 + 32    )]    pub mint: Account&lt;&#39;info, Mint&gt;,    #[account(mut)]    pub authority: Signer&lt;&#39;info&gt;,    pub system_program: Program&lt;&#39;info, System&gt;,&#125;</code></pre><p>A bit to unpack. In <code>#[account(...)]</code> we pass 3 parameters defined by Anchor:</p><ul><li><code>init</code> is a flag: create the account if it doesn’t exist.</li><li><code>payer</code> specifies who pays for the account creation.</li><li><code>space</code> is how many bytes to allocate: 8 (discriminator) + 1 for <code>u8</code> + 32 for <code>Pubkey</code>.</li></ul><p>This macro decorates the <code>mint</code> field. <code>Account&lt;&#39;info, Mint&gt;</code> is an Anchor account type for reading&#x2F;writing our <code>Mint</code> (as opposed to <code>TokenAccount</code>, etc.).</p><p>Next, <code>#[account(mut)]</code> indicates lamports may change. <code>authority</code> is a <code>Signer&lt;&#39;info&gt;</code>, meaning a signature from the owner is required. The <code>’info</code> lifetime is a Rust feature—think of it like a borrowed reference. Finally, <code>system_program</code> is boilerplate whenever SOL transfers may occur. Altogether, <code>InitMint</code> is a wrapper around <code>Mint</code> with account-related constraints.</p><h3 id="6-Initialize-the-token-program"><a href="#6-Initialize-the-token-program" class="headerlink" title="6. Initialize the token program"></a>6. Initialize the token program</h3><p>Focus on the functions under <code>#[program]</code>, which marks program entrypoints. The template contains:</p><pre><code>#[program]pub mod usdt_clone &#123;    use super::*;    pub fn initialize(ctx: Context&lt;Initialize&gt;) -&gt; Result&lt;()&gt; &#123;   // delete        msg!(&quot;Greetings from: &#123;:?&#125;&quot;, ctx.program_id);             // delete        Ok(())                                                    // delete    &#125;                                                             // delete&#125;</code></pre><p>Remove <code>initialize</code> and add:</p><pre><code>pub fn init_mint(ctx: Context&lt;InitMint&gt;, decimals: u8) -&gt; Result&lt;()&gt; &#123;    let mint = &amp;mut ctx.accounts.mint;    mint.decimals = decimals;    mint.mint_authority = ctx.accounts.authority.key();    Ok(())&#125;</code></pre><p>Place <code>init_mint</code> where <code>initialize</code> was. Ignoring the macros, it’s a normal Rust function. <code>Context</code> is provided by Anchor (even though we didn’t define it), and <code>InitMint</code> is the type we created earlier.</p><p>The first parameter specifies the authority; the second (<code>u8</code>) is the token precision. It returns <code>()</code>: success returns nothing; errors bubble up.</p><p>Inside, we assign to <code>mint</code>, which is a deserialized, mutable account from <code>ctx.accounts</code>. Because it’s a mutable reference, updating it persists the data on-chain.</p><h3 id="7-Unit-tests"><a href="#7-Unit-tests" class="headerlink" title="7. Unit tests"></a>7. Unit tests</h3><p>Compile first to ensure you didn’t miss anything—Rust is strict and may produce warnings:</p><pre><code>anchor build  </code></pre><p>Then edit <code>usdt_clone/tests/usdt_clone.ts</code> and paste:</p><pre><code>import anchor from &quot;@coral-xyz/anchor&quot;;import &#123; Program &#125; from &quot;@coral-xyz/anchor&quot;;import &#123; SystemProgram, Keypair &#125; from &quot;@solana/web3.js&quot;;import &#123; assert &#125; from &quot;chai&quot;;const &#123; AnchorProvider, BN &#125; = anchor;describe(&quot;usdt_clone / init_mint&quot;, () =&gt; &#123;  const provider = AnchorProvider.env();  anchor.setProvider(provider);  const program = anchor.workspace.UsdtClone as Program;  const mintKey = Keypair.generate();  it(&quot;creates a Mint with correct metadata&quot;, async () =&gt; &#123;    const txSig = await program.methods      .initMint(new BN(6))      .accounts(&#123;        mint: mintKey.publicKey,        authority: provider.wallet.publicKey,        systemProgram: SystemProgram.programId,      &#125;)      .signers([mintKey])      .rpc();    console.log(&quot;tx:&quot;, txSig);    const mintAccount = await program.account.mint.fetch(mintKey.publicKey);    assert.equal(mintAccount.decimals, 6);    assert.equal(      mintAccount.mintAuthority.toBase58(),      provider.wallet.publicKey.toBase58()    );  &#125;);&#125;);</code></pre><p>This uses the local test framework to call <code>initMint</code>, e.g., setting 6 decimals and supplying the 3 accounts that <code>InitMint</code> requires. It logs <code>txSig</code>, then reads <code>program.account.mint.fetch</code> and asserts the values.</p><p>Run the tests:</p><pre><code>anchor test</code></pre><p>If all goes well you’ll see <code>1 passing (460ms)</code>.</p><h3 id="8-Open-account-amp-transfer"><a href="#8-Open-account-amp-transfer" class="headerlink" title="8. Open account &amp; transfer"></a>8. Open account &amp; transfer</h3><p>Building on what we’ve learned, add two more account structs for opening an account and transferring. The new macro <code>#[error_code]</code> defines an enum for program errors:</p><pre><code>#[derive(Accounts)]pub struct InitTokenAccount&lt;&#39;info&gt; &#123;    #[account(init, payer = owner, space = 8 + 32 + 8)]    pub token: Account&lt;&#39;info, TokenAccount&gt;,    #[account(mut, signer)]    pub owner: Signer&lt;&#39;info&gt;,    pub system_program: Program&lt;&#39;info, System&gt;,&#125;#[derive(Accounts)]pub struct Transfer&lt;&#39;info&gt; &#123;    #[account(mut, has_one = owner)]    pub from: Account&lt;&#39;info, TokenAccount&gt;,    #[account(mut)]    pub to: Account&lt;&#39;info, TokenAccount&gt;,    #[account(signer)]    pub owner: Signer&lt;&#39;info&gt;,&#125;#[error_code]pub enum ErrorCode &#123;    InsufficientFunds,    ArithmeticOverflow,&#125;</code></pre><p>Add two methods for opening and transferring. Note <code>token.balance = 1000</code> grants a default balance of 1000 upon opening—this simplifies tests and can be changed as you like:</p><pre><code>pub fn init_token_account(ctx: Context&lt;InitTokenAccount&gt;) -&gt; Result&lt;()&gt; &#123;  let token = &amp;mut ctx.accounts.token;  token.owner = ctx.accounts.owner.key();  token.balance = 1000;  Ok(())&#125;pub fn transfer(ctx: Context&lt;Transfer&gt;, amount: u64) -&gt; Result&lt;()&gt; &#123;  let from = &amp;mut ctx.accounts.from;  let to   = &amp;mut ctx.accounts.to;  require!(from.balance &gt;= amount, ErrorCode::InsufficientFunds);  from.balance -= amount;  to.balance = to      .balance      .checked_add(amount)      .ok_or(ErrorCode::ArithmeticOverflow)?;  Ok(())&#125;</code></pre><p>Unit tests:</p><pre><code>const tokenA = Keypair.generate();const tokenB = Keypair.generate();it(&quot;initializes tokenA &amp; tokenB, each with balance 1000&quot;, async () =&gt; &#123;  for (const tok of [tokenA, tokenB]) &#123;    await program.methods      .initTokenAccount()      .accounts(&#123;        token: tok.publicKey,        owner: provider.wallet.publicKey,        systemProgram: SystemProgram.programId,      &#125;)      .signers([tok])      .rpc();    const acc = await program.account.tokenAccount.fetch(tok.publicKey);    assert.equal(      acc.owner.toBase58(),      provider.wallet.publicKey.toBase58()    );    assert.equal(acc.balance.toNumber(), 1000);  &#125;&#125;);it(&quot;transfers 250 from A to B (balances 750 / 1250)&quot;, async () =&gt; &#123;  await program.methods    .transfer(new BN(250))    .accounts(&#123;      from:  tokenA.publicKey,      to:    tokenB.publicKey,      owner: provider.wallet.publicKey,    &#125;)    .rpc();  const a = await program.account.tokenAccount.fetch(tokenA.publicKey);  const b = await program.account.tokenAccount.fetch(tokenB.publicKey);  assert.equal(a.balance.toNumber(), 750);  assert.equal(b.balance.toNumber(), 1250);&#125;);</code></pre><p>If you’re curious, try deploying this program to devnet as well and calling it via the SDK.</p><p><br><br></p><h2 id="Development-Tutorial-3"><a href="#Development-Tutorial-3" class="headerlink" title="Development-Tutorial-3"></a>Development-Tutorial-3</h2><p>You may have noticed that describing business logic is relatively lightweight, while <code>#[account]</code> types and their parameters (auto-creating accounts, how many bytes to rent, etc.) are the tricky bits. Because all account data must fit into node memory—and memory is expensive—Solana requires careful sizing. The account model is also a bit complex.</p><h3 id="1-Issue-a-token-via-CLI"><a href="#1-Issue-a-token-via-CLI" class="headerlink" title="1. Issue a token via CLI"></a>1. Issue a token via CLI</h3><p>For USDT-like scenarios, Solana provides library functions and even CLI tools. You can issue tokens without writing a program. Tokens are called SPL Tokens. To create a 6-decimal SPL token (no token name needed):</p><pre><code>spl-token create-token --decimals 6</code></pre><p>The output includes an <code>Address</code>, the token mint address. For example, mine was <code>E75GMXAfJ91XuRboSpjwkDmta45Etgt3F3Gf5WLZvLbV</code> (view it in the <a href="https://explorer.solana.com/address/E75GMXAfJ91XuRboSpjwkDmta45Etgt3F3Gf5WLZvLbV?cluster=devnet">explorer</a>).</p><p>Next, create an Associated Token Account (ATA) for your local wallet for this token. This is like instantiating a record in the token program that tracks your balance. Without it, the token program doesn’t “know” you.</p><p>“Account” here can be confusing: you already have a wallet address visible via <code>solana address</code>, so why create an ATA in the token program? Think of the program maintaining a <code>map&#123;&#125;</code>; creating an ATA inserts a key&#x2F;value where the key is your wallet address and the value is your token balance. If there’s no entry, you can’t even receive transfers.</p><p>Why require pre-creation? Because on Solana, on-chain space is scarce and must be paid for. Creating an ATA reserves 165 bytes. You can estimate rent with <code>solana rent 165</code>, e.g., <code>0.00203928 SOL</code>. Beyond the transaction fee, you pay this rent when creating the ATA. Hence the explicit creation step.</p><p>Create the ATA:</p><pre><code>spl-token create-account E75GMXAfJ91XuRboSpjwkDmta45Etgt3F3Gf5WLZvLbV</code></pre><p>You’ll see <code>Creating account</code> followed by the ATA address, e.g., <code>E5XmcEJhhGUri8itThLGk8QfPzY1acFid8JmVyo5DWUo</code> (also visible in the <a href="https://explorer.solana.com/address/E5XmcEJhhGUri8itThLGk8QfPzY1acFid8JmVyo5DWUo?cluster=devnet">explorer</a>).</p><p>Note that ATAs have their own addresses. If your wallet is <code>a</code>, your USDT ATA might be <code>b</code>. Receiving and sending USDT uses the ATA, not your base wallet. SPL Token CLI can show the mapping:</p><pre><code>spl-token address --verbose --token E75GMXAfJ91XuRboSpjwkDmta45Etgt3F3Gf5WLZvLbV// output looks likeWallet address: 75sFifxBt7zw1YrDfCdPjDCGDyKEqLWrBarPCLg6PHwbAssociated token address: E5XmcEJhhGUri8itThLGk8QfPzY1acFid8JmVyo5DWUo</code></pre><p>Now check your USDT balance. The <code>balance</code> parameter takes the mint (token) address, not the ATA:</p><pre><code>spl-token balance E75GMXAfJ91XuRboSpjwkDmta45Etgt3F3Gf5WLZvLbV </code></pre><p>It’ll be 0 by default. Mint some tokens. The command has 3 parameters: mint address, amount, and ATA (who to mint to):</p><pre><code>spl-token mint E75GMXAfJ91XuRboSpjwkDmta45Etgt3F3Gf5WLZvLbV 5 E5XmcEJhhGUri8itThLGk8QfPzY1acFid8JmVyo5DWUo</code></pre><p>After success, you can query the balance or view it in the explorer. To transfer:</p><pre><code>spl-token transfer &lt;MINT&gt; 1 &lt;ATA&gt;</code></pre><p>For convenience, the last parameter can be a wallet address instead of an ATA (the CLI derives the ATA), which is why wallets feel like “there is no ATA”:</p><pre><code>spl-token transfer &lt;MINT&gt; 1 &lt;RECIPIENT_WALLET&gt;</code></pre><h3 id="2-Write-a-program-using-the-SPL-library"><a href="#2-Write-a-program-using-the-SPL-library" class="headerlink" title="2. Write a program using the SPL library"></a>2. Write a program using the SPL library</h3><p>Let’s call SPL library functions from a program. These system-level libraries are audited and safer than rolling your own. With them, you can focus on business logic rather than low-level details like precision math. Create a new project:</p><pre><code>anchor init usdt_spl</code></pre><p>Add the <code>anchor-spl</code> dependency. This pulls the latest version. After running it, <code>programs/usdt_spl/Cargo.toml</code> should include <code>anchor-spl = &quot;0.31.1&quot;</code> under <code>[dependencies]</code>:</p><pre><code>cargo add anchor-spl</code></pre><p>Start coding. First import SPL types. Previously we used Anchor types like <code>Account</code> and <code>Signer</code>. SPL also provides types—for example, <code>TokenAccount</code> represents an ATA:</p><pre><code>use anchor_spl::token::&#123;self, MintTo, Token, TokenAccount, Mint&#125;;</code></pre><p>Define the accounts for a mint-to operation:</p><pre><code>#[derive(Accounts)]pub struct MintToCtx&lt;&#39;info&gt; &#123;    #[account(mut)]    pub mint: Account&lt;&#39;info, Mint&gt;,     #[account(mut)]    pub to:   Account&lt;&#39;info, TokenAccount&gt;,    #[account(mut)]    pub authority: Signer&lt;&#39;info&gt;,    pub token_program: Program&lt;&#39;info, Token&gt;,&#125;</code></pre><p><code>mut</code> means data is writable. <code>Account</code> is the Anchor wrapper we’ve used. <code>Mint</code> here is from SPL—we no longer define our own <code>Mint</code> struct. Similarly, <code>TokenAccount</code> and <code>Token</code> are SPL types. Looks simpler, right? Not so fast—one more piece:</p><pre><code>impl&lt;&#39;info&gt; From&lt;&amp;MintToCtx&lt;&#39;info&gt;&gt; for CpiContext&lt;&#39;_, &#39;_, &#39;_, &#39;info, MintTo&lt;&#39;info&gt;&gt;&#123;    fn from(accts: &amp;MintToCtx&lt;&#39;info&gt;) -&gt; Self &#123;        let cpi_accounts = MintTo &#123;            mint:      accts.mint.to_account_info(),            to:        accts.to.to_account_info(),            authority: accts.authority.to_account_info(),        &#125;;        CpiContext::new(accts.token_program.to_account_info(), cpi_accounts)    &#125;&#125;</code></pre><p>This Rust <code>From</code> impl converts <code>&amp;MintToCtx&lt;&#39;info&gt;</code> into <code>CpiContext&lt;..., MintTo&lt;&#39;info&gt;&gt;</code>. CPI stands for Cross-Program Invocation—packaging the target program and accounts into a single structure. The last generic, <code>MintTo</code>, is the SPL type we’ll pass.</p><p>Why an “external program”? Because SPL Token isn’t just types—it’s an already-deployed on-chain program. Using SPL crates essentially calls those deployed programs. When your program runs and you invoke SPL, it finds the SPL program and executes logic there, returning results. In other words, programs across the network share the same SPL implementation.</p><p>Finally, the <code>#[program]</code> method:</p><pre><code>pub fn mint_to(ctx: Context&lt;MintToCtx&gt;, amount: u64) -&gt; Result&lt;()&gt; &#123;    token::mint_to((&amp;*ctx.accounts).into(), amount)&#125;</code></pre><h3 id="3-Build-the-program"><a href="#3-Build-the-program" class="headerlink" title="3. Build the program"></a>3. Build the program</h3><p>You’ll hit a compile error unless you enable features in <code>programs/usdt_spl/Cargo.toml</code>:</p><pre><code>[features]idl-build = [&quot;anchor-lang/idl-build&quot;, &quot;anchor-spl/idl-build&quot;][dependencies]anchor-spl  = &#123; version = &quot;0.31.1&quot;, features = [&quot;token&quot;, &quot;idl-build&quot;] &#125;</code></pre><p>Static builds won’t include SPL by default; the config above enables it. Now build:</p><pre><code>anchor build</code></pre><h3 id="4-Write-tests"><a href="#4-Write-tests" class="headerlink" title="4. Write tests"></a>4. Write tests</h3><p>Install SPL-related Node.js deps. Tests are in TypeScript:</p><pre><code>npm i @coral-xyz/anchor@^0.31 @solana/spl-token chai</code></pre><p>Paste into <code>tests/usdt_spl.ts</code>:</p><pre><code>import anchor from &quot;@coral-xyz/anchor&quot;;import &#123; Program &#125; from &quot;@coral-xyz/anchor&quot;;import &#123;  createMint,  createAssociatedTokenAccount,  getAccount,  TOKEN_PROGRAM_ID,&#125; from &quot;@solana/spl-token&quot;;import &#123; assert &#125; from &quot;chai&quot;;const &#123; AnchorProvider, BN &#125; = anchor;describe(&quot;usdt_spl / mint_to&quot;, () =&gt; &#123;  const provider = AnchorProvider.env();  anchor.setProvider(provider);  const program = anchor.workspace.UsdtSpl as Program;  let mintPubkey: anchor.web3.PublicKey;  let ata: anchor.web3.PublicKey;  it(&quot;creates mint, mints 1 USDT into ATA&quot;, async () =&gt; &#123;    mintPubkey = await createMint(      provider.connection,      provider.wallet.payer,          // fee-payer      provider.wallet.publicKey,      // mint authority      null,                           // freeze authority      6                               // decimals    );    ata = await createAssociatedTokenAccount(      provider.connection,      provider.wallet.payer,          // fee-payer      mintPubkey,      provider.wallet.publicKey       // owner    );    await program.methods      .mintTo(new BN(1_000_000))      // 1 USDT      .accounts(&#123;        mint: mintPubkey,        to: ata,        authority: provider.wallet.publicKey,        tokenProgram: TOKEN_PROGRAM_ID,      &#125;)      .rpc();    const accInfo = await getAccount(provider.connection, ata);    assert.equal(accInfo.amount.toString(), &quot;1000000&quot;);  &#125;);&#125;);</code></pre><p>Run tests:</p><pre><code>anchor test</code></pre><h3 id="5-Deploy-to-devnet"><a href="#5-Deploy-to-devnet" class="headerlink" title="5. Deploy to devnet"></a>5. Deploy to devnet</h3><p>Ensure you have enough SOL, then:</p><pre><code>anchor deploy --provider.cluster devnet </code></pre><p>Sometimes you’ll hit <code>Operation timed out</code>. You can pass your own RPC URL (wrap long URLs in quotes):</p><pre><code>anchor deploy --provider.cluster &quot;&lt;your-rpc-url&gt;&quot;</code></pre><p>Network issues can also leave partial buffers locally or on-chain. To bypass such states, try:</p><pre><code>solana program deploy \  target/deploy/usdt_spl.so \  --program-id target/deploy/usdt_spl-keypair.json \  --url &quot;&lt;your-rpc-url&gt;&quot;</code></pre><p>This is often more reliable. Without <code>--program-id</code>, it generates a new keypair and deploys to a new address—choose based on your needs. After success, check the <a href="https://explorer.solana.com/address/CFXzAhGKEz7tSFdNcVeCX8HosFGYczD7rZyD4vwoWozY?cluster=devnet">explorer</a>.</p><h3 id="6-Call-the-on-chain-program-via-SDK"><a href="#6-Call-the-on-chain-program-via-SDK" class="headerlink" title="6. Call the on-chain program via SDK"></a>6. Call the on-chain program via SDK</h3><p>Let’s use the SDK again. Edit <code>app/app.js</code> and paste:</p><pre><code>/* scripts/mint_to.js   (CommonJS) */const anchor = require(&quot;@coral-xyz/anchor&quot;);const &#123;  createMint,  createAssociatedTokenAccount,  getAccount,  TOKEN_PROGRAM_ID,&#125; = require(&quot;@solana/spl-token&quot;);const fs   = require(&quot;fs&quot;);const os   = require(&quot;os&quot;);const path = require(&quot;path&quot;);const &#123; Keypair, Connection, PublicKey &#125; = anchor.web3;const RPC_URL = process.env.RPC_URL || &quot;https://api.devnet.solana.com&quot;;const connection = new Connection(RPC_URL, &#123; commitment: &quot;confirmed&quot; &#125;);const secret = Uint8Array.from(  JSON.parse(fs.readFileSync(path.join(os.homedir(), &quot;.config/solana/id.json&quot;))));const wallet = new anchor.Wallet(Keypair.fromSecretKey(secret));const provider = new anchor.AnchorProvider(connection, wallet, &#123;  preflightCommitment: &#39;confirmed&#39;,&#125;);anchor.setProvider(provider);const idl  = JSON.parse(fs.readFileSync(path.resolve(&quot;target/idl/usdt_spl.json&quot;)));const prog = new anchor.Program(idl, provider);(async () =&gt; &#123;  const mint = await createMint(connection, wallet.payer, wallet.publicKey, null, 6);  const ata  = await createAssociatedTokenAccount(connection, wallet.payer, mint, wallet.publicKey);  const sig = await prog.methods    .mintTo(new anchor.BN(1_000_000))    .accounts(&#123; mint, to: ata, authority: wallet.publicKey, tokenProgram: TOKEN_PROGRAM_ID &#125;)    .rpc();  console.log(&quot;tx:&quot;, sig);  console.log(`explorer: https://explorer.solana.com/tx/$&#123;sig&#125;?cluster=devnet`);  const bal = await getAccount(connection, ata);  console.log(&quot;balance:&quot;, bal.amount.toString());&#125;)();</code></pre><p>If everything works, you’ll see:</p><pre><code>~/work/github/sol_contract/usdt_spl main ❯ node app/app.jstx: 3MgHxsfnJp68mrrABvCh9iwNm6MSXp1SEvk7vDYHoW7KhTEHfVNyMWsbfbEAXTC9gLzcmWu5xbkzia8hgZrcZ18iexplorer: https://explorer.solana.com/tx/3MgHxsfnJp68mrrABvCh9iwNm6MSXp1SEvk7vDYHoW7KhTEHfVNyMWsbfbEAXTC9gLzcmWu5xbkzia8hgZrcZ18i?cluster=devnetbalance: 1000000</code></pre>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;This is a beginner-friendly series that teaches Solana smart contract development from the ground up. It has 3 parts:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a</summary>
        
      
    
    
    
    
    <category term="Tutorial" scheme="https://en.smallyu.net/tags/Tutorial/"/>
    
    <category term="Smart Contracts" scheme="https://en.smallyu.net/tags/Smart-Contracts/"/>
    
  </entry>
  
  <entry>
    <title>Beware of Tantin Technology and Its Products</title>
    <link href="https://en.smallyu.net/2025/05/15/Beware%20of%20Tantin%20Technology%20and%20Its%20Products/"/>
    <id>https://en.smallyu.net/2025/05/15/Beware%20of%20Tantin%20Technology%20and%20Its%20Products/</id>
    <published>2025-05-15T12:37:11.000Z</published>
    <updated>2025-08-08T08:18:35.753Z</updated>
    
    <content type="html"><![CDATA[<p>Over the past month, I worked at a company called <a href="https://www.tantin.com/">Tantin Chain</a> as a backend wallet developer. During my time there, I was mainly responsible for developing a transaction aggregation service. The core function of this service is to receive client requests, query transaction record information for the requested address from data sources, process the data into a business-defined format, and return the result. </p><p>Because it involves multiple chains, multiple data sources, and processing three types of transactions for each address—regular transactions, ERC-20 transactions, and internal transactions—while also handling Redis caching, a dedicated aggregation service was needed. </p><p>This service currently supports four data sources: Ankr, Quick Node, Blockscout, and Etherscan. The full source code is open-sourced here: <a href="https://github.com/smallyunet/tx-aggregator">smallyunet&#x2F;tx-aggregator</a></p><p>This company has close ties with Coinstore. Initially, some of the early employees were borrowed from Coinstore. Later, after forming a new team through external recruitment, the Coinstore staff returned to their original positions. Two new teams were formed, mainly responsible for developing three product lines: public chain, cross-chain bridge, and wallet. After a month of development, we had planned to launch and release the first official version today. But for some unknown reason, the company laid off all employees from both teams—on the same day as the scheduled launch.</p><p>Back to my own work: this transaction aggregation service is actually quite simple—it only took about one or two weeks to develop. The rest of the time was spent on polishing: optimizing environment configurations, writing unit and integration tests, adding documentation, improving code structure… I must say, the work during this time was quite enjoyable. I haven’t had such a relaxing job in the past two years. The team atmosphere was also great—fun and lively. Having been immersed in serious blockchain tech for so long, switching to regular backend development for a while was a refreshing change of pace.</p><br><h3 id="Reminder-2025-05-22"><a href="#Reminder-2025-05-22" class="headerlink" title="Reminder (2025.05.22)"></a>Reminder (2025.05.22)</h3><p>After some investigation, Tantin Chain’s Chinese name is 天体链, and its sister department is Tantin Exchange (TTX), known in Chinese as 天体交易所. TTX was previously called ttsmart, and it issued a token named CTC.</p><p>A word of caution: this company originated in Cambodia and recently established an office in Singapore. It has a deeply rooted background in pyramid schemes and has a history of disappearing with funds. Traces of this information can be found online. Everyone should avoid using Tantin’s products to prevent potential losses of personal assets. </p><p>The company recruits under the name Tantin Technology. Industry professionals should also be cautious and avoid joining this company. If any issues arise on the user side, there could be associated liabilities.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Over the past month, I worked at a company called &lt;a href=&quot;https://www.tantin.com/&quot;&gt;Tantin Chain&lt;/a&gt; as a backend wallet developer.</summary>
        
      
    
    
    
    
    <category term="Work" scheme="https://en.smallyu.net/tags/Work/"/>
    
    <category term="Unemployment" scheme="https://en.smallyu.net/tags/Unemployment/"/>
    
  </entry>
  
  <entry>
    <title>Want to Develop a Minimal EVM Virtual Machine</title>
    <link href="https://en.smallyu.net/2025/05/11/Want%20to%20Develop%20a%20Minimal%20EVM%20Virtual%20Machine/"/>
    <id>https://en.smallyu.net/2025/05/11/Want%20to%20Develop%20a%20Minimal%20EVM%20Virtual%20Machine/</id>
    <published>2025-05-10T17:15:07.000Z</published>
    <updated>2025-08-06T10:55:09.744Z</updated>
    
    <content type="html"><![CDATA[<p>I’ve named this project echoevm.com. The main goal is to start from the simplest stack operations and gradually build a complete Ethereum bytecode execution environment.</p><p>Why choose this direction? Let’s analyze the technical modules of an Ethereum client:</p><ol><li>RPC: A GRPC wrapper? The focus is more on protocol design than technical implementation.</li><li>P2P: There’s an existing libp2p available — it’s mostly about node discovery and routing tables, maybe dig into Kademlia DHT?</li><li>Account system: ECDSA? Cryptography?</li><li>Transaction pool: Transaction analysis, sealed transactions, MEV protection directions.</li><li>Consensus mechanism: The design of consensus mechanisms belongs in the research realm — typically PhD-level research in labs, publishing papers, producing test data to prove cutting-edge optimizations, and finally securing funding to hire engineers for implementation.</li><li>Storage: Experts in database internals are useful anywhere; it’s not specific to blockchain.</li><li>Data structures: Study the implementation of Merkle Patricia Trees?</li><li>State synchronization: Light client direction — for example, using Celestia’s core tech to separate execution from storage, or offloading Archive node data?</li></ol><p>Overall, I lean toward doing something engineering-focused rather than academic, yet still technically challenging. It should be meaningful both for personal technical growth and for the potential outcomes. If this minimal EVM is successfully developed, it can lead to a series of follow-up achievements, and many valuable products can be built on top of it.</p><p>The conversion from Solidity to bytecode is compiler expert territory. What I aim to do is execute the bytecode — starting with the simplest operations like addition and jump, then move on to gas calculation, context switching, and ultimately be able to execute all historical Ethereum transactions.</p><br><h3 id="v0-0-2-2025-06-09"><a href="#v0-0-2-2025-06-09" class="headerlink" title="v0.0.2 (2025.06.09)"></a>v0.0.2 (2025.06.09)</h3><p>This version adds the ability to run runtime bytecode, meaning you can first deploy a contract and then call the deployed contract’s functions with specific parameters. For example:</p><pre><code>go run ./cmd/echoevm -bin ./build/Add.bin -function &#39;add(uint256,uint256)&#39; -args &quot;3,5&quot;</code></pre><p>This command executes the bytecode from the <code>./build/Add.bin</code> file and calls the <a href="https://github.com/smallyunet/echoevm/blob/v0.0.2/test/contracts/Add.sol#L7">add function</a>, passing in the arguments 3 and 5. After the program completes, it will return the computation result, which is 8.</p><br><h3 id="v0-0-1-2025-05-27"><a href="#v0-0-1-2025-05-27" class="headerlink" title="v0.0.1 (2025.05.27)"></a>v0.0.1 (2025.05.27)</h3><p>Implemented a very simple version. Now you can use <code>solc</code> to compile an <a href="https://github.com/smallyunet/echoevm/blob/v0.0.1/test/contracts/Add.sol">Add.sol</a> contract, and then have <code>echoevm</code> read the generated <code>Add.bin</code> deployment code, which will output the contract’s runtime code after deployment.</p><p>During the implementation of this version, I learned the difference between deployment code and runtime code. Typically, we first deploy a contract to the blockchain and then make calls to it. These are actually two different operations, but both use the same EVM execution. The EVM doesn’t care whether the input bytecode is for deployment or invocation; it simply handles different opcodes differently. Deployment code generally includes both the <code>CODECOPY</code> and <code>RETURN</code> opcodes, which can be used to distinguish the type of input.</p><br><h3 id="v0-0-2-2025-06-09-1"><a href="#v0-0-2-2025-06-09-1" class="headerlink" title="v0.0.2 (2025-06-09)"></a>v0.0.2 (2025-06-09)</h3><p>This version adds the ability to run runtime bytecode—that is, first deploy the contract and then call its functions, optionally passing parameters. For example:</p><pre><code>go run ./cmd/echoevm -bin ./build/Add.bin -function &#39;add(uint256,uint256)&#39; -args &quot;3,5&quot;</code></pre><p>This command executes the bytecode in <code>./build/Add.bin</code>, calls the <a href="https://github.com/smallyunet/echoevm/blob/v0.0.2/test/contracts/Add.sol#L7">add function</a> with arguments 3 and 5, and returns 8 when the program finishes.</p><br><h3 id="v0-0-3-2025-06-24"><a href="#v0-0-3-2025-06-24" class="headerlink" title="v0.0.3 (2025-06-24)"></a>v0.0.3 (2025-06-24)</h3><p>Good news—echoevm can now execute contract transactions in the first 10 000 blocks of the Ethereum mainnet! (Because there were no contract transactions in those early blocks :P)</p><p>This release introduces block-execution mode: you can run a single block or a range of blocks. You’ll need a URL that serves block data; for early Ethereum blocks, be sure to use an archive-mode node. The full command looks like this:</p><pre><code>echoevm -start-block 0 -end-block 10000 -rpc &lt;url&gt;</code></pre><p>echoevm’s bytecode support is still limited. Running more recent blocks may raise errors about unsupported opcodes; that’s expected.</p><br><h3 id="v0-0-4-2025-07-05"><a href="#v0-0-4-2025-07-05" class="headerlink" title="v0.0.4 (2025-07-05)"></a>v0.0.4 (2025-07-05)</h3><p>This version adds the ability to read bytecode directly from an artifact file—the JSON artifact generated by a Hardhat project when it compiles. Earlier versions could only read the binary file produced by <code>solc</code>. Previously, you’d compile and run like this:</p><pre><code># Compile the contract to produce bytecodenpx --yes solc --bin Add.sol -o ./build# Run echoevm to execute the bytecodego run ./cmd/echoevm run -bin ./test/bins/build/Add_sol_Add.bin -function &quot;add(uint256,uint256)&quot; -args &quot;1,2&quot;</code></pre><p>Now it’s simpler. For a standard <a href="https://github.com/smallyunet/echoevm/tree/v0.0.4/test/contract">Hardhat project</a>, every compile creates an artifact file, and echoevm can read the JSON directly:</p><pre><code># Compile the Hardhat project’s contractsnpx hardhat compile# (Optional) run the project’s testsnpx hardhat test# Run echoevm to execute the bytecodego run ./cmd/echoevm run -artifact ./test/contract/artifacts/contracts/Add.sol/Add.json -function &quot;add(uint256,uint256)&quot; -args &quot;1,2&quot;</code></pre><p>This release also adds support for more opcodes, but it’s still not enough to execute a full Ethereum block. Next we’ll add test cases incrementally by Solidity feature and examine missing opcodes—hence the focus on execution improvements in this version.</p><br><h3 id="v0-0-5-2025-07-27"><a href="#v0-0-5-2025-07-27" class="headerlink" title="v0.0.5 (2025-07-27)"></a>v0.0.5 (2025-07-27)</h3><p>This is a minor release that adds a comprehensive set of <a href="https://github.com/smallyunet/echoevm/tree/v0.0.5/test/contract/contracts">Solidity contracts</a> as test cases, covering basic data types, functions, control flow, modifiers, events, interfaces, libraries, inline assembly, and other Solidity features.</p><p>A handy command is provided; run it from the project root to see all the test results:</p><pre><code>make test-advanced</code></pre><p>All tests pass. However, echoevm still can’t execute Ethereum mainnet block 10 000 000, indicating the missing opcodes aren’t part of Solidity’s core syntax—they must come from elsewhere.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;I’ve named this project echoevm.com. The main goal is to start from the simplest stack operations and gradually build a complete</summary>
        
      
    
    
    
    
    <category term="Plan" scheme="https://en.smallyu.net/tags/Plan/"/>
    
    <category term="EVM" scheme="https://en.smallyu.net/tags/EVM/"/>
    
  </entry>
  
  <entry>
    <title>Design of a ZK-Based On-Chain Identity System</title>
    <link href="https://en.smallyu.net/2025/04/30/Design%20of%20a%20ZK-Based%20On-Chain%20Identity%20System/"/>
    <id>https://en.smallyu.net/2025/04/30/Design%20of%20a%20ZK-Based%20On-Chain%20Identity%20System/</id>
    <published>2025-04-30T14:18:54.000Z</published>
    <updated>2025-08-09T09:05:26.061Z</updated>
    
    <content type="html"><![CDATA[<p>I’ve named this system <strong>zkgate.fun</strong>, aiming to leverage the features of zero-knowledge proofs in combination with blockchain to create a small tool. The key function is to allow users to prove they belong to a certain group without revealing their real on-chain identity.</p><p>Here’s the current idea: the administrator starts with a list of addresses (e.g., an array of Ethereum addresses), then calculates a Merkle Root Hash based on this list and submits it to a smart contract. Individuals in the list can use a Circom circuit’s proving key to generate a zk proof for themselves, and then submit this zk proof to the smart contract.</p><p>The smart contract will use the <code>verifier.sol</code> generated from the Circom circuit to verify the zk proof and determine whether the address used to generate the proof is included in the Merkle Root Hash. The result of this verification is then returned.</p><p>With this approach, the admin doesn’t need to publicly disclose the addresses in the group, and the addresses within the group also don’t need to declare their identity. They just need to submit the zk proof generated using zero-knowledge proof to prove their membership in the group. I’ll proceed to implement this technically.</p><br><h3 id="Update-v0-1-0-2025-05-09"><a href="#Update-v0-1-0-2025-05-09" class="headerlink" title="Update v0.1.0 (2025.05.09)"></a>Update v0.1.0 (2025.05.09)</h3><p>First, a correction to the previous design: the administrator <strong>must</strong> publicly disclose the address list of the group. Otherwise, it’s impossible to generate a Merkle Tree, and users can’t locate their address’s position in the tree or generate the necessary path proof.</p><p>On a positive note, a very basic demo now works (<a href="https://github.com/smallyunet/zkgate-demo">smallyunet&#x2F;zkgate-demo</a>). While the demo lacks features (it can’t even verify address ownership in the circuit), it proves the toolchain process.</p><p>The specific implementation steps:</p><ol><li>An <a href="https://github.com/smallyunet/zkgate-demo/blob/v0.1.0/offchain/smt.js">off-chain script</a> generates <a href="https://github.com/smallyunet/zkgate-demo/blob/v0.1.0/offchain/inputs.json">inputs.json</a> from the address list and the user’s own address. This file includes the Merkle Root Hash and path information needed for verification.</li><li>The <a href="https://github.com/smallyunet/zkgate-demo/blob/v0.1.0/circuits/merkleSmtProof.circom">circuit code</a> is compiled into <a href="https://github.com/smallyunet/zkgate-demo/tree/main/circuits/build">binary files</a> used to generate witness files.</li><li>A <code>.zkey</code> file is created using the public <a href="https://github.com/smallyunet/zkgate-demo/blob/v0.1.0/circuits/run.sh#L17-L28">ptau file</a>.</li><li>From the <code>.zkey</code> file, export <a href="https://github.com/smallyunet/zkgate-demo/blob/v0.1.0/circuits/proof.json">proof.json</a>, <a href="https://github.com/smallyunet/zkgate-demo/blob/v0.1.0/circuits/public.json">public.json</a>, and <a href="https://github.com/smallyunet/zkgate-demo/blob/v0.1.0/circuits/verification_key.json">verification_key.json</a>. These three can be used for off-chain verification.</li><li>Export the <a href="https://github.com/smallyunet/zkgate-demo/blob/v0.1.0/circuits/contracts/Groth16Verifier.sol">.sol contract file</a> from the <code>.zkey</code> file and deploy it on-chain.</li><li>Use the contents of <code>prove.json</code> and <code>public.json</code> as <a href="https://github.com/smallyunet/zkgate-demo/blob/v0.1.0/hardhat/scripts/prove.js#L41">parameters</a> to call the contract’s <a href="https://github.com/smallyunet/zkgate-demo/blob/v0.1.0/circuits/contracts/Groth16Verifier.sol"><code>verifyProof</code></a> function. If the proof is valid, it returns <code>true</code>; otherwise, <code>false</code>.</li></ol><p>If an address is not in the group list, there are two cases:</p><ol><li>Attempting to generate <code>inputs.json</code> using an <a href="https://github.com/smallyunet/zkgate-demo/blob/v0.1.0/offchain/smt_non_member.js#L24">unauthorized address</a> will result in an error during proof generation.</li><li>Attempting to submit a fake <a href="https://github.com/smallyunet/zkgate-demo/blob/v0.1.0/hardhat/scripts/fakeProofWithCorrectRoot.js#L26">proof</a> to the contract will fail verification.</li></ol><p>Currently, this primitive demo uses plaintext addresses to build the proof, like:</p><pre><code class="js">const members = [  &quot;0xf39Fd6e51aad88F6F4ce6aB8827279cffFb92266&quot;,  &quot;0x70997970C51812dc3A010C7d01b50e0d17dc79C8&quot;,  &quot;0x3C44CdDdB6a900fa2b585dd299e03d12FA4293BC&quot;,];const proofKey = toField(members[0]);const &#123; siblings &#125; = await tree.find(proofKey);</code></pre><p>This checks whether <code>members[0]</code> is part of the tree built from <code>members</code>. Clearly, it is. To fake it, just replace the address:</p><pre><code class="js">const nonMemberAddress = &quot;0x1234567890123456789012345678901234567890&quot;;const proofKey = toField(nonMemberAddress);const &#123; siblings &#125; = await tree.find(proofKey);</code></pre><p>So the <code>members</code> list must be public, and the current program only checks if an address is in that list. Even if <code>members[0]</code> isn’t my address, I can still use it to build a valid proof. Then what’s the point of zk?</p><p>Next step: require users to <strong>sign a message</strong> with their private key, then recover the address from the signature <strong>inside the zk circuit</strong>, and check if the recovered address is in the members list.</p><p>Sounds simple? In reality, using a zk circuit to recover an address from an ECDSA signature is absurdly complex—like building a nuclear reactor out of Lego. No wonder zk devs are losing their hair.</p><br><h3 id="Update-v0-2-0-2025-05-13"><a href="#Update-v0-2-0-2025-05-13" class="headerlink" title="Update v0.2.0 (2025.05.13)"></a>Update v0.2.0 (2025.05.13)</h3><p>This version solves the problem of address ownership verification. The main idea is to separate the zk proof from the address ownership proof: off-chain zk proves the address’s position in the Merkle Root, while on-chain the user submits a signature of the root using their private key. The contract recovers the address from the signature and compares it with the address in the zk proof.</p><pre><code>1. zk proof includes address info -&gt; on-chain verification reveals address info2. Private key signs root -&gt; signature submitted -&gt; contract recovers address3. Compare zk proof address == recovered address</code></pre><p>Code changes:</p><ol><li>Off-chain code doesn’t need changes — the <a href="https://github.com/smallyunet/zkgate-demo/blob/v0.2.0/offchain/smt.js#L37">inputs</a> already include the key.</li><li>In the circuit code, the key is made <a href="https://github.com/smallyunet/zkgate-demo/blob/v0.2.0/circuits/merkleSmtProof.circom#L27">public</a>.</li><li>The smart contract accepts the <a href="https://github.com/smallyunet/zkgate-demo/blob/v0.2.0/hardhat/contracts/ZkGateRegistry.sol#L38">signature</a>, <a href="https://github.com/smallyunet/zkgate-demo/blob/v0.2.0/hardhat/contracts/ZkGateRegistry.sol#L49">recovers the address</a>, and compares it with the address in the proof.</li><li>The script that calls the contract must <a href="https://github.com/smallyunet/zkgate-demo/blob/v0.2.0/hardhat/scripts/prove.js#L44-L45">sign the root</a> and pass the signature to the contract.</li></ol><p>As of now, <strong>zkgate.fun</strong> allows group admins to only publish a Merkle Root Hash on-chain, keeping the full member list private. Group members just need the full list and a signature from their address’s private key to generate a zk proof and prove their membership.</p><p>The only information not hidden by zk is the user’s address, which must still be submitted for verification.</p><br><h3 id="Update-2025-05-14"><a href="#Update-2025-05-14" class="headerlink" title="Update (2025.05.14)"></a>Update (2025.05.14)</h3><p>There is an existing zk protocol supported by the Ethereum Foundation, with a mature toolchain and ecosystem, called <strong>Semaphore</strong>. Try its demo with a frontend UI here:</p><ul><li><a href="https://semaphore.pse.dev/">https://semaphore.pse.dev/</a></li></ul><p>In the first two versions of zkgate.fun, I avoided using Semaphore’s EdDSA account system, preferring to stick with Ethereum’s native ECDSA. However, only EdDSA is zk-friendly: it can use Poseidon Hash signatures that zk circuits can verify directly—unlike the “off-chain sign, on-chain recover” clumsy approach I used.</p><p>From a learning standpoint, this project taught me how zk toolchains work in just a few days. But from an industry perspective, there’s no way I could outperform Semaphore on my own. Even with a frontend UI and visual interactivity, zkgate.fun would just end up like <a href="https://demo.semaphore.pse.dev/">Semaphore’s Demo</a>, but technically inferior.</p><p>Therefore, I’ve decided to stop developing <strong>zkgate.fun</strong>. The domain will expire in a year and will not be renewed.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;I’ve named this system &lt;strong&gt;zkgate.fun&lt;/strong&gt;, aiming to leverage the features of zero-knowledge proofs in combination with</summary>
        
      
    
    
    
    
    <category term="zk" scheme="https://en.smallyu.net/tags/zk/"/>
    
    <category term="planning" scheme="https://en.smallyu.net/tags/planning/"/>
    
  </entry>
  
  <entry>
    <title>Design of the Web3 Tipping System giveme.wtf</title>
    <link href="https://en.smallyu.net/2025/04/29/About%20the%20Design%20of%20the%20Web3%20Tipping%20System%20giveme.wtf/"/>
    <id>https://en.smallyu.net/2025/04/29/About%20the%20Design%20of%20the%20Web3%20Tipping%20System%20giveme.wtf/</id>
    <published>2025-04-29T11:26:45.000Z</published>
    <updated>2025-08-06T10:38:27.633Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Product-Form"><a href="#Product-Form" class="headerlink" title="Product Form"></a>Product Form</h3><p>giveme.wtf is a domain I just registered, intended as a small Web3 tipping tool. Similar Web2 platforms include:</p><ul><li><a href="https://buymeacoffee.com/">https://buymeacoffee.com/</a></li><li><a href="https://linktr.ee/">https://linktr.ee/</a></li></ul><p>The difference is that the personal page on giveme.wtf will display Web3 wallet receiving addresses and QR codes, much like a personal PayPal payment link. It will support multiple chain address formats including Bitcoin, Ethereum, Dogecoin, etc., and users can choose freely.</p><p>giveme.wtf will not act as an intermediary for funds; it will simply display tipping address information. For example, visiting giveme.wtf&#x2F;{username} will show the receiving address info set up by the user, including Ethereum address text and QR code. That’s it.</p><p>Of course, on giveme.wtf&#x2F;{username}, users can also set a simple bio, avatar, domain, social media, etc., like a small personal homepage, making it more shareable.</p><h3 id="Technical-Implementation"><a href="#Technical-Implementation" class="headerlink" title="Technical Implementation"></a>Technical Implementation</h3><ul><li>Registration</li></ul><p>Users register with a MetaMask wallet. After connecting the wallet, they can set a unique, globally-managed username via a smart contract. This requires a transaction to submit the desired username to the contract.</p><ul><li>Profile Info</li></ul><p>Once the EVM address is bound to the username, users can set their profile info including avatar, bio, wallet addresses, etc.</p><p>After entering the info, the frontend sends it to the backend, which saves it on an IPFS node (pinned for long-term), and returns the CID to the frontend.</p><p>The frontend, after receiving the CID, initiates another contract interaction to write the username-&gt;CID mapping into the smart contract. This step can be combined with registration or kept separate, since users may want to register without setting a profile.</p><ul><li>Display</li></ul><p>The on-chain username-&gt;CID is the authoritative data. The frontend fetches the CID from the contract based on the username in giveme.wtf&#x2F;{username}, then queries the IPFS gateway for the data and renders the page.</p><p>Profiles are minimal JSON data, very small in size. To speed up gateway queries, Cloudflare’s Web3 gateway CDN can be used.</p><ul><li>Network Selection</li></ul><p>The smart contract is deployed on Base.</p><h3 id="Extensions-and-Optimizations"><a href="#Extensions-and-Optimizations" class="headerlink" title="Extensions and Optimizations"></a>Extensions and Optimizations</h3><p>Later, on-chain data can be used to generate statistics like which receiving addresses are using the tipping system, total amount tipped, and make a leaderboard categorized by username or chain.</p><p>Ranking can boost the exposure of the bio under each username. Upvote your idol to keep them at the top.</p><p>We can also add 24-hour leaderboards or competitive ranking formats.</p><p>The system could also be extended into a social network. Tipping history could form relationship graphs, and even evolve into an IM tool with auto group creation, etc.</p><h4 id="Username-Recovery"><a href="#Username-Recovery" class="headerlink" title="Username Recovery"></a>Username Recovery</h4><p>A drawback of MetaMask registration is what happens if a wallet is lost—does that mean username control is lost too? A recovery mechanism can be designed, such as allowing each username to set a list of recovery addresses. Any address in this list can reclaim control and update the CID. This is aimed at lost wallets.</p><p>What if the wallet gets hacked? Wouldn’t the hacker just change the recovery list? Yes, once a hacker has control of the username, they could reinforce it by changing to their own address. Is there a way to regain control after a hack? Not in Web3.</p><h4 id="Network-Selection"><a href="#Network-Selection" class="headerlink" title="Network Selection"></a>Network Selection</h4><p>Currently, a chain must be chosen to deploy the smart contract, which ensures data integrity. Choosing a chain is tricky, as users might not hold tokens on-chain.</p><p>For example, choosing Base requires users to have ETH and also ETH on Base, which can be a big hurdle.</p><p>To solve this, gas fee abstraction can be considered—using a paymaster from ERC-4337 (which has mostly faded), or the older Meta Transaction method. However, we also have to prevent abuse and ensure we can afford to subsidize fees.</p><h4 id="Data-Availability"><a href="#Data-Availability" class="headerlink" title="Data Availability"></a>Data Availability</h4><p>In the MVP, data is stored on IPFS, but there’s only one server. IPFS is a low-level file routing protocol, and we can wrap it with a simpler layer like Filecoin, but less complex due to small data volume. PoST is complex due to encryption&#x2F;decryption for large files, but giveme.wtf’s data is small. We can just verify a Merkle Root Hash, meaning a lightweight verification and incentive system on top of IPFS. Nodes that store full data could receive rewards after periodic checks. Details of rewards are TBD.</p><h4 id="Off-Chain-Data-Caching"><a href="#Off-Chain-Data-Caching" class="headerlink" title="Off-Chain Data Caching"></a>Off-Chain Data Caching</h4><p>Querying username-&gt;CID from the contract every time is slow and uses RPC resources. We should cache this off-chain via a centralized backend that listens to contract events and writes username-&gt;CID to Cloudflare Workers KV.</p><p>Frontend should first query Cloudflare Workers KV, and fallback to the contract if unavailable.</p><p>But what if the centralized service is compromised and changes username-&gt;CID? Funds could be misdirected.</p><p>This is a data integrity problem that Optimistic Rollup also solves. Here’s a possible approach combined with Zetachain’s cross-chain logic.</p><p>First, the off-chain caching service builds a Merkle Tree using all username-&gt;CID data. The resulting Merkle Root Hash is the integrity proof and is regularly submitted on-chain. Frontend checks this root hash on-chain to verify if the cached CID is tampered.</p><p>Also, multiple indexer programs can agree on a TSS key. Only this key can submit Merkle Root Hashes. They will only agree if all their root hashes match—effectively multi-signature.</p><p>Finally, introduce a cool-down + challenge period. After submission, the root hash doesn’t take effect immediately. Anyone can challenge it. If successful, the new root is invalidated, and the old one remains. Designing a reliable challenge mechanism is complex, but it’s something to optimize in the future.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h3 id=&quot;Product-Form&quot;&gt;&lt;a href=&quot;#Product-Form&quot; class=&quot;headerlink&quot; title=&quot;Product Form&quot;&gt;&lt;/a&gt;Product Form&lt;/h3&gt;&lt;p&gt;giveme.wtf is a domain I just</summary>
        
      
    
    
    
    
    <category term="web3" scheme="https://en.smallyu.net/tags/web3/"/>
    
    <category term="Plan" scheme="https://en.smallyu.net/tags/Plan/"/>
    
  </entry>
  
  <entry>
    <title>People Who Hype Cursor Usually Lack Technical Skills</title>
    <link href="https://en.smallyu.net/2025/04/12/People%20Who%20Hype%20Cursor%20Usually%20Lack%20Technical%20Skills/"/>
    <id>https://en.smallyu.net/2025/04/12/People%20Who%20Hype%20Cursor%20Usually%20Lack%20Technical%20Skills/</id>
    <published>2025-04-12T12:33:38.000Z</published>
    <updated>2025-08-06T10:38:27.726Z</updated>
    
    <content type="html"><![CDATA[<p>The title is a bit clickbaity—don’t take it too seriously. What I mean is that we shouldn’t focus too much on the tools we use. It’s simple logic: only when your own engineering skills fall short of what Cursor can do would you think Cursor is amazing and can do everything. Of course, that’s kind of an empty statement.</p><p>In fact, Cursor’s code completion isn’t much better than GitHub Copilot’s. They both use the same underlying models—either Claude or GPT. In terms of engineering fine-tuning, both Cursor and Copilot work by using some files as context for ongoing conversation.</p><p>Cursor is slightly better than Copilot in that it actively searches and references other files in the current project directory. That’s genuinely useful—you don’t have to tell it which files to reference; it tries on its own. Copilot, as a plugin, lacks this ability. That’s definitely a strong point for Cursor. If your project has a lot of reusable code, Cursor can really shine.</p><p>But sometimes Cursor feels overly “smart.” It even creates new files in your project without your consent, which means you have to keep an eye on whether it’s modifying files you didn’t intend to change. In contrast, Copilot (in GoLand) is just a plugin that offers code suggestions—you choose whether to use them. Copilot in VS Code now offers a similar experience to Cursor, where it gives you the option to accept or reject changes.</p><p>So in comparison: Cursor and Copilot use the same large language models (nobody really thinks Cursor trained its own model, right?), but Cursor has more control at the project level, while Copilot, true to its name, acts more like an assistant. That’s their biggest difference.</p><p>Now back to the models themselves. o1 is the best model so far—at least from my daily experience. I often use o1 to precisely pinpoint bugs in my code, while other models tend to give incorrect or vague explanations for the same issue, including o3-mini-high and 4o.</p><p>For example, when calling a smart contract, the original command was:</p><pre><code>cast call requestPrice(string) &quot;BTC&quot; —-rpc-url=http://eth:8545</code></pre><p>Later, I needed to call another function that takes one more argument, so I copied the code and changed it to:</p><pre><code>cast call requestPrice(string) &quot;BTC&quot; &quot;USD&quot; —-rpc-url=http://eth:8545</code></pre><p>Did you notice the issue right away? Actually, 4o did give a correct analysis, just not precise—it listed three possible causes. But o1 got it right straight away.</p><p>Of course, differences between models aren’t always this clear-cut—just happened to have this example in mind. What I want to say is, from daily use, o1 is the most reliable model.</p><p>I seriously suspect that the people hyping up Cursor are those who haven’t really used AI before, and only realized how powerful generative AI has become after using Cursor—so they’re thrilled. And when they need generative AI, their first reaction isn’t to open ChatGPT or Gotk3, but to jump into Cursor’s code panel and start chatting.</p><p>So in reality, those hyping Cursor are mistaking the power of generative AI for the power of Cursor itself, which is why they think Cursor is exceptionally good.</p><p>I’ve been strongly recommended Cursor more than once at work, even told to stop using GoLand, with people saying things like “GoLand is trash” and “Cursor is the best.”</p><p>First of all, I’ve always thought that choice of editor is a personal preference—why make a big deal out of it? Second, if people think your choice of editor reflects a hierarchy or sense of superiority, that’s just childish. Lastly, I use GoLand for two simple reasons: 1) the arrows clearly show interface implementation relationships; 2) the forward&#x2F;backward navigation shortcuts are very handy. These two reasons help me quickly understand and follow the code.</p><p>This leads to a difference: people who use GoLand tend to focus more on code logic. When looking for specific parts of code, they prefer jumping through code relationships like interface implementations. On the other hand, Cursor (VS Code) users focus more on the project’s directory structure, filenames, and file locations—because Cursor lacks solid code navigation features, they have to rely on the structure to piece things together.</p><p>As for code autocompletion, GoLand with the Copilot plugin handles everyday needs just fine. Most of the time, what needs completing is something like a log statement. For more complex, logic-heavy code, I’m hesitant to rely on AI.</p><p>Maybe the reason some people recommend Cursor to me is they assume I don’t know how to use AI, or think I don’t know how to use Cursor (?). That’s odd. I tried ChatGPT back in 2023 when it first blew up and even wrote <a href="/2023/03/30/Don't%20Underestimate%20ChatGPT/">Don’t Underestimate ChatGPT</a>. Nowadays, I use ChatGPT all the time—both for work and in life.</p><p>All in all, my point is: it’s totally fine to like Cursor or to use Cursor. Just don’t hype Cursor too much.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;The title is a bit clickbaity—don’t take it too seriously. What I mean is that we shouldn’t focus too much on the tools we use. It’s</summary>
        
      
    
    
    
    
    <category term="AI" scheme="https://en.smallyu.net/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>On Code Review Etiquette</title>
    <link href="https://en.smallyu.net/2025/03/25/On%20Code%20Review%20Etiquette/"/>
    <id>https://en.smallyu.net/2025/03/25/On%20Code%20Review%20Etiquette/</id>
    <published>2025-03-25T13:45:43.000Z</published>
    <updated>2025-08-06T10:38:27.722Z</updated>
    
    <content type="html"><![CDATA[<p>Previously, I recommended two blog posts by Yin Wang:</p><ul><li>“<a href="https://www.yinwang.org/blog-cn/2015/03/03/how-to-respect-a-programmer">How to Respect a Programmer</a>”</li><li>“<a href="https://www.yinwang.org/blog-cn/2015/03/11/git-etiquette">Git Etiquette</a>”</li></ul><p>Due to a lack of standardized practices in my past work experiences, I didn’t have a proper understanding of Code Review. Recently, triggered by a colleague’s emotional remarks on this topic, I started to pay more attention to the issue of Code Review.</p><h3 id="Basic-Etiquette-Don’t-Use-FYI"><a href="#Basic-Etiquette-Don’t-Use-FYI" class="headerlink" title="Basic Etiquette: Don’t Use FYI"></a>Basic Etiquette: Don’t Use FYI</h3><p>Google’s published Code Review guidelines, “<a href="https://google.github.io/eng-practices/review/reviewer/standard.html">The Standard of Code Review</a>,” are extremely instructive and comprehensive. Even the process-related issues I currently encounter can be addressed by following this guideline. Of course, this requires that all team members have first agreed upon and understood this guideline, instead of assuming everyone in the company already knows and follows it.</p><p>The guideline (TSCR) already covers process issues and etiquette, so I won’t repeat them here. What caught my attention is a small section: “<a href="https://google.github.io/eng-practices/review/reviewer/comments.html#label-comment-severity">Label comment severity</a>,” which talks about categorizing the importance of comments in Code Review, using prefixes so the author can clearly understand which comments must be addressed and which are optional.</p><p>Other than mandatory comments (which don’t require a prefix), Google’s guideline lists three types of prefixes — all from the reviewer’s perspective and none of them block approval or merging:</p><ul><li><code>Nit</code> (Nitpick): You should change it, but I can accept it if you don’t.</li><li><code>Optional</code>: Just a suggestion, feel free to decide.</li><li><code>FYI</code> (For Your Information): No changes required for this PR, but I find this point interesting — something you can look into later.</li></ul><p>Every time I see “For Your Information,” I instinctively translate it into a common phrase from traditional Chinese culture: “It’s for your own good.”</p><p>Anyone who grew up in Chinese society — even without harsh parenting — likely understands the weight of this phrase.</p><p>For your own good, you must study hard<br>For your own good, you can’t play games<br>For your own good, you must take the civil service exam<br>For your own good, you should get married early<br>For your own good, you have to have children<br>…</p><p>Sometimes, parents use “for your own good” as an excuse to satisfy their desire to control. Other times, they may sincerely mean well but offer poor advice due to limited vision.</p><p>In short, “for your own good” carries a very negative connotation in Chinese. Bringing such language into the workplace is even more absurd. Although “For Your Information” isn’t literally “for your own good,” to avoid misunderstanding, it’s best to avoid this phrasing altogether.</p><p>So, the basic etiquette of Code Review is: don’t use FYI.</p><h3 id="Why-“For-Your-Own-Good”-Is-Often-Wrong"><a href="#Why-“For-Your-Own-Good”-Is-Often-Wrong" class="headerlink" title="Why “For Your Own Good” Is Often Wrong"></a>Why “For Your Own Good” Is Often Wrong</h3><h4 id="Conclusion-First"><a href="#Conclusion-First" class="headerlink" title="Conclusion First"></a>Conclusion First</h4><p>Because no one can truly understand another person.</p><p>Do parents truly understand their children? Do married couples really know what their partner is thinking? Do police investigators fully grasp the minds of the suspects they question? Can psychology experts guess why their girlfriend is mad in the morning? And most importantly — do you really understand yourself?</p><p>So we can draw a conclusion that has nothing to do with technology: out of courtesy, we should avoid telling others “it’s for your own good.”</p><h4 id="A-Concrete-Example"><a href="#A-Concrete-Example" class="headerlink" title="A Concrete Example"></a>A Concrete Example</h4><p>In a recent project, I submitted code that implemented a simple event bus. Both the event’s Publish and Subscribe functions used RW locks to ensure thread-safe map access:</p><pre><code class="Go">func (eb *EventBus) Publish(event Event) &#123;    eb.mu.RLock()    defer eb.mu.RUnlock()    if ch, exists := eb.channels[event]; exists &#123;        ch &lt;- event    &#125;&#125;</code></pre><p>The Code Review suggestion I received was to use <code>sync.Map</code> instead:</p><pre><code class="Go">func (eb *EventBus) Publish(event Event) &#123;    if ch, ok := eb.channels.Load(event); ok &#123;        // Note: Type assertion needed here        ch.(chan Event) &lt;- event    &#125;&#125;</code></pre><p>At most, this was a Nit-level comment. I wasn’t particularly concerned, and it was easy to deal with.</p><p>The real issue was that I heard something along the lines of “for your own good” — essentially, “for your own good, you need to understand the difference between RW locks, mutexes, and sync.Map, and then choose the best implementation for the event bus scenario and be able to explain it logically to others.”</p><p>From a technical growth perspective, I personally don’t mind this kind of issue. But this kind of thing feels like textbook answers often used in job interviews. As interviews have evolved in recent years, more and more people have grown tired of such rigid, textbook-style questioning.</p><p>Of course, people who obsess over these low-level technical differences likely have a deep passion for technology — and that’s not a bad thing. We should respect all genuine effort and seriousness about technology. But tech has many different dimensions.</p><h4 id="My-Interests"><a href="#My-Interests" class="headerlink" title="My Interests"></a>My Interests</h4><p>Am I someone who has technical passion? Maybe — sometimes. Otherwise, I wouldn’t have quit Fusionist without a backup job, giving up a salary higher than my current one (even including tokens). Whether it’s tech or anything else, all of us want to chase things we find interesting.</p><p>From my past experiences, here are some tech topics I care about and enjoy exploring just out of curiosity:</p><ul><li><p>What’s the fundamental difference between PoW and PoS? Is PoW better than PoS?</p><ul><li>“<a href="/2024/04/14/Why%20PoW%20is%20More%20Decentralized%20than%20PoS/">Why PoW Is More Decentralized than PoS</a>”</li></ul></li><li><p>How does Ethereum’s PoS differ from Cardano’s PoS?</p><ul><li>Why is Cardano’s PoS considered purer? Why is Ethereum’s PoS more decentralized?</li></ul></li><li><p>What are the pros and cons of PBFT? How can PBFT be optimized?</p><ul><li>“<a href="/2025/01/05/All%20BFT%20Consensus%20Blockchains%20Are%20Centralized/">All BFT Consensus Blockchains Are Centralized</a>”</li><li>“<a href="/2024/06/09/Why%20Ethereum%20Casper%20Needs%20EIP-7251/">Why Ethereum Casper Needs EIP-7251</a>”</li><li>“<a href="/2024/06/03/PBFT%20in%20Blockchain%20Doesn't%20Require%20a%20Second%20Vote/">PBFT in Blockchain Doesn’t Need a Second Round of Voting</a>”</li></ul></li><li><p>How do different types of blockchains handle forks?</p><ul><li>“<a href="/2023/07/01/Understanding%20Blockchain%20Consensus%20Mechanisms/">Understanding Blockchain Consensus Mechanisms</a>”</li><li>“<a href="/2024/08/22/How%20PoS%20Blockchains%20Handle%20Forks/">How PoS Blockchains Handle Forks</a>”</li></ul></li><li><p>What are some interesting potential applications of blockchain?</p><ul><li>“<a href="/2023/05/18/Pebbling-Game/">Pebbling Game</a>”</li><li>“<a href="/2023/02/22/A%20Mechanism%20for%20Generating%20Random%20Numbers%20on%20the%20Blockchain/">A Mechanism for Generating Random Numbers on Blockchain</a>”</li><li>“<a href="/2022/12/27/%22Designing%20a%20'Guess%202_3%20of%20the%20Average'%20dApp%20Game%22/">2&#x2F;3 Average Guessing dApp Game Design</a>”</li></ul></li></ul><p>Are these topics useful? Not really. No interviewer ever asked about them, and they’re rarely useful at work. I just explore them for fun. The answers to these questions aren’t readily available online, not even ChatGPT can give precise answers. Only after studying, reading papers, and combining with personal experience can one form a technical opinion — whether right or wrong.</p><p>So maybe out of mental inertia, I rarely care about overly basic programming questions. Everyone’s different — you can’t force someone to care about something just because of an FYI.</p><h4 id="FYI-Be-a-Good-Writer"><a href="#FYI-Be-a-Good-Writer" class="headerlink" title="FYI: Be a Good Writer"></a>FYI: Be a Good Writer</h4><p>(Yes, I just said don’t use FYI, and here I go again.)</p><p>There’s a memorable chapter in the book “<a href="https://www.joecotellese.com/posts/rework-book-summary/">Rework</a>” titled “Hire great writers.” The point was not about publishing articles or writing reports at work — but that good writers often have a clear and logical way of expressing problems, which is very helpful at work.</p><p>Back to tech — today, writing technical articles is quite common. If someone has a strong understanding of lock usage, they could write a solid piece explaining different types of locks and the best use cases. Share it on various platforms, gain thousands of followers, and if the insights keep coming, maybe even publish a book or open source it as a free e-book… FYI… don’t take it too seriously.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Previously, I recommended two blog posts by Yin Wang:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;“&lt;a</summary>
        
      
    
    
    
    
    <category term="Programmer" scheme="https://en.smallyu.net/tags/Programmer/"/>
    
  </entry>
  
  <entry>
    <title>Suppose We Launch an Ethereum PoS Network Called Oiia Network</title>
    <link href="https://en.smallyu.net/2025/01/28/Suppose%20We%20Launch%20an%20Ethereum%20PoS%20Network%20Called%20Oiia%20Network/"/>
    <id>https://en.smallyu.net/2025/01/28/Suppose%20We%20Launch%20an%20Ethereum%20PoS%20Network%20Called%20Oiia%20Network/</id>
    <published>2025-01-28T15:26:40.000Z</published>
    <updated>2025-08-06T10:38:28.701Z</updated>
    
    <content type="html"><![CDATA[<p>OIIA OIIA (Spinning Cat) is a recently popular meme featuring a spinning cat. Compared to DOGE on PoW chains, OIIA aims to be the cat-themed memecoin on a PoS chain.</p><p>Unlike memecoins issued by platforms like pump.fun or tokens like $Trump, OIIA tokens will be entirely generated through PoS mining. There is no pre-allocation (as verified by the genesis file), meaning tokens not mined cannot be purchased with money.</p><h3 id="Network-Motivation"><a href="#Network-Motivation" class="headerlink" title="Network Motivation"></a>Network Motivation</h3><ol><li><a href="/2025/01/10/The%20Best%20Way%20to%20Issue%20a%20Cryptocurrency/">The Best Way to Issue Cryptocurrency</a></li><li>Oiia will provide tools that make it easier to set up Ethereum PoS networks, further lowering the barrier to entry.</li></ol><h4 id="Why-Users-Should-Participate"><a href="#Why-Users-Should-Participate" class="headerlink" title="Why Users Should Participate"></a>Why Users Should Participate</h4><p>If participants lack relevant experience, they can benefit as learners by:</p><ol><li>Learning how to set up a complete Ethereum PoS network.</li><li>Understanding how to launch and maintain an Ethereum Validator node, including staking and unstaking processes.</li><li>Becoming proficient in using Ethereum ecosystem tools for nodes.</li><li>Identifying and solving usability issues in Ethereum ecosystem tools, contributing to the broader Ethereum ecosystem.</li></ol><h4 id="Why-Not-Use-Ethereum-Testnets"><a href="#Why-Not-Use-Ethereum-Testnets" class="headerlink" title="Why Not Use Ethereum Testnets"></a>Why Not Use Ethereum Testnets</h4><p>As Ethereum network learners, why choose Oiia Network over testnets like Sepolia?</p><p>The reason lies in Oiia Network’s identity as a memecoin.</p><h3 id="Network-Specifications"><a href="#Network-Specifications" class="headerlink" title="Network Specifications"></a>Network Specifications</h3><h4 id="Technical-Foundation"><a href="#Technical-Foundation" class="headerlink" title="Technical Foundation"></a>Technical Foundation</h4><p>Oiia Network uses Ethereum clients Geth + Lighthouse as initial nodes. Only the startup configuration and genesis file are modified—no code changes are made.</p><h4 id="Chain-ID-and-Network-ID"><a href="#Chain-ID-and-Network-ID" class="headerlink" title="Chain ID and Network ID"></a>Chain ID and Network ID</h4><p>Decimal:</p><pre><code>20220915</code></pre><p>Hexadecimal:</p><pre><code>0x1348BF3</code></pre><h4 id="Initial-Validators"><a href="#Initial-Validators" class="headerlink" title="Initial Validators"></a>Initial Validators</h4><p>The initial validator count is 128, the minimum scale for network launch. This number will be directly written into the <code>genesis.ssz</code> file.</p><h4 id="Initial-Faucet"><a href="#Initial-Faucet" class="headerlink" title="Initial Faucet"></a>Initial Faucet</h4><p>Since initial participation is expected to be limited, a reserve of 128 × 32 &#x3D; 4096 OIIA will be allocated as the faucet balance and placed in the faucet address.</p><p>The faucet will distribute tokens via PoW Faucet (web-based mining). </p><p>The faucet aims to provide small amounts of tokens for testing the network and incentivizing early Validators to join (although acquiring 32 OIIA from the faucet alone will be challenging). If 128 solo stakers participate, it would be a significant success, and the 4096 OIIA reserve should suffice.</p><h4 id="Initial-Token-Supply"><a href="#Initial-Token-Supply" class="headerlink" title="Initial Token Supply"></a>Initial Token Supply</h4><p>To avoid issues like Ethereum Foundation’s token sales, OIIA will not pre-allocate any tokens to developers or DAOs. Pre-allocation often raises suspicion across networks.</p><p>Ethereum’s PoS consensus has no upper limit on token supply. Thus, the initial supply is limited to 4096 OIIA. All post-launch circulation will come from mining rewards, similar to Bitcoin.</p><p>In summary, based on the genesis file of Oiia Network, apart from the 4096 OIIA reserved for the airdrop (not reflected in the genesis file for the 128 Validator nodes, valued at 4096 OIIA), no additional tokens will be pre-allocated to any address.</p><h4 id="How-to-Become-a-Validator"><a href="#How-to-Become-a-Validator" class="headerlink" title="How to Become a Validator"></a>How to Become a Validator</h4><p>Since the initial token supply is very limited and the faucet cannot provide enough OIIA, users can apply to become a Validator through the community. The community will transfer 32 OIIA directly from the faucet address to the applicant’s address.</p><h4 id="Network-Launch-Progress"><a href="#Network-Launch-Progress" class="headerlink" title="Network Launch Progress"></a>Network Launch Progress</h4><p>As there are no commercial objectives, the network launch will proceed at a relaxed pace.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;OIIA OIIA (Spinning Cat) is a recently popular meme featuring a spinning cat. Compared to DOGE on PoW chains, OIIA aims to be the</summary>
        
      
    
    
    
    
    <category term="OIIA" scheme="https://en.smallyu.net/tags/OIIA/"/>
    
  </entry>
  
  <entry>
    <title>The Best Way to Issue a Cryptocurrency</title>
    <link href="https://en.smallyu.net/2025/01/10/The%20Best%20Way%20to%20Issue%20a%20Cryptocurrency/"/>
    <id>https://en.smallyu.net/2025/01/10/The%20Best%20Way%20to%20Issue%20a%20Cryptocurrency/</id>
    <published>2025-01-09T16:39:12.000Z</published>
    <updated>2025-08-06T10:38:28.702Z</updated>
    
    <content type="html"><![CDATA[<p>A few days ago, a well-known figure from a non-Internet-related industry issued a memecoin on pump.fun. Over the past two days, there has been public discussion about migrating the memecoin to a dedicated blockchain, such as launching a new chain while preserving original addresses and balances.</p><p>The motivation behind this memecoin is simple: the issuer needs to raise funds to support their activities. However, due to the nature of these activities, many wallets have blacklisted the memecoin.</p><p>Of course, we won’t discuss the motivations behind issuing a cryptocurrency here. Instead, we’ll focus on the technical methods of issuing a cryptocurrency and compare them.</p><h3 id="The-Best-Method"><a href="#The-Best-Method" class="headerlink" title="The Best Method"></a>The Best Method</h3><p>To start with the conclusion: the most reliable technical solution for issuing a cryptocurrency is to use an Ethereum client to run a blockchain with a different Chain ID from Ethereum.</p><h3 id="Why-Not-Pump-fun"><a href="#Why-Not-Pump-fun" class="headerlink" title="Why Not Pump.fun"></a>Why Not Pump.fun</h3><p>Pump.fun is an excellent platform that allows for one-click token issuance while ensuring contract security, no rug pulls, no presales, and no security vulnerabilities. This makes it much more convenient and secure than writing a smart contract from scratch.</p><p>Pump.fun’s greatest strength is that tokens can be traded immediately using a bonding curve mechanism to define prices. This allows a token to be tradable even with very few traders, which is something other issuance methods cannot achieve.</p><p>However, pump.fun has its drawbacks. Firstly, it operates in the SOL ecosystem. It’s unclear why pump.fun chose Solana over Ethereum initially. Before purchasing a newly issued token, buyers need to understand and own SOL. While SOL is widely recognized, why should buyers have to learn about it first?</p><p>Secondly, if a token’s market cap is below $100K, it is tied to the pump.fun platform. Without visiting the pump.fun website, there is no way to trade it. If the site or domain disappears, the token loses its trading entry, which is detrimental to long-term development. Tokens with a market cap above $100K can enter Raydium, but how many buyers understand Raydium? This creates reliance on a DEX platform.</p><p>Thus, while pump.fun offers convenience, users must bear the risks of the platform and the Solana blockchain. Will Solana exist long-term? How long is “long”?</p><p>Pump.fun accurately positions itself as a memecoin issuance platform.</p><h3 id="Why-Not-PoW"><a href="#Why-Not-PoW" class="headerlink" title="Why Not PoW"></a>Why Not PoW</h3><p>PoW is the most decentralized form of blockchain technology, but the cost of launching a PoW chain is too high. There are no ready-made technical frameworks to reuse, requiring hardcore technical expertise. Additionally, maintenance costs are high—if no one mines, the issuer has to mine themselves, and the hash rate cannot be too low.</p><h3 id="Why-Not-Cosmos"><a href="#Why-Not-Cosmos" class="headerlink" title="Why Not Cosmos"></a>Why Not Cosmos</h3><p>Cosmos-based projects often carry negative connotations such as BFT (Byzantine Fault Tolerance) and consortium chains, making it an unattractive choice.</p><p>ATOM, Cosmos’s native token, is only ranked around #50 in market cap. The ecosystem has its niche use cases, but if there’s no compelling reason to use Cosmos, it’s best to avoid it.</p><p>Additionally, Cosmos’s ecosystem is underdeveloped—there is still no wallet like MetaMask that can connect to any RPC. Using Cosmos would bring many challenges.</p><h3 id="Why-Not-Polkadot-x2F-Avalanche"><a href="#Why-Not-Polkadot-x2F-Avalanche" class="headerlink" title="Why Not Polkadot &#x2F; Avalanche"></a>Why Not Polkadot &#x2F; Avalanche</h3><p>Even blockchain professionals struggle to fully understand and use Polkadot and Avalanche. The issue isn’t that they are incomprehensible, but rather that they have a high learning curve.</p><p>For example, Polkadot’s Existential Deposit mechanism is perplexing—why does it even exist? There are many other unknown pitfalls, making it a risky choice.</p><h3 id="Why-Not-Ethereum-Layer-2"><a href="#Why-Not-Ethereum-Layer-2" class="headerlink" title="Why Not Ethereum Layer 2"></a>Why Not Ethereum Layer 2</h3><p>Ethereum Layer 2 (L2) solutions were not designed for token issuance but rather for projects to earn protocol fees. L2s extend Ethereum, but their native tokens are still ETH.</p><p>While L2 technology is open-source and functional, it requires centralized operation and continuous fault proof submissions to Layer 1. Moreover, transaction fees must be paid in real ETH, which can be expensive. If there aren’t enough users, transaction fees alone could be a financial burden.</p><h3 id="Why-Not-Issuing-an-ERC-20-Token-on-Ethereum"><a href="#Why-Not-Issuing-an-ERC-20-Token-on-Ethereum" class="headerlink" title="Why Not Issuing an ERC-20 Token on Ethereum"></a>Why Not Issuing an ERC-20 Token on Ethereum</h3><p>Most people cannot write smart contracts safely. Security vulnerabilities are a major risk—even if the issuer believes the contract is secure, buyers may struggle to verify its safety. Identifying secure contracts is difficult, making this method unadvisable.</p><p>What about issuing an ERC-20 token on Layer 2? The problem is choosing which L2 network to use. While L2 fees are lower, data between different L2s is not interoperable. In a way, L2 solutions fragment Ethereum rather than strengthen it.</p><h3 id="Why-Ethereum"><a href="#Why-Ethereum" class="headerlink" title="Why Ethereum"></a>Why Ethereum</h3><p>There are undeniable facts:</p><ol><li>Ethereum’s EVM is the most widely recognized and used smart contract standard in the blockchain industry.</li><li>Ethereum’s PoS is the most decentralized consensus mechanism aside from PoW.</li><li>Ethereum’s dominance is unshakable – ETH killers may surpass Ethereum in some metrics, but the EVM standard will remain.</li><li>Ethereum’s community and ecosystem are more active, with better infrastructure than other blockchains.</li><li>New blockchain projects aim to be EVM-compatible rather than replacing EVM.</li></ol><p>Given these facts, the best way to launch a blockchain network is to use an Ethereum client, modify the configuration files and startup parameters, and launch a Layer 1 network.</p><p>From a network operations perspective, even if the Ethereum client is never upgraded again, the network can still run stably for a long time.</p><p>Regarding transaction fees—if the token price is low, fees will be cheap. Thus, fees are unlikely to become an insurmountable issue.</p><h3 id="How-to-Solve-Initial-Trading-and-Airdrop-Issues"><a href="#How-to-Solve-Initial-Trading-and-Airdrop-Issues" class="headerlink" title="How to Solve Initial Trading and Airdrop Issues"></a>How to Solve Initial Trading and Airdrop Issues</h3><p>Apart from pump.fun and PoW chains, all other token issuance methods face the problem of initial liquidity—the token won’t be immediately listed on CEX or DEX platforms. How can buyers purchase it? What can they use to buy it?</p><p>The only viable solution is ICO-style presales, where the network officially launches at the Token Generation Event (TGE). Although this process often involves controversies and disputes, using Ethereum nodes ensures that the Genesis file clearly defines every address, making the network credible and widely accepted.</p><p>Once the network genesis is established without issues, the rest can be managed through the network’s own inflation model, allowing it to operate smoothly in the long run.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;A few days ago, a well-known figure from a non-Internet-related industry issued a memecoin on pump.fun. Over the past two days, there</summary>
        
      
    
    
    
    
    <category term="Blockchain" scheme="https://en.smallyu.net/tags/Blockchain/"/>
    
  </entry>
  
  <entry>
    <title>All BFT Consensus Blockchains Are Centralized</title>
    <link href="https://en.smallyu.net/2025/01/05/All%20BFT%20Consensus%20Blockchains%20Are%20Centralized/"/>
    <id>https://en.smallyu.net/2025/01/05/All%20BFT%20Consensus%20Blockchains%20Are%20Centralized/</id>
    <published>2025-01-05T03:57:59.000Z</published>
    <updated>2025-08-06T10:38:27.633Z</updated>
    
    <content type="html"><![CDATA[<p>First, let’s rank consensus mechanisms in terms of decentralization. This ranking is almost indisputable:</p><p>PoW &gt; PoS &gt; DPoS &gt; BFT</p><p>Now, let’s compare PoS and BFT from the perspective of handling forks.</p><p>Due to the nature of the BFT algorithm, all chains using BFT consensus do not have forks, whether soft or hard forks. A chain without forks means that there is only one version of the network at any given time, and this version is determined by the project issuer. Even if the issuer is not an official entity, this version can only come from a centralized organization. Therefore, blockchains using BFT consensus are centralized.</p><p>What happens if the network issuer makes an unacceptable change?</p><p>Under PoS consensus, validators can choose either the old rules or the new rules. Both versions can coexist until most validators reach a consensus and the network regains consistency. If validators never reach consensus, the network will keep forking indefinitely.</p><p>Under BFT consensus, validators can also choose between the old and new rules, but if one side reaches half of the validators, the network will stop. The network will only restart once validators reach an offline agreement.</p><p>In other words, when a fork should theoretically occur, BFT networks simply halt. This is why networks like Solana and SUI have experienced outages.</p><p>At this point, you can understand that the centralization in BFT networks means that there cannot be two simultaneous networks. While other consensus mechanisms also rarely result in such situations, they at least allow for the possibility.</p><p>To clarify further, the centralization of BFT networks means that if a certain proportion of validators want to stop the network, they can. The only way to restore the network is to start a new one (which is essentially a form of hard fork).</p><p>What are the implications of this? In the Ethereum network, even if the majority of nodes go offline, as long as a few remain, the network can continue to operate. However, BFT networks have a fault tolerance of less than half—if half of the validators go offline, the network completely shuts down, making it impossible to transfer any on-chain assets.</p><p>From an investment perspective, if you plan to hold a cryptocurrency long-term, which type of network do you think is safer and better protects your assets?</p><p>However, it is important to note that network reliability does not necessarily come from decentralization. Coinbase’s Base network, for example, derives its reliability from U.S. government regulation and partial compliance. Many exchanges and government institutions store funds in Coinbase Prime’s custodial service, making the Base network relatively reliable as well.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;First, let’s rank consensus mechanisms in terms of decentralization. This ranking is almost indisputable:&lt;/p&gt;
&lt;p&gt;PoW &amp;gt; PoS &amp;gt; DPoS</summary>
        
      
    
    
    
    
    <category term="BFT" scheme="https://en.smallyu.net/tags/BFT/"/>
    
  </entry>
  
  <entry>
    <title>Predictions for the Blockchain Industry in 2025</title>
    <link href="https://en.smallyu.net/2024/12/16/Predictions%20for%20the%20Blockchain%20Industry%20in%202025/"/>
    <id>https://en.smallyu.net/2024/12/16/Predictions%20for%20the%20Blockchain%20Industry%20in%202025/</id>
    <published>2024-12-16T15:04:43.000Z</published>
    <updated>2025-08-06T10:38:27.727Z</updated>
    
    <content type="html"><![CDATA[<p>Events in 2024:</p><ol><li><p>Bitcoin halving, Bitcoin spot ETF approval, Bitcoin reaching new highs.</p></li><li><p>Trump endorsing BTC, Musk endorsing DOGE.</p></li><li><p>Bitcoin narratives cooled down, inscriptions and runes were ignored, Layer 2 technologies failed to gain traction (Lightning Network, Taproot, RGB, RGB++), and no reliable Layer 2 projects emerged (Nervos, Merlin, Nubit, Fractal Bitcoin).</p></li><li><p>Ethereum’s Cancun upgrade introduced Blob, significantly reducing Layer 2 costs. However, depositing from Layer 2 to exchanges still requires a 25-minute waiting period, which creates a poor user experience. Since reorganization is possible, transactions remain unsafe.</p></li><li><p>NFT markets disappeared, with Coinbase and Binance shutting down NFT trading platforms.</p></li><li><p>DEXX exchange was hacked, resulting in tens of millions of funds stolen from thousands of users. Both the exchange and users were of Chinese background, with many being beginners.</p></li></ol><hr><p>Predictions for 2025:</p><ol><li><p>Bitcoin price will hit a new high of $140,000.</p></li><li><p>Bitcoin does not need OP_CAT.</p></li><li><p>Ethereum’s dominance will remain unshakable; all ETH Killers will lack potential, including Solana, Ton, Tron, Polkadot, Cardano, Avalanche, Cosmos, and SUI.</p></li><li><p>The existing public chain landscape will remain unchanged, and no new high-market-cap Layer 1 blockchain will emerge.</p></li><li><p>New blockchains with integrated technology will appear, incorporating low-cost features as native functionalities, such as oracles, random numbers, on-chain governance, Subnet, WebAssembly, DID, etc. To boost their appeal, they will also ride the ZK and AI hype, only to discover that ZK has no real effect and has no actual connection to AI.</p></li><li><p>Cross-chain functionality will remain a rigid demand, but no decentralized solution will succeed in practice, now or in the future.</p></li><li><p>New blockchains will inevitably be EVM-compatible, and new projects will prioritize EVM support.</p></li><li><p>Ecosystem-oriented projects will continue to emerge, following the technical frameworks of specific blockchains to pursue their own goals. Ethereum, Polkadot, Cosmos, Internet Computer, and Avalanche all provide such ecosystem environments.</p></li></ol><hr><p>As an ordinary person wanting to participate in blockchain, there are only 3 things you can do:</p><ol><li><p>Dollar-cost average into Bitcoin.</p></li><li><p>Dollar-cost average into Bitcoin.</p></li><li><p>Dollar-cost average into Bitcoin.</p></li></ol>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Events in 2024:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Bitcoin halving, Bitcoin spot ETF approval, Bitcoin reaching new highs.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;&lt;p&gt;Trump endorsing</summary>
        
      
    
    
    
    
    <category term="Blockchain" scheme="https://en.smallyu.net/tags/Blockchain/"/>
    
  </entry>
  
  <entry>
    <title>The Economic Challenges of Restaking Projects</title>
    <link href="https://en.smallyu.net/2024/11/18/The%20Economic%20Challenges%20of%20Restaking%20Projects/"/>
    <id>https://en.smallyu.net/2024/11/18/The%20Economic%20Challenges%20of%20Restaking%20Projects/</id>
    <published>2024-11-18T15:13:15.000Z</published>
    <updated>2025-08-06T10:38:28.712Z</updated>
    
    <content type="html"><![CDATA[<p>Restaking is a relatively early-stage field, with one of the more notable projects being Eigen Layer. It gained considerable attention for a time because Eigen Layer hired researchers from the Ethereum Foundation with high salaries. Public opinion speculated that these incentives led Ethereum Foundation members to promote a shift toward centralization in Ethereum’s development.</p><p>Eigen Layer has made significant waves. Undeniably, Restaking’s business model is feasible, as Eigen Layer has already set the path. Its operational model does not invite much skepticism.</p><p>However, returning to the definition of Restaking, certain questions remain worth pondering. For example, why Restaking instead of Staking?</p><p>The core issue of Restaking projects is not technological but economic. In other words, Restaking projects lack technological barriers but are constrained by business model barriers. The key lies in whether they can operate effectively within business collaborations.</p><h3 id="Why-Restaking"><a href="#Why-Restaking" class="headerlink" title="Why Restaking?"></a>Why Restaking?</h3><p>The reason is simple: limited returns. As a staking user, I can stake ETH to obtain stETH and earn a stable 3% staking yield. On top of that, I can stake stETH on Eigen Layer, earning additional rewards if available. Even if there are no extra rewards, I still have a guaranteed 3% yield.</p><p>But what about Staking? This poses a dilemma. Holding ETH, should I pursue the stable 3% yield from stETH or opt for the unreliable returns from Eigen Layer projects?</p><p>This brings us to a critical question: where does Eigen Layer’s revenue come from?</p><p>Staking rewards on PoS chains are native and highly stable. What about Eigen Layer? Its rewards must come from users utilizing AVS (Active Verification Services). So, what services does AVS provide?</p><h3 id="The-Theory-Behind-Restaking"><a href="#The-Theory-Behind-Restaking" class="headerlink" title="The Theory Behind Restaking"></a>The Theory Behind Restaking</h3><p>Here’s a theoretical framework:</p><p>For PoS chains, users stake tokens to give validators staking weight, enabling validators to validate block data.<br>In Restaking projects, users stake tokens to give operators staking weight, enabling operators to validate arbitrary computational tasks.</p><p>Doesn’t this sound appealing? PoS chains are merely a subset of Restaking projects, which implies significant potential for Restaking.</p><p>This theory holds some merit. However, on closer scrutiny, the comparison should be with DPoS (Delegated Proof of Stake) consensus rather than PoS. In terms of decentralization, DPoS is less decentralized than PoS.</p><h3 id="Comparing-Restaking-with-DPoS"><a href="#Comparing-Restaking-with-DPoS" class="headerlink" title="Comparing Restaking with DPoS"></a>Comparing Restaking with DPoS</h3><p>Would Restaking projects have a significant advantage over DPoS? Let’s consider another question: why has DPoS primarily been used for block data validation rather than for verifying other types of data?</p><p>The answer is straightforward: there’s no data more important than user assets. For example, is the accuracy of tomorrow’s weather forecast more critical than the balance of a bank account? Historically, DPoS has served only one scenario: validating block transaction data. Finding a use case more critical than asset data is exceedingly difficult.</p><p>With this in mind, let’s return to the issue of Restaking yields. If DPoS offers a 3% staking yield, how much could Restaking provide? Theoretically, less than 3%, because the data validated by Restaking is unlikely to surpass the importance of asset data.</p><p>This is why Restaking projects must adopt Restaking rather than direct Staking—they cannot compete with Staking yields. By building on Staking, Restaking transforms into something different.</p><h3 id="Revenue-Sources-for-Restaking"><a href="#Revenue-Sources-for-Restaking" class="headerlink" title="Revenue Sources for Restaking"></a>Revenue Sources for Restaking</h3><p>In essence, the staking yields of both DPoS and Restaking originate from users of the service.</p><p>In DPoS, one group of users stakes tokens to become validators, while another group relies on these validators for asset security. Users thus allow the DPoS chain to mint 3% additional tokens as block rewards. While this increases the total supply, effectively taxing all participants, it sustains the system.</p><p>In Restaking, one group of users stakes tokens to become operators, while another group relies on these operators for data validation. The basic logic resembles that of DPoS. Here, the “other group” refers to users of AVS services, who ultimately fund the returns in Restaking.</p><p>Restaking’s yields cannot materialize out of thin air—they come directly from users. The payment mechanism can be straightforward: users pay directly for services. For instance, invoking an AVS service might cost $0.10 per transaction. Such direct billing eliminates the need for adjustments in token supply.</p><h3 id="Economic-Feasibility"><a href="#Economic-Feasibility" class="headerlink" title="Economic Feasibility"></a>Economic Feasibility</h3><p>How much user payment is sufficient? Suppose there is a staking pool of 1 million stETH. To provide a 1% annual return to stakers, assume 10,000 users call AVS services once daily. </p><p>At this point, another question arises: which user would willingly pay for such a service? On Ethereum L1, even a $1 transaction fee is considered exorbitant. Many people hesitate to pay $9 for an iQiyi subscription, and countless developers refuse to buy legitimate licenses for tools like IDEA despite using them daily.</p><p>Of course, as long as the bubble doesn’t burst, everyone’s wealth seems to grow. In a bull market, no one appears to be losing money. As long as one can exit before the bubble bursts, everything will appear rosy.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Restaking is a relatively early-stage field, with one of the more notable projects being Eigen Layer. It gained considerable attention</summary>
        
      
    
    
    
    
    <category term="Restaking" scheme="https://en.smallyu.net/tags/Restaking/"/>
    
  </entry>
  
  <entry>
    <title>Understanding the Technical Architecture of Any Blockchain Project</title>
    <link href="https://en.smallyu.net/2024/10/15/Understanding%20the%20Technical%20Architecture%20of%20Any%20Blockchain%20Project/"/>
    <id>https://en.smallyu.net/2024/10/15/Understanding%20the%20Technical%20Architecture%20of%20Any%20Blockchain%20Project/</id>
    <published>2024-10-15T15:43:36.000Z</published>
    <updated>2025-08-06T10:38:28.714Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Basic-Structure"><a href="#Basic-Structure" class="headerlink" title="Basic Structure"></a>Basic Structure</h3><p>The most basic blockchain is just a blockchain itself, with the capability of consensus-based block production. It may have many nodes or only one node, and each node provides an RPC interface for receiving transactions:</p><img src="1.png" width="60%"><p>With the advent of Ethereum, blockchain transactions are not only transactions but also have the ability to execute smart contracts:</p><img src="2.png" width="60%"><p>There will always be an external program to interact with smart contracts, which initiates transactions:</p><img src="3.png" width="60%"><p>From this point, it’s important to clarify two types of actions:</p><ol><li>Any interaction with the blockchain, whether submitting or querying transactions, is considered on-chain interaction.</li><li>Any action without interaction with the blockchain is considered off-chain behavior.</li></ol><p>Initiating interaction with a smart contract is always considered on-chain interaction. Similarly, no matter what language the external program initiating the transaction is written in, whether it’s Javascript or Golang, it’s called the smart contract SDK:</p><img src="4.png" width="60%"><p>In addition to Ethereum’s EVM contracts, there may also be contracts from other virtual machines (SVM, WASM), or Cosmos’s direct operation of the state database (Native contracts). These can be uniformly understood as on-chain smart contracts:</p><img src="5.png" width="60%"><p>Any on-chain contract requires an off-chain program to initiate transactions to achieve certain functions.</p><p>When the smart contract has specific logic, it may trigger some events, and these events are often listened to and processed by off-chain nodes:</p><img src="6.png" width="60%"><p>These off-chain nodes can be named anything, written in any language, as long as they capture events from the contract. Generally, there are two ways to listen to events:</p><ol><li>Actively poll by continuously requesting the node’s interface to check for new events.</li><li>Passively accept events, for example, through a long connection established via WebSocket.</li></ol><p>Once a certain event is triggered in the contract, the off-chain node listens to the event and then enters different code branches based on the event. After that, more complex operations can be carried out.</p><p>There may be multiple off-chain nodes or multiple roles, but this is not important. What matters is that they all interact with the events on the blockchain:</p><img src="7.png" width="60%"><p>Generally, off-chain nodes do not communicate with each other on their own. Instead, they follow the blockchain’s block content because off-chain nodes also need to maintain state consistency. In blockchain scenarios, the chain itself already provides a good mechanism for maintaining state consistency:</p><img src="8.png" width="60%"><p>So at this point, you realize that for a blockchain project, there are only two types of interactions between off-chain nodes and on-chain nodes:</p><ol><li>Sending data to the blockchain through transactions.</li><li>Querying events from the blockchain by listening to events.</li></ol><p>Cosmos has a project that supports EVM contracts and also provides the <code>evm_hook</code> interface. When an EVM contract triggers an event, it will actively call an interface function. This hook function is essentially passive event listening for contract events, but instead of triggering an RPC request, it calls a function directly. The only additional complexity is that the EVM contract triggers the function of a Cosmos module, linking the implementation methods of the two contracts together:</p><img src="9.png" width="60%"><p>No matter how complex the architecture becomes, the interaction between off-chain nodes and on-chain nodes still involves only two actions.</p><p>If things get more complex, what direction will they take? Off-chain nodes will start submitting transactions to the blockchain:</p><img src="10.png" width="60%"><p>Perhaps after listening to an event, a transaction is submitted, and that transaction triggers another event, leading to further actions. But overall, the interaction between off-chain nodes and on-chain nodes still only involves two actions.</p><h3 id="Filling-in-Business-Logic"><a href="#Filling-in-Business-Logic" class="headerlink" title="Filling in Business Logic"></a>Filling in Business Logic</h3><p>With the basic technical methods in place, it’s easier to understand how to layer business logic on top of them.</p><p>When faced with complex business logic, you can always distinguish which parts involve on-chain interactions and which parts are off-chain behavior. The core difference lies in where the data state is stored — either on the blockchain or in off-chain nodes:</p><ol><li>If the data is sent to the chain through transactions, the complexity of the business depends on the logic of the contract.</li><li>If the action is taken by off-chain nodes after listening to an event, the complexity depends on the off-chain code.</li></ol><p>If the complexity exceeds the two scenarios described above, it means off-chain nodes are communicating independently of the blockchain, resulting in inconsistent states. Such off-chain nodes can be considered to have operated outside of the blockchain project.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h3 id=&quot;Basic-Structure&quot;&gt;&lt;a href=&quot;#Basic-Structure&quot; class=&quot;headerlink&quot; title=&quot;Basic Structure&quot;&gt;&lt;/a&gt;Basic Structure&lt;/h3&gt;&lt;p&gt;The most basic</summary>
        
      
    
    
    
    
    <category term="Blockchain" scheme="https://en.smallyu.net/tags/Blockchain/"/>
    
  </entry>
  
  <entry>
    <title>Why You Shouldn&#39;t Engage in Secondary Development of Ethereum</title>
    <link href="https://en.smallyu.net/2024/09/12/Why%20You%20Shouldn&#39;t%20Engage%20in%20Secondary%20Development%20of%20Ethereum/"/>
    <id>https://en.smallyu.net/2024/09/12/Why%20You%20Shouldn&#39;t%20Engage%20in%20Secondary%20Development%20of%20Ethereum/</id>
    <published>2024-09-12T07:29:05.000Z</published>
    <updated>2025-08-06T10:38:28.725Z</updated>
    
    <content type="html"><![CDATA[<p>The reasoning is simple. Ethereum has a core development team. The Ethereum Foundation, at its center, provides funding to various Ethereum client development teams, who in turn develop for Ethereum. Vitalik came to China to raise funds, and after securing the money, formed a development team in another country. After a year of intensive development, Ethereum was born. Back in the day, the Ethereum Foundation participated in Ethereum’s ICO at less than $1, and now the price of ETH has increased thousands of times. That’s how the Ethereum Foundation got its money.</p><p>The Ethereum ecosystem is mainly composed of three parts: Layer 1, Layer 2, and ecosystem projects. (Staking-related projects don’t require your development. Does Restaking have anything to do with tech?)</p><p>For Layer 1, there are several major client teams: the execution layer includes Geth, Nethermind, Besu, Erigon, and Reth, while the consensus layer includes Prysm, Lighthouse, Teku, Nimbus, and Lodestar. Regardless of the relationship between these teams and Ethereum, if you or your company claims to want to conduct secondary development based on Ethereum clients, then what exactly do you want to develop?</p><p>If it’s an improvement beneficial to the Ethereum network itself, such as improving performance or optimizing data structures, you can directly submit an Issue or PR to Ethereum, or even establish a cooperative relationship, allowing the official Ethereum client version to support your optimizations. Moreover, the founding teams of these clients are still actively developing. Do you think you have a reason to outperform the “insiders” in terms of either client functionality or performance, whether as an individual or as a company?</p><p>For example, take parallel EVM, which aims to speed up EVM transaction execution. This is a challenge even the Geth team has been unable to solve. Can any small team just casually pull it off?</p><p>If it’s a modification that benefits your own chain but not Ethereum, and you expect the Ethereum development team not to accept your proposals and improvements, then the issue becomes even stranger. What makes your chain’s requirements so unique that these “self-owned” developments are necessary? Ethereum is already quite complete. In such a scenario, it seems you need to reevaluate the entire endeavor starting from the initial requirements.</p><p>On the Layer 2 side, the major teams include Polygon, Optimism, Zksync, and others. Why have Ethereum Layer 2 solutions become so popular and successful? Because Layer 2 is the direction endorsed by Vitalik. Why has the ENS project gained widespread adoption? Because ENS is a project approved by Vitalik. Why was there a buzz around AA wallets for a while? Because it was brought up by Vitalik’s soulbound tokens concept. You can see from Vitalik’s blog that all major current ecosystem projects have direct ties to Vitalik himself. The founders of these projects can all talk to Vitalik.</p><p>Vitalik is the big boss behind the entire Ethereum ecosystem. So, if you say you want to create a project within the Ethereum ecosystem, is technical ability your primary concern? What determines if a project will succeed? First, you look at whether Ethereum’s roadmap aligns with this direction. Then, see which project in this direction is leading within the Ethereum ecosystem. And then? You’ll realize that it has nothing to do with you. The Ethereum Foundation didn’t give you money, so why are you getting involved?</p><p>From a developer’s perspective, if you want to participate in Ethereum ecosystem development, what do you need the Ethereum core team for? If you want to improve Op Stack’s Fault Proofs, what do you need Optimism’s core team for? As an outsider, you’re spending time and resources just to carry water for others?</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;The reasoning is simple. Ethereum has a core development team. The Ethereum Foundation, at its center, provides funding to various</summary>
        
      
    
    
    
    
    <category term="Programmer" scheme="https://en.smallyu.net/tags/Programmer/"/>
    
  </entry>
  
  <entry>
    <title>Why You Shouldn&#39;t Pursue Smart Contract or DeFi Development</title>
    <link href="https://en.smallyu.net/2024/09/11/Why%20You%20Shouldn&#39;t%20Pursue%20Smart%20Contract%20or%20DeFi%20Development/"/>
    <id>https://en.smallyu.net/2024/09/11/Why%20You%20Shouldn&#39;t%20Pursue%20Smart%20Contract%20or%20DeFi%20Development/</id>
    <published>2024-09-11T12:51:35.000Z</published>
    <updated>2025-08-06T10:38:28.726Z</updated>
    
    <content type="html"><![CDATA[<p>Currently, when the job market mentions “contract development,” it generally refers to “EVM contract development on Ethereum.” However, in reality, Ethereum is not the only blockchain. There are potentially hundreds of blockchains, and Ethereum is not the only one with smart contracts. Solana has SVM, Polkadot uses Wasm, Cosmos achieves smart contract functionality through its parallel chains, and there are many other implementations.</p><p>So, do you see the issue? If a programmer claims to be a “contract developer,” they are confining themselves to a narrow direction. Solidity is a scripting language created by the Ethereum team, and “contract development” means entrusting your career to this immature scripting language. At the very least, we should be “programmers,” not just “Solidity programmers,” right?</p><p>A programmer can do some contract development work when needed, but a contract developer can only develop contracts. How high is the learning curve for Solidity itself? Generally, you can start writing in about half a week.</p><p>Then there’s DeFi development, as most people doing contract development are learning DeFi development. The problem here is that, whether it’s Centralized Finance or Decentralized Finance, the core is still “finance,” and “decentralized” is just an adjective modifying finance.</p><p>What is “finance”? It’s an entirely different field from being a “programmer.” The world’s elites are engaged in finance on Wall Street, so can a programmer, who has switched careers, truly grasp finance? Aren’t current DeFi projects all related to leverage, staking, and lending? Wasn’t Luna’s collapse caused by excessive leverage? How many capital firms were involved behind Luna? Can the average person fully understand the reasons behind Luna’s collapse? Probably not, and even professional financial analysts might struggle to get clear answers after long analysis.</p><p>In other words, professional finance experts are not necessarily programmers, and programmers are almost never professional finance experts. The financial industry is deep; it’s not something you can grasp just by learning to code and picking up Solidity, and certainly not something a programmer aspiring to DeFi can easily master.</p><p>Furthermore, even if a programmer understands DeFi, what can they do with that knowledge? They can end up working for the big capital players, implementing whatever business logic is assigned to them. Is there room for creativity? Are you going to design your own financial logic? That’s laughable. The ones who have control over vast amounts of capital are never programmers, and programmers never have control over vast amounts of capital.</p><p>What I mean is, if a programmer wants to understand finance deeply and express unique insights into the entire financial industry, it’s… almost impossible. It’s extremely difficult, and anyone capable of doing that won’t be a programmer. However, if you just want to understand a particular technical field and share some opinions, it’s still possible. At least you won’t need to own (or manage assets for others) a vast amount of capital.</p><p>What if a programmer who understands finance starts their own financial company? Are you sure?</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Currently, when the job market mentions “contract development,” it generally refers to “EVM contract development on Ethereum.” However,</summary>
        
      
    
    
    
    
    <category term="Programmer" scheme="https://en.smallyu.net/tags/Programmer/"/>
    
  </entry>
  
  <entry>
    <title>My Cryptocurrency Dollar-Cost Averaging Strategy (Part 1)</title>
    <link href="https://en.smallyu.net/2024/08/28/My%20Cryptocurrency%20Dollar-Cost%20Averaging%20Strategy%20(Part%201)/"/>
    <id>https://en.smallyu.net/2024/08/28/My%20Cryptocurrency%20Dollar-Cost%20Averaging%20Strategy%20(Part%201)/</id>
    <published>2024-08-27T18:15:14.000Z</published>
    <updated>2025-08-06T10:38:27.719Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>As time goes by and my understanding of the market deepens, the dollar-cost averaging (DCA) strategy, especially the investment portfolio, may undergo significant changes. This is why I labeled this as Part One in the title. If the DCA strategy changes, there may be Part Two, Part Three, and so on. Of course, I will also explain the reasons for any changes.</p></blockquote><p>This year, I’ve been focusing more on investment topics, partly because I’ve lost some money through reckless trading.</p><p>Recently, I’ve been heavily influenced by Li Xiaolai’s ideas. The theory behind the DCA strategy is quite exciting. You can delve deeper into the topic through the following resources:</p><ul><li>“<a href="https://ri.firesbox.com/#/">The DCA Strategy that Changes Your Fate</a>” by Li Xiaolai — everything about DCA is covered in this book.</li><li><a href="https://youtu.be/tmRQImBk6NA?si=Cl7Fwiq2WcfM28P2">The DCA Strategy that Changes Your Fate: Public Class Live</a> — a YouTube video where Li Xiaolai himself interprets the theory.</li></ul><p>Besides DCA, here are a few other investment references:</p><ul><li>“<a href="https://github.com/xiaolai/the-self-cultivation-of-leeks">The Self-Cultivation of Leeks</a>” by Li Xiaolai</li><li><a href="https://www.youtube.com/@ChandlerGuoChannel">Chandler Guo’s YouTube Channel</a></li></ul><p>I want to practice the DCA investment method, which involves addressing several questions:</p><ol><li>Should I join Li Xiaolai’s investment practice group? Not necessary, especially for those with self-discipline.</li><li>Should I buy <a href="https://b.watch/">BOX</a>? Rumor has it that Li’s books must be read, his classes can be attended, but you should never buy the coins.</li><li>What method should be used for DCA? Binance’s DCA feature is sufficient, with zero fees (remember to occasionally withdraw to a wallet).</li><li>What is the frequency of DCA? Daily, because prices fluctuate rapidly. If the frequency is too low, the cycle becomes too long.</li><li>What is the duration of the DCA? I have currently planned to DCA for one year.</li><li>What are the targets for DCA?</li></ol><p>I did not blindly follow the selection and proportion of targets in Li Xiaolai’s BOX. Initially, Li Xiaolai’s BOX had a high proportion of EOS, which proved to be a failure, so EOS is no longer included in the BOX. Currently, the latest situation is that BTC accounts for 92% of the BOX’s composition. Additionally, XIN has always been a component of BOX, showing that personal biases can influence decisions, as most of us probably don’t even know what XIN is, while Li Xiaolai has consistently chosen this coin for years.</p><p>The targets and allocation proportions I chose are:</p><table><thead><tr><th align="center">No.</th><th align="center">Target</th><th align="center">Proportion</th><th align="center">Tag</th><th align="center">Risk</th><th align="center">Max Supply</th></tr></thead><tbody><tr><td align="center">1</td><td align="center">BTC</td><td align="center">50%</td><td align="center">PoW, UTXO</td><td align="center">Low</td><td align="center">✅</td></tr><tr><td align="center">2</td><td align="center">ETH</td><td align="center">10%</td><td align="center">Smart Contract Platform</td><td align="center">Medium</td><td align="center">❌</td></tr><tr><td align="center">3</td><td align="center">LTC</td><td align="center">5%</td><td align="center">PoW, UTXO</td><td align="center">High</td><td align="center">✅</td></tr><tr><td align="center">4</td><td align="center">DOGE</td><td align="center">5%</td><td align="center">PoW, UTXO</td><td align="center">High</td><td align="center">❌</td></tr><tr><td align="center">5</td><td align="center">BCH</td><td align="center">5%</td><td align="center">PoW, UTXO</td><td align="center">High</td><td align="center">✅</td></tr><tr><td align="center">6</td><td align="center">ADA</td><td align="center">5%</td><td align="center">PoS, UTXO</td><td align="center">High</td><td align="center">✅</td></tr><tr><td align="center">7</td><td align="center">SOL</td><td align="center">5%</td><td align="center">Smart Contract Platform</td><td align="center">High</td><td align="center">❌</td></tr><tr><td align="center">8</td><td align="center">FIL</td><td align="center">5%</td><td align="center">PoSt</td><td align="center">Very High</td><td align="center">❌</td></tr><tr><td align="center">9</td><td align="center">TON</td><td align="center">5%</td><td align="center">Smart Contract Platform</td><td align="center">Very High</td><td align="center">❌</td></tr><tr><td align="center"><del>10</del></td><td align="center"><del>XEC</del></td><td align="center"><del>3%</del></td><td align="center"><del>PoW, UTXO</del></td><td align="center"><del>Very High</del></td><td align="center"><del>✅</del></td></tr><tr><td align="center"><del>11</del></td><td align="center"><del>DASH</del></td><td align="center"><del>2%</del></td><td align="center"><del>PoW, UTXO</del></td><td align="center"><del>Very High</del></td><td align="center"><del>✅</del></td></tr><tr><td align="center">10</td><td align="center">XMR</td><td align="center">5%</td><td align="center">PoW, UTXO</td><td align="center">Very High</td><td align="center">❌</td></tr></tbody></table><p>(Updated on 2024.09.26)</p><p>You can view this collection of coins in this public <a href="https://coinmarketcap.com/watchlist/66d339a5c316be09d04b7b16/">Watchlist</a>, which links to the CoinMarketCap website. You’ll notice that nearly all of the coins have a market cap ranking within the top 100, following the fourth principle from “<a href="/2024/05/04/%E7%82%92%E5%B8%81%E6%8A%95%E8%B5%84%E7%9A%84%E5%B0%8F-tips/">Some Small Tips for Crypto Investing</a>”.</p><p>In my DCA portfolio, BTC is always the top choice, making up 50% of the total allocation. Additionally, five PoW coins make up 20% of the portfolio, meaning PoW coins collectively account for 70%. Most PoW coins have a capped supply.</p><p>Due to the saying “Bitcoin is gold, Litecoin is silver,” LTC has been relatively strong. DOGE and LTC are like close allies, sharing the same mining algorithm. The <a href="https://www.litecoinpool.org/">mining pool</a> mines both of these coins simultaneously, so the prices of LTC and DOGE cannot be simply estimated like the “shutdown price” of BTC miners. Moreover, DOGE is the leader among memecoins, has a long history, and is favored by Elon Musk, making it hard to ignore. Thus, LTC and DOGE are included together.</p><p>BCH emerged as a workaround for high transaction fees during the Bitcoin Cash era (2017). Has the Blocksize War truly ended? BCH represents the large block faction, so it is included here. BTC has moved away from its “electronic cash” purpose to become a “store of value.” I believe the debate on this issue is not entirely over. BCH later forked into BSV, so why isn’t BSV included? BSV’s ecosystem is small, and it includes some active but uninformed projects (like Note). Additionally, BSV’s founder is wanted by the authorities, among other reasons.</p><p>DASH and XEC are the least justifiable choices, being so obscure that many people have never heard of them, and they are also the highest risk. XEC is included because the <a href="https://github.com/bitcoin-cash-node/bitcoin-cash-node">node code</a> of BCH is forked from XEC’s code, which suggests that XEC has decent technical capabilities. DASH is a fork of LTC and was more of a filler choice because many old wallets, like Unstoppable, primarily support PoW coins, and DASH is among them. Additionally, Binance’s mining pool service supports only a few coins, including DASH, so DASH is included as a high-risk alternative for “electronic cash.”</p><p>Then there’s ADA, which has strong academic credentials and a pure PoS consensus model using the UTXO model, making it an alternative to BTC in the PoS consensus space. Moreover, ADA’s technology is continuously updated, and if PoS wins out one day, ADA is undoubtedly a key player. Therefore, I anticipate a better future for ADA.</p><p>FIL, on the other hand, falls under the category of distributed storage. Computer science has two major directions: distributed computing and distributed storage. ETH claims to be the “World Computer” and takes on the role of distributed computing, while FIL is the leader in the storage space. It’s worth noting that libp2p was developed by Filecoin, and many blockchains like ETH use the p2p module directly from libp2p. Additionally, the widely used IPFS was developed by Filecoin Labs. Thus, FIL has strong research and development capabilities, and there might be a day when it achieves significant breakthroughs.</p><p>Finally, we have the smart contract platforms. Honestly, I don’t like smart contracts much; many people equate smart contracts with blockchain or think that only blockchains that support smart contracts are true blockchains. When it comes to holding coins, coins on smart contract platforms are merely <a href="/micro-blog/#2024-31">fuel</a> without a capped supply, so why bother hoarding them? However, smart contract platforms are popular, have many users, and their prices remain high. ETH, SOL, and TON all support smart contracts and are currently highly watched, so I allocated some proportion to them.</p><p>Additionally, here are the reasons some popular coins were not included:</p><table><thead><tr><th align="center">Coin</th><th align="center">Reason for Exclusion</th></tr></thead><tbody><tr><td align="center">BNB</td><td align="center">It’s a platform token, not a chain.</td></tr><tr><td align="center">DOT</td><td align="center">No max supply, high APR.</td></tr><tr><td align="center">ATOM</td><td align="center">No max supply, high APR.</td></tr><tr><td align="center">AVAX</td><td align="center">No max supply, no obvious advantages.</td></tr><tr><td align="center">APT, SUI</td><td align="center">BFT consensus type.</td></tr><tr><td align="center">All ERC-20 tokens</td><td align="center">Not chains.</td></tr><tr><td align="center">All Memecoins</td><td align="center">No long-term value.</td></tr><tr><td align="center">Inscriptions, Runes</td><td align="center">BTC transaction fees are too high.</td></tr></tbody></table><p>Wish myself good luck!</p><h3 id="Update-2024-09-26"><a href="#Update-2024-09-26" class="headerlink" title="Update (2024.09.26)"></a>Update (2024.09.26)</h3><p>XEC and DASH have been removed from the original portfolio. In the previous selection, XEC and DASH were already two assets with insufficient reasons for inclusion, and their total market cap rankings were around 100 or even lower, with poor community engagement.</p><table><thead><tr><th align="center"></th><th align="center"></th><th align="center"></th><th align="center"></th><th align="center"></th><th align="center"></th></tr></thead><tbody><tr><td align="center"><del>10</del></td><td align="center"><del>XEC</del></td><td align="center"><del>3%</del></td><td align="center"><del>PoW, UTXO</del></td><td align="center"><del>Very High</del></td><td align="center"><del>✅</del></td></tr><tr><td align="center"><del>11</del></td><td align="center"><del>DASH</del></td><td align="center"><del>2%</del></td><td align="center"><del>PoW, UTXO</del></td><td align="center"><del>Very High</del></td><td align="center"><del>✅</del></td></tr></tbody></table><p>More importantly, XMR is now used to replace the combined 5% allocation that was previously held by them. XMR is one of the <a href="https://x.com/DarkDotFail/status/1765104459913330820">main currencies</a> used on the dark web, which only accepts BTC and XMR. XMR has strong privacy protection features. In the dark web’s application domain, XMR, XEC, and DASH are frequently <a href="https://x.com/Altcoinbuzznews/status/1746989440373784958">discussed together</a> as three comparable cryptocurrencies. If we were to choose one from these three, XMR would be the first choice.</p><table><thead><tr><th align="center"></th><th align="center"></th><th align="center"></th><th align="center"></th><th align="center"></th><th align="center"></th></tr></thead><tbody><tr><td align="center">10</td><td align="center">XMR</td><td align="center">5%</td><td align="center">PoW, UTXO</td><td align="center">Very High</td><td align="center">❌</td></tr></tbody></table>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;As time goes by and my understanding of the market deepens, the dollar-cost averaging (DCA) strategy, especially the</summary>
        
      
    
    
    
    
    <category term="Dollar-Cost Averaging Strategy" scheme="https://en.smallyu.net/tags/Dollar-Cost-Averaging-Strategy/"/>
    
  </entry>
  
  <entry>
    <title>How PoS Blockchains Handle Forks</title>
    <link href="https://en.smallyu.net/2024/08/22/How%20PoS%20Blockchains%20Handle%20Forks/"/>
    <id>https://en.smallyu.net/2024/08/22/How%20PoS%20Blockchains%20Handle%20Forks/</id>
    <published>2024-08-22T09:41:01.000Z</published>
    <updated>2025-08-06T10:38:27.699Z</updated>
    
    <content type="html"><![CDATA[<p>Mainstream public blockchains can be classified into three categories based on their consensus mechanisms: PoW, PoS, and PBFT. The choice of consensus mechanism largely determines the network’s TPS, degree of decentralization, and node scale.</p><p>Apart from PoW, the other two consensus mechanisms, PoS and PBFT, face a fundamental issue: how to recover when the network experiences a soft fork. Since PoS and PBFT do not require computational power to generate blocks, they cannot use the same longest chain rule as PoW.</p><h3 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h3><h4 id="Consensus-Overview"><a href="#Consensus-Overview" class="headerlink" title="Consensus Overview"></a>Consensus Overview</h4><p>PoW-based chains include BTC, BCH, BSV, LTC, DOGE, ZEC, and others. PoW uses the longest chain rule, where nodes facing multiple forked chains simply choose the one with the highest block height. Since generating each block requires significant computational power, the cost of attacking the network is high.</p><p>PoS-based chains include ETH, BNB, TRON, DOT, TON, ADA, AVAX, NEO, and others. Almost all current smart contract platform chains use PoS consensus.</p><p>PBFT-based chains include ATOM, SOL, TON, ONT, APT, SUI, etc. Among them, Cosmos is the most well-known, Solana shows potential to surpass Ethereum, and The Open Network has also developed well this year.</p><p>You might find it strange to classify SOL under PBFT. Isn’t SOL based on PoH consensus? Doesn’t SOL have staking features, such as earning rewards through staking in the Solflare wallet? TON also has staking and rewards, right?</p><p>These are two separate issues.</p><p>Firstly, Solana indeed developed and uses a BFT-like consensus called <a href="https://solana.com/news/8-innovations-that-make-solana-the-first-web-scale-blockchain">Tower BFT</a>. PoH is used to solve the clock problem on the Solana chain, not as a complete consensus mechanism.</p><p>Secondly, when it comes to PoS+BFT consensus, should it be classified as PoS or BFT? The above classification mainly refers to PoS, dPoS, PoS Casper, etc., while anything involving BFT is classified under PBFT for distinction. For instance, Cosmos also has staking and reward features, but few people would say Cosmos uses PoS.</p><h4 id="About-Forks"><a href="#About-Forks" class="headerlink" title="About Forks"></a>About Forks</h4><p>When dealing with forks in PoS and PBFT consensus, there are two aspects to consider.</p><p>One aspect is whether the staker list (called <code>Validators</code> in Ethereum, <code>Stakeholders</code> in Cardano) is consistent. Since PoS and PBFT generally use VRF to select a node from a candidate list as the block producer, what are the similarities and differences in handling this issue?</p><p>The other aspect is the rule for choosing the chain when the network forks (called <code>Forkchoice</code> in Ethereum, <code>Chain selection rule</code> in Cardano).</p><h3 id="Inconsistent-Staker-List"><a href="#Inconsistent-Staker-List" class="headerlink" title="Inconsistent Staker List"></a>Inconsistent Staker List</h3><h4 id="Consortium-Chains"><a href="#Consortium-Chains" class="headerlink" title="Consortium Chains"></a>Consortium Chains</h4><p>Let’s start with the simplest, consortium chains. Consortium chains do not have coins, so there is no staking involved, only pure PBFT.</p><p>As the name suggests, consortium chains have very high entry barriers. You need to be reviewed or authorized to become a consortium member. Technically, this means that to join the network, it must be done with the knowledge of other nodes. For example, all nodes’ configuration files contain a list of network members, defining the public keys and corresponding indexes of the network nodes. To add a node, all other nodes need to update their configuration files.</p><p>When a node produces a block, it randomly selects one from this list using VRF as the block producer. Generally, VRF returns a simple number corresponding to the index in the public key list, and the block producer signs the block with this public key.</p><p>This method is somewhat cumbersome but is characteristic of consortium chains. In this mode, the staker list is unlikely to be inconsistent. If it is, it means a configuration file error. A configuration error will always be wrong, making it easy to troubleshoot.</p><h4 id="Cosmos"><a href="#Cosmos" class="headerlink" title="Cosmos"></a>Cosmos</h4><p>Cosmos Hub uses a consensus called <a href="https://docs.cometbft.com/v0.37/introduction/">CometBFT</a>. The basic process involves spending no less than 180 ATOM to register as a Validator, after which you may be selected as a block producer.</p><p>Since BFT consensus requires voting before block production, if there is indeed an inconsistency in the staker list within the network, two blocks might be produced at the same block height by different nodes, and other nodes in the network would vote on these blocks.</p><p>There are two scenarios here: a normal network and an abnormal network.</p><p>In a normal network, when two blocks are produced, only one of them can receive more than 2&#x2F;3 of the votes; it’s impossible for both blocks to receive more than 2&#x2F;3 of the votes. So, before block production, nodes with inconsistent staker lists are already excluded from the process, ensuring that they don’t affect subsequent procedures.</p><p>In an abnormal network, where a node cannot perceive the presence of other nodes, even if its staker list matches a few nodes in the current sub-network, the other nodes will not cast their votes. Unless the entire sub-network is isolated and the staker list coincidentally shares the same error, that sub-network would be isolated, playing alone on a local network. Network anomalies themselves are abnormal situations, isolated from the outside world.</p><h4 id="Cardano"><a href="#Cardano" class="headerlink" title="Cardano"></a>Cardano</h4><p>Cardano’s PoS is the purest form of PoS, without a voting mechanism. Cardano’s consensus has undergone <a href="https://iohk.io/en/blog/posts/2022/06/03/from-classic-to-chronos-the-implementations-of-ouroboros-explained/">multiple evolutions</a> (there’s a lot to it, and I haven’t finished reading it).</p><p>The rule in the Cardano network is that anyone can stake any amount into Stake pools to become a <a href="https://docs.cardano.org/about-cardano/learn/delegation/">Delegator</a>. These Delegators share the pool’s rewards in proportion to their staked amount but do not have the right to produce blocks.</p><p>In the Cardano network, the entities with the right to produce blocks are Stake pools. In other words, nodes that may be selected as block producers are already on the <a href="https://preprod.cexplorer.io/pool">pool list</a>. There aren’t many of them, around 300 at present, and each slot randomly selects one to produce a block.</p><p>So what happens if there is an inconsistency in the Stake pools list among nodes after registration? Cardano’s documentation <a href="https://developers.cardano.org/docs/operate-a-stake-pool/introduction-to-cardano#how-it-works">describes</a> that when two blocks are produced in the same slot, the Chain Selection Rule is activated. This means that when a second block is produced, the chain has already forked, and all nodes will activate the chain selection rule to recover.</p><h4 id="Ethereum"><a href="#Ethereum" class="headerlink" title="Ethereum"></a>Ethereum</h4><p>To become a Validator in Ethereum, you need to spend 32 ETH to register your node information on the <a href="https://etherscan.io/address/0x00000000219ab540356cbb839cbe05303d7705fa">staking contract</a>, after which all Validators retrieve the staker list from the contract.</p><p>How do you ensure that other Validators have synchronized the staker information from the contract to their local node? You can find a field called <a href="https://github.com/ethereum/consensus-specs/blob/v1.3.0/specs/phase0/validator.md#eth1-data">Eth Data</a> in any block on the Beacon Chain explorer, such as <a href="https://beaconcha.in/block/20584195">this block</a>. This field is crucial for the staker list. When a validator is selected as the block producer, it packages the current staker list synchronized by the node, including the total number of stakers and the Deposit root information, into the block.</p><p>The Ethereum network updates the staker list approximately every 17 hours. During this period, new validators are only added to the network if the Eth Data field in more than half of the blocks contains the new validator. </p><p>Thus, the process of adding Validators to Ethereum is long and strict. The staker list is difficult to be inconsistent under such rules.</p><h3 id="Chain-Selection-After-Forks"><a href="#Chain-Selection-After-Forks" class="headerlink" title="Chain Selection After Forks"></a>Chain Selection After Forks</h3><h4 id="Ethereum-1"><a href="#Ethereum-1" class="headerlink" title="Ethereum"></a>Ethereum</h4><p>If multiple forks occur in Ethereum, the choice is relatively easy because Ethereum has a voting mechanism. Each block contains the number of validators that voted for it. When a fork occurs, simply selecting the block with the most votes should suffice.</p><p>In fact, Ethereum’s fork choice is based on a <a href="https://ethos.dev/beacon-chain">checkpoint mechanism</a>. Each block is a slot, every 32 slots form an epoch, and each epoch is a checkpoint. A checkpoint that receives more than 2&#x2F;3 of the votes becomes justified. When the checkpoint after the next one also becomes justified, the current checkpoint is considered finalized. Therefore, in Ethereum, a transaction takes 15 minutes to be marked as finalized.</p><p>The checkpoints mentioned here are the basis for <a href="https://arxiv.org/abs/1710.09437">FFG</a> fork choice. Each chain will choose the one with more checkpoints, so Ethereum’s consensus does not select the chain with the most blocks, but the one with the most checkpoints. The chain with the most checkpoints is the main chain.</p><h4 id="Cardano-1"><a href="#Cardano-1" class="headerlink" title="Cardano"></a>Cardano</h4><p>Cardano currently uses a <a href="https://developers.cardano.org/docs/operate-a-stake-pool/introduction-to-cardano/#what-if-for-some-reason-there-is-a-fork">Chain selection rule</a> provided by the <a href="https://dl.acm.org/doi/10.1145/3243734.3243848">Ouroboros Genesis</a> version.</p><p>The previous version of Ouroboros Genesis was <a href="https://link.springer.com/chapter/10.1007/978-3-319-78375-8_3">Ouroboros Praos</a>. The Praos version introduced a rule called <code>maxvalid</code>, and the Genesis version made some improvements to this rule by incorporating the <code>moving checkpoint</code> feature, resulting in a new rule called <code>maxvalid-mc</code>.</p><p>The moving checkpoint is a simple concept: when facing multiple forked chains, if the fork does not exceed <code>k</code> blocks, the chain with the longest length is selected. If the fork exceeds <code>k</code> blocks, it is ignored entirely. This means the local chain will only select the longest chain within the <code>k</code> blocks range. The range of <code>k</code> blocks is referred to as the moving checkpoint. The advantage of this restriction is that it helps avoid the longest chain attack. Of course, Cardano established this rule through a series of academic analyses and practical tests.</p><h4 id="Cosmos-1"><a href="#Cosmos-1" class="headerlink" title="Cosmos"></a>Cosmos</h4><p>In PBFT chains like Cosmos, as long as the staker list is consistent under normal network conditions, forks will not occur.</p><h3 id="Conclusion"><a href="#Conclusion" class="headerlink" title="Conclusion"></a>Conclusion</h3><p>In summary, each consensus mechanism has detailed rules for handling forks, and these rules have been tested in real-world scenarios by established public blockchains. The specific implementation of fork recovery is closely tied to the design philosophy of each blockchain.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Mainstream public blockchains can be classified into three categories based on their consensus mechanisms: PoW, PoS, and PBFT. The</summary>
        
      
    
    
    
    
    <category term="Consensus Mechanism" scheme="https://en.smallyu.net/tags/Consensus-Mechanism/"/>
    
  </entry>
  
  <entry>
    <title>Why Ethereum Casper Needs EIP-7251</title>
    <link href="https://en.smallyu.net/2024/06/09/Why%20Ethereum%20Casper%20Needs%20EIP-7251/"/>
    <id>https://en.smallyu.net/2024/06/09/Why%20Ethereum%20Casper%20Needs%20EIP-7251/</id>
    <published>2024-06-09T15:57:17.000Z</published>
    <updated>2025-08-06T10:38:28.723Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://arxiv.org/abs/1710.09437">Casper the Friendly Finality Gadget</a> is the consensus mechanism currently used by Ethereum, a type of PoS implementation. This relationship is similar to how Bitcoin uses SHA-256 for mining while Dogecoin uses Scrypt. Other PoS implementations include Cardano’s Ouroboros.</p><p><a href="https://eips.ethereum.org/EIPS/eip-7251">EIP-7251</a> proposes increasing the staking limit per validator from 32 ETH to 2048 ETH. This change aims to effectively reduce the number of validators and the communication load on the P2P network.</p><p>This change is urgent because Ethereum simulated a large number of stakers in a test environment. The <a href="https://notes.ethereum.org/@parithosh/bigboi-beaconchain-test-2">test results</a> show that when the number of stakers reaches 2.1 million, the network voting rate drops below 50%, preventing it from reaching a final state. This means the checkpoint mechanism fails, leaving the network in a very insecure state. Ethereum’s current number of validators has already reached <a href="https://beaconscan.com/stat/validator">1.4 million</a>. If changes are not made in time, the Ethereum network will collapse in the near future.</p><p>Why is Ethereum facing this dilemma? Isn’t PoS a consensus mechanism that can scale to large networks?</p><p>The reason lies in the fact that Ethereum Casper is an improvement on BFT, not on PoS.</p><p>Let’s first look at how Vitalik describes Ethereum Casper, emphasizing its improvements over BFT:</p><img src="1.png" /><p>Now, let’s look at the specific process of Ethereum Casper: nodes stake assets to become validators, and then a node is randomly selected to produce a block through VRF. After the block is produced, all validators vote on the validity of the block. These votes are first submitted to the committee members, who aggregate the votes and then synchronize among themselves. Committee members are randomly elected at intervals.</p><p>For those familiar with BFT but not with Ethereum Casper, learning that only blocks receiving 2&#x2F;3 of the votes can be marked as final may trigger sensitivity to the 2&#x2F;3 number. This is because 2&#x2F;3 is the voting ratio emphasized by BFT to ensure 3f+1 fault tolerance.</p><p>BFT’s voting mechanism ensures that forks do not occur in the network. Ethereum adopts this advantage of BFT, making handling fork scenarios relatively easy by judging the block with the highest vote rate as the main block. If validators vote for two blocks simultaneously, they are penalized, which is why Ethereum is the only PoS chain with a slashing mechanism. Combined with the checkpoint mechanism, Ethereum can handle very complex fork situations, identifying the main chain even if the network forks into a tree structure.</p><p>The problem is that Ethereum Casper, while adopting BFT’s strengths, also inherits BFT’s drawbacks, namely the high communication volume. BFT’s communication volume is O(n<sup>2</sup>), generally supporting a network of fewer than 100 nodes, as detailed in <a href="https://ar5iv.labs.arxiv.org/html/2303.11045">this report</a>.</p><p>We can roughly compare the message volumes of BFT and Ethereum Casper.</p><p>BFT at 100 nodes has a throughput of about 50 tps, with message inflation O(n<sup>2</sup>), leading to a message volume of:</p><pre><code>n = (100^2) * 50)  = 500000  = 0.5 M/s</code></pre><p>Ethereum Casper with 2 million validators and a 50% voting rate, with a block time of 12 seconds and 64 committees, has a message inflation O(n), resulting in a message volume of:</p><pre><code>n = 2M * 0.5 / 12 * 64  = 1000000 / 12 * 64  = 5 M/s</code></pre><p>This calculation is rough and imprecise, differing by an order of magnitude, but considering the significant differences in implementation and hardware environments, discrepancies are normal. Overall, the difference is not too large.</p><p>Thus, Ethereum’s integration of BFT’s voting mechanism results in a high communication volume. Ethereum Casper improves BFT by incorporating the Stake mechanism, supporting tens of thousands of nodes.</p><p>Notably, Ethereum Casper’s message inflation is only O(n) because it requires only one round of voting.</p><p>Additionally, the committee mechanism is somewhat similar to the layered consensus of consortium chains. Some domestic companies improve blockchain technology without the token concept, but BFT algorithms can only support dozens of nodes, leading to layered consensus based on BFT. The basic idea is to select a subset of nodes as proposal nodes to produce blocks and vote, while other nodes only receive data. The consensus group (proposal nodes) is rotated periodically.</p><p>For consortium chains, VRF + BFT + layered consensus is a relatively complete technical combination.</p><p>In contrast, Ethereum adds the Stake mechanism, where each node in a consortium chain is a validator and has a chance to produce blocks, while Ethereum requires staking a certain amount of tokens to become a validator. The committee mechanism, compared to layered consensus, retains the voting rights of each validator, only selecting representatives to aggregate votes. Layered consensus directly deprives most nodes of block-producing rights, leaving it to a few nodes.</p><p>Thus, Ethereum’s consensus can be simply understood as Stake + VRF + BFT + committee mechanism.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://arxiv.org/abs/1710.09437&quot;&gt;Casper the Friendly Finality Gadget&lt;/a&gt; is the consensus mechanism currently used by</summary>
        
      
    
    
    
    
    <category term="BFT" scheme="https://en.smallyu.net/tags/BFT/"/>
    
    <category term="Ethereum" scheme="https://en.smallyu.net/tags/Ethereum/"/>
    
  </entry>
  
  <entry>
    <title>PBFT in Blockchain Doesn&#39;t Require a Second Vote</title>
    <link href="https://en.smallyu.net/2024/06/03/PBFT%20in%20Blockchain%20Doesn&#39;t%20Require%20a%20Second%20Vote/"/>
    <id>https://en.smallyu.net/2024/06/03/PBFT%20in%20Blockchain%20Doesn&#39;t%20Require%20a%20Second%20Vote/</id>
    <published>2024-06-03T03:09:21.000Z</published>
    <updated>2025-08-06T10:38:27.722Z</updated>
    
    <content type="html"><![CDATA[<p>Why does PBFT require two rounds of voting, and what is the role of the second vote? This question has puzzled me for a long time.</p><h3 id="Reverse-Deduction"><a href="#Reverse-Deduction" class="headerlink" title="Reverse Deduction"></a>Reverse Deduction</h3><p>From this perspective, in what situations does the second vote play a role? It only plays a role when the results of the second vote differ from the first. If the second vote’s results are strictly consistent with the first, then there is no need for a second vote.</p><p>So, in what situations would the second vote’s results differ from the first? Only when malicious nodes exist and deliberately cast different votes in the second voting phase will the results differ.</p><p>This is the conventional operational flowchart of traditional PBFT, where node 3 is a faulty or malicious node and does not respond from beginning to end:</p><img src="1.png" width="70%"><p>This is the flowchart with the prepare phase removed, retaining only one voting process, where node 3 is still a faulty node and does not respond:</p><img src="2.png" width="60%"><p>The key is that in this scenario, nodes 0, 1, and 2 are honest nodes and will never cast malicious votes or abstain, so the result of the commit phase will be consistent with the prepare phase. Thus, even if the prepare phase is removed, the system will eventually reach a consensus.</p><p>Node 3 has always been a malicious node. If, during the commit phase, any of the nodes 0, 1, or 2 cast votes that differ from the prepare phase, it means that there are more than one malicious node in the system, exceeding the fault tolerance capability.</p><h3 id="Forward-Understanding"><a href="#Forward-Understanding" class="headerlink" title="Forward Understanding"></a>Forward Understanding</h3><p>To prove that the second vote is necessary is equivalent to stating that without the second vote, the system will not function correctly.</p><p>Logically, even if the second vote has various benefits, such as increasing the system’s fault tolerance through redundancy, quickly identifying errors, and promptly adjusting to a consistent state, it does not prove that the second vote is indispensable. For example, in the high-voted answer in <a href="https://cs.stackexchange.com/questions/54152/why-is-the-commit-phase-in-pbft-necessary">Why is the commit phase in PBFT necessary?</a>, many points are mentioned, but it mainly explains the design and function of the commit phase from a positive perspective.</p><p>A more plausible explanation I’ve found is here: <a href="https://stackoverflow.com/questions/51125238/pbft-why-cant-the-replicas-perform-the-request-after-2-3-have-prepared-why-do">PBFT: Why can’t the replicas perform the request after 2&#x2F;3 have prepared? Why do we need the commit phase?</a> </p><p>It mentions that without the commit phase, nodes cannot ensure the order of request execution during a view change.</p><p>I think the description on StackOverflow differs from the meaning of the high-voted answer. The high-voted answer implies that nodes’ execute phases become inconsistent without the commit phase, with some being faster and others slower. However, even with two rounds of voting, nodes might fail after the commit phase but before execution, causing execution differences. Therefore, this type of failure is not the critical scenario.</p><p>A more reasonable scenario is mentioned in the paper <a href="https://pmg.csail.mit.edu/papers/bft-tocs.pdf">Practical Byzantine Fault Tolerance and Proactive Recovery</a>. During a view change, different requests might use the same sequence number and be packaged into different views.</p><blockquote><p>Replicas may collect prepared certificates in different views with the same sequence number and different requests. The commit phase solves this problem as follows.</p></blockquote><h3 id="Single-Vote-Process"><a href="#Single-Vote-Process" class="headerlink" title="Single Vote Process"></a>Single Vote Process</h3><p>This scenario is based on a single vote process, meaning there is no prepare phase.</p><h4 id="Scenario-Setup"><a href="#Scenario-Setup" class="headerlink" title="Scenario Setup"></a>Scenario Setup</h4><p><strong>View V1</strong></p><ol><li>R1 proposes proposal P and broadcasts it to R2, R3, and R4.</li><li>Proposal P is executed by R2, R3, and R4, but not by R1.</li></ol><pre><code>R1: –R2: P –&gt; Execute PR3: P –&gt; Execute PR4: P –&gt; Execute P</code></pre><p><strong>View Switch to V2</strong></p><ol><li>Assume R1 fails, and the view switches to V2.</li><li>R2 proposes a new proposal P’.</li><li>R2 proposes a new proposal P’ and broadcasts it to R1, R3, and R4.</li><li>The new proposal P’ is executed by all replicas.</li></ol><pre><code>R1: --      P&#39; --&gt; Execute P&#39;R2: P --&gt; Execute P      P&#39; --&gt; Execute P&#39;R3: P --&gt; Execute P      P&#39; --&gt; Execute P&#39;R4: P --&gt; Execute P      P&#39; --&gt; Execute P&#39;</code></pre><h4 id="Specific-Example"><a href="#Specific-Example" class="headerlink" title="Specific Example"></a>Specific Example</h4><p>Assume proposals P and P’ are operations on the same account balance:</p><ul><li>Proposal P: Increase account A’s balance by 10 units.</li><li>Proposal P’: Decrease account A’s balance by 5 units.</li></ul><p>The order of operations and results in views V1 and V2 are as follows:</p><p><strong>View V1</strong></p><pre><code>R1: Account A balance = 100 (P not executed)R2: Account A balance = 110 (P executed)R3: Account A balance = 110 (P executed)R4: Account A balance = 110 (P executed)</code></pre><p><strong>View V2</strong></p><pre><code>R1: Account A balance = 100 (P not executed) –&gt; Execute P’ –&gt; Account A balance = 95R2: Account A balance = 110 (P executed) –&gt; Execute P’ –&gt; Account A balance = 105R3: Account A balance = 110 (P executed) –&gt; Execute P’ –&gt; Account A balance = 105R4: Account A balance = 110 (P executed) –&gt; Execute P’ –&gt; Account A balance = 105</code></pre><h4 id="Scenario-Analysis"><a href="#Scenario-Analysis" class="headerlink" title="Scenario Analysis"></a>Scenario Analysis</h4><p>Let’s repeat this sentence: Different requests (R2) use the same sequence number (R1 thinks it is P) and are packaged into different views (P’). The same sequence number should refer to the execution order, indicating which request is to be executed at the current time.</p><p>In the above scenario, the final state is indeed inconsistent due to node A’s failure.</p><h3 id="Two-Votes"><a href="#Two-Votes" class="headerlink" title="Two Votes"></a>Two Votes</h3><p>How does the two-vote process solve the problem in the above scenario?</p><ol><li>If node A fails after receiving the prepare result and before starting the commit, all nodes will not enter the execute phase.</li><li>If node A fails after receiving the commit result and before starting the execute, node A will retry executing P based on the commit result, then execute P’.</li></ol><h4 id="Scenario-Analysis-1"><a href="#Scenario-Analysis-1" class="headerlink" title="Scenario Analysis"></a>Scenario Analysis</h4><p>Did you notice a bit of unfairness in point 2?</p><p>In the two-vote scenario, node A can retry executing P based on the commit result.</p><p>In the single-vote scenario, node A does not retry executing P based on the commit result but directly executes P’.</p><p>Therefore, the two-vote process does not completely avoid state inconsistencies caused by node failures before execution. It merely adds an extra communication step to repeatedly confirm that other nodes’ states are consistent with its expectations, reducing the risk of state inconsistency.</p><p>The two-vote process advances the time for detecting faults. If node A does not cast a vote in the commit phase, other nodes will know that node A has failed, rather than waiting until they have executed and then discovering that node A has not executed. More confirmation means more security, reducing the cost of system rollback after execution and trying to agree as much as possible before execution. This is probably the greatest role of the two-vote process.</p><p>Overall, the second vote never seems to demonstrate an indispensable significance but merely brings some benefits and enhances system security. This issue might be similar to why TCP requires three-way handshakes to establish a connection. Wouldn’t two be enough? Perhaps even one is sufficient, but it could cause some problems. Three confirmations are sufficiently secure.</p><h3 id="Stateless-vs-Stateful"><a href="#Stateless-vs-Stateful" class="headerlink" title="Stateless vs. Stateful"></a>Stateless vs. Stateful</h3><p>Why does PBFT require repeated confirmations to avoid state inconsistencies after execution? Maybe because any system rollback is a very cautious task, so the cost of communication before execution is increased.</p><h4 id="Stateless"><a href="#Stateless" class="headerlink" title="Stateless"></a>Stateless</h4><p>Returning to the single-vote scenario above, under what circumstances would the faulty node A not execute P’?</p><ol><li>Node A knows it failed to execute P.</li><li>Node A must execute P before executing P’.</li></ol><p>If these two conditions are met, even with a single vote, the same effect as the two-vote process can be achieved.</p><p>For stateless systems, if a node only records a final number, it would be quite difficult. The node knows it has not executed P and then receives a P’, but cannot distinguish whether P’ should be executed after P or is on an equal level with P.</p><p>The normal sequence is:</p><pre><code>O -&gt; P -&gt; P&#39;</code></pre><p>For node A, knowing it has not executed P but receives a P’:</p><pre><code>O -&gt; (P&#39;)?</code></pre><p>Should it execute? Node A does, and the state becomes chaotic.</p><p>For this reason, the execution in stateless systems is very cautious.</p><h4 id="Stateful"><a href="#Stateful" class="headerlink" title="Stateful"></a>Stateful</h4><p>Blockchain is a stateful system that naturally records its execution records (blocks) and enforces the ordering of requests (block hash, parent hash).</p><p>When a node receives a block, it can determine the position of the block, whether it should be executed in the current round, and whether it is missing blocks, promptly synchronizing the blocks from other nodes.</p><p>Therefore, in the context of blockchain, if the goal is merely to achieve the final state consistency of most nodes, a second vote is not necessary.</p><h3 id="Doubts"><a href="#Doubts" class="headerlink" title="Doubts"></a>Doubts</h3><p>Why does PBFT require two votes? This question lies at the knowledge boundary of GPT-4. If you ask it in detail, it will start making up answers, which is typical of GPT-4 when it does not know the answer.</p><p>With my limited internet search capabilities, I have never found a convincing reason that proves the second vote in PBFT is necessary.</p><p>After repeated deductions, the conclusion I have reached is that a second vote is not necessary, and a single vote can also achieve the same majority node consistency.</p><p>But why, for so long, have PBFT and various variants such as Tendermint and HotStuff retained the two-vote process? Why has no one ever questioned the necessity of the second vote?</p><p>Where exactly am I wrong? Perhaps my understanding of PBFT is not deep enough, and I have not touched upon the scenarios where the second vote truly plays a role. But if such scenarios exist, why can’t I find material that directly describes these scenarios?</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Why does PBFT require two rounds of voting, and what is the role of the second vote? This question has puzzled me for a long</summary>
        
      
    
    
    
    
    <category term="BFT" scheme="https://en.smallyu.net/tags/BFT/"/>
    
  </entry>
  
  <entry>
    <title>Developer&#39;s Mindset</title>
    <link href="https://en.smallyu.net/2024/05/30/Developer&#39;s%20Mindset/"/>
    <id>https://en.smallyu.net/2024/05/30/Developer&#39;s%20Mindset/</id>
    <published>2024-05-30T05:46:26.000Z</published>
    <updated>2025-08-06T10:38:27.645Z</updated>
    
    <content type="html"><![CDATA[<p>Prelude: “<a href="https://www.yinwang.org/blog-cn/2015/02/01/creative-thinking">Creative Thinking</a>“ — Wang Yin</p><hr><p>I’ve noticed a phenomenon: when you say A is good, someone will say A is not as good as B, so A is not good.</p><p>The first case is when you say SOL’s technology is better than BNB’s, it will spark controversy. Some people use the fact that SOL has experienced several outages to prove that SOL’s technology is not good. Others say that trading coins is not technology-driven but capital-driven, and that technology is not important. These viewpoints reflect their respective positions.</p><p>From a developer’s perspective, no one would regard BNB as a blockchain because it is a platform coin, with centralized node operations and an operational model that is not blockchain-like. Technically, it forked Geth’s code with some modifications, and adopted PoS earlier than Geth to increase control over the entire chain. After ETH completes the Cancun upgrade, BNB also imitated and implemented its own BIP-4844, clearly belonging to the same technical system as ETH.</p><p>Another perspective is that after ETH’s ETF is close to approval, people start discussing whether the next ETF will be for DOGE, SOL, or even DOT, but no one mentions BNB, which fully demonstrates that BNB is different from other public chains and not in the same track. To determine whether two products belong to the same track, one can see if there is a competitive relationship where one must die for the other to live. If BNB uses ETH’s technology but hopes ETH dies, it is illogical. The normal logic should be hoping ETH gets better, and BNB will also benefit.</p><p>From a user’s (trader’s) perspective, it doesn’t matter what technology you use or how good your technology is. A meme can be in the top ten in market value, a dog with a hat can be worth billions, I will go where the investors are, I will buy what capital speculates, FOMO is the way to go.</p><p>The second case is when you say SOL’s technology is good, others will say ETH is better, so SOL is not good.</p><p>It’s the same issue of perspective. From a user’s point of view, there are countless reasons to compare the pros and cons of two projects. When you say A is good, someone can always find a B that is better than A or a C that is better than A in some aspect. Using such techniques, they can defeat anyone or any project. There is also a huge space for controversy and a hierarchy of disdain, just like whether PHP is the best language in the world.</p><p>But from a developer’s perspective, if I want to develop a chain, my chain needs to compare technology and compete for the market with SOL. Can I do better than SOL? Certainly not. So, from this standpoint, isn’t it reasonable for me to say SOL’s technology is pretty good?</p><p>SOL here is just an example. Actually, any established public chain in the top 100 of CMC has some highlights, especially those that pioneered and tried different consensus algorithms. They may not be as well-known as ETH and SOL, but they have also achieved good results.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Prelude: “&lt;a href=&quot;https://www.yinwang.org/blog-cn/2015/02/01/creative-thinking&quot;&gt;Creative Thinking&lt;/a&gt;“ — Wang Yin&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;I’ve</summary>
        
      
    
    
    
    
    <category term="Mindset" scheme="https://en.smallyu.net/tags/Mindset/"/>
    
  </entry>
  
  <entry>
    <title>Key Points of Issuing Cryptocurrency</title>
    <link href="https://en.smallyu.net/2024/05/26/Key%20Points%20of%20Issuing%20Cryptocurrency/"/>
    <id>https://en.smallyu.net/2024/05/26/Key%20Points%20of%20Issuing%20Cryptocurrency/</id>
    <published>2024-05-26T14:31:26.000Z</published>
    <updated>2025-08-06T10:38:27.718Z</updated>
    
    <content type="html"><![CDATA[<p>First, here are two additional tips about investing in cryptocurrencies:</p><ol><li><p>Whether you are using Bitcoin, fiat currency, or another cryptocurrency as your base, it mainly depends on what you have on hand and which currency is easily accessible. The logic of having no silver bullet applies in any situation.</p></li><li><p>With ETH’s ETF halfway approved, it implies that the SEC might accept PoS, but the ETF funds cannot be used for staking (I still don’t understand why). Previously, I mentioned selecting from the top 100 on CMC, and it might need another condition: the cryptocurrency should not have been labeled as a security by the SEC. Maybe after personnel changes or new laws pass, cryptocurrencies will no longer be under the SEC’s jurisdiction. However, at least it shows that under the same standards, many cryptocurrencies have obvious problems. ETH has always been in an ambiguous state, so its current situation with the ETF is quite complicated.</p></li></ol><p>There are actually only a handful of safe and reliable cryptocurrencies. For example, DOT has a low profile, and the SEC has never defined DOT, but its staking rate has reached 57% of its circulation, maintaining an annual yield of 17%. I still can’t understand what this situation implies, what the consequences of a high staking rate are, and why DOT’s yield can be so high. If all holders receive the annual yield equally, wouldn’t it be equivalent to inflation, causing the price to drop? For the network, the higher the staking rate, the safer it is. However, the fewer coins in circulation, the less useful the coin is, and it cannot even be used for transaction fees. Such incomprehensible cryptocurrencies are also not worth buying.</p><p>Now, about issuing cryptocurrencies. Recently, I inadvertently listened to a recording of Li Xiaolai that was circulating online, and it was quite enlightening.</p><p>The core point of all cryptocurrencies is just one: to distribute the coins in a valuable way. The price of the coin is determined by what the holders believe it is worth. As long as holders do not sell, the price will not fall. Including BTC, it is distributed through mining, every 10 minutes, a fixed amount regardless of how many participants, with one winner every 10 minutes, adding randomness and encouraging active participation.</p><p>ETH is also distributed through mining, with block rewards every 12 seconds given to miners, similar to BTC. ETH’s two major black marks are:</p><ol><li>The development team pre-mined an unknown amount, and the ICO distributed tokens at a low price to many people in a black-box manner.</li><li>The unlimited issuance model, with no cap on the total supply, potentially causing inflation and implying that the development team can print money continuously.</li></ol><p>Li Xiaolai issued a coin called Caddy, collaborating with a community of millions of real users, selling it to them at one-tenth the price and encouraging them to like, share, and hype news online. Li Xiaolai himself said that to successfully plan a coin, being an influencer with traffic and influence is a crucial condition. Li Xiaolai, being an influencer, frequently publishes books, gives speeches, and is a well-known teacher at New Oriental, has a strong background.</p><p>The point about being an influencer ultimately attracts a large number of fans, who recognize the coin, and the coin reaches these fans at a certain price. Therefore, whether it’s mining, early airdrops, exchange LaunchPools, or incentive distributions, the goal is to distribute the coins to holders in a valuable way. Holders must pay a price for the coin to have value. Giving it away broadly for free makes the coin worthless, but pegging it one-to-one with the dollar makes it a stablecoin. This value must be controlled, neither too specific nor non-existent.</p><p>Additionally, tenfold or hundredfold coins have no logic. ETH’s hype is generally attributed to two main reasons: one is a national policy at the time that prevented BTC from being withdrawn from exchanges. The other is a Ponzi scheme using ETH with a daily interest rate of 1%, where many users bought ETH from exchanges and transferred it to the Ponzi scheme, driving up the price. Interestingly, during this period, ETH’s price increased by over a thousand times, and the Ponzi scheme could sustain itself for three years without collapsing.</p><p>FIL was once heavily mined in China, with its price soaring to 200. Why was the price so high? It was also due to a Ponzi scheme. Later, mining was banned in China, and now FIL has no vitality left, despite its genuinely good technology. Another example is NEO, which also rose by hundreds of times without a good technical foundation, having only a dozen centralized nodes and being written in C#, claiming to be the Chinese version of Ethereum. The main reason for its rise was also a financial scheme. The founders didn’t hold many coins, and even now, it’s evident that the coin price is periodically manipulated by the scheme.</p><p>So, technology is not the absolute priority. Technology serves as a basis for horizontal comparison. For instance, among several projects called ETA, ETB, ETC, and ETH, even a Ponzi scheme would choose a relatively reliable coin with something to hype. Then it’s up to fate.</p><p>As for gossip, many news reports state that Li Xiaolai was once the richest person in the crypto world, buying six-figure amounts of Bitcoin at a quarter of the market price, holding it for years through multiple bull and bear cycles, and finally selling it at a high price. But it’s not that simple. You can find many of Li Xiaolai’s Bitcoin lectures online, showing that he did not just buy and hold but understood Bitcoin’s complex knowledge, gave lectures, and logically believed in Bitcoin before entering the crypto world. This teaches us not to buy blindly, but to look carefully before buying, not just buying a token with a nice code on the exchange or based on promotional articles. Those who genuinely make money have a deep logical foundation and do a lot of homework.</p><p>Another version of the gossip is that Li Xiaolai organized a Bitcoin fund, raising tens of thousands of Bitcoins for private investments in mining, exchanges, and stocks, which resulted in heavy losses, with many people losing money and forming a rights group. Later, he invested in EOS and made back the money, paying off the debts at a discount. Li Xiaolai boasted about having six-figure Bitcoins, but he didn’t. The police couldn’t find them during a search, and Li Xiaolai is still restricted from leaving the country. Who knows if he really has Bitcoins? If he does, he can’t be let out. This teaches us that no one gets rich by trading cryptocurrencies. Li Xiaolai was already wealthy, and despite that, he kept engaging in various operations, investing, and running funds. Making money always involves doing things, not expecting to get rich from trading cryptocurrencies by just buying and holding. Even those who participated in Li Xiaolai’s Bitcoin fund were skeptical about Bitcoin’s future value, with many dropping out along the way. So, what about now?</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;First, here are two additional tips about investing in cryptocurrencies:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Whether you are using Bitcoin, fiat currency,</summary>
        
      
    
    
    
    
    <category term="Cryptocurrency" scheme="https://en.smallyu.net/tags/Cryptocurrency/"/>
    
  </entry>
  
  <entry>
    <title>Small Tips for Cryptocurrency Investment</title>
    <link href="https://en.smallyu.net/2024/05/04/Small%20Tips%20for%20Cryptocurrency%20Investment/"/>
    <id>https://en.smallyu.net/2024/05/04/Small%20Tips%20for%20Cryptocurrency%20Investment/</id>
    <published>2024-05-04T12:44:13.000Z</published>
    <updated>2025-08-06T10:38:28.701Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1-BTC-is-the-Industry-Baseline"><a href="#1-BTC-is-the-Industry-Baseline" class="headerlink" title="1. BTC is the Industry Baseline"></a>1. BTC is the Industry Baseline</h3><p>The existence of Bitcoin underpins the entire cryptocurrency industry. If Bitcoin were ever to be discredited, deemed unsafe, not decentralized, or valueless, the whole industry would collapse. Bitcoin has never been surpassed. In fact, except for Bitcoin, all other cryptocurrencies are altcoins, especially in the eyes of veteran miners who have experienced the era of Bitcoin alone. Altcoins started as Bitcoin imitators, trying to make certain changes, including Ethereum. Vitalik also dabbled with colored coins, started chains from PoW, and raised funds in China. Everything started from Bitcoin.</p><h3 id="2-PoW-is-Resilient"><a href="#2-PoW-is-Resilient" class="headerlink" title="2. PoW is Resilient"></a>2. PoW is Resilient</h3><p>Around April 12, 2024, due to multiple factors, generally believed to be due to skirmishes between two countries potentially leading to war, all cryptocurrencies fell by an average of about 20%. Binance’s Gainer leaderboard was entirely red, which can be simply referred to as the 412 incident.</p><p>Observing the price changes during this period, it is evident that PoW-based coins generally fell less than PoS-based coins. Led by BTC, Doge, LTC, BCH, ZEC, ETC, and ETHW all showed smaller declines. After all, PoW chains involve miners investing real computational power and hardware costs, making them reluctant to sell at low prices. PoS, on the other hand, involves staking a lot of money into servers, generating money from money, which comes relatively easily. ETH, DOT, ADA, COSMOS, and many others—about 50 of the top 100 on CMC—are PoS-based with staking functions.</p><h3 id="3-BTC-Standard"><a href="#3-BTC-Standard" class="headerlink" title="3. BTC Standard"></a>3. BTC Standard</h3><p>The basic logic of crypto trading is based on the BTC standard, meaning trading altcoins against Bitcoin’s rate. Suppose you initially have 1 BTC and believe Doge’s upcoming rise will outperform BTC. You convert BTC to Doge, wait for Doge to rise by 20%, and then convert all Doge back to BTC. Your BTC has now increased from 1 to 1.2. This is the essence of the BTC standard.</p><p>From then on, you will ignore market fluctuations, undeterred by bull or bear markets, focusing only on the amount of Bitcoin you have—be it 1, 1.2, or 0.8. Regardless of how BTC’s price changes against fiat, it will double every four years, dropping before rising again, achieving all-time highs repeatedly.</p><p>Trading based on fiat standards usually ends in losses, with many suffering significant losses. This specifically refers to spot trading; avoid contracts entirely.</p><h3 id="4-Choose-from-CMC-Top-100"><a href="#4-Choose-from-CMC-Top-100" class="headerlink" title="4. Choose from CMC Top 100"></a>4. Choose from CMC Top 100</h3><p>Focus as much as possible on coins ranked in the top 100 on Coin Market Cap (CMC) and select from these. The reasons are twofold: the probability of a severe crash is lower, and support from the ecosystem is better. Lower-ranked coins can pose issues like wallet incompatibility, making transactions difficult. Or, a contract address change (as happened recently with an AI sector coin) can leave you stuck, as the old contract still runs at 20% of the price, while the new one operates at 80%.</p><h3 id="5-Founder’s-Departure-Marks-Decentralization"><a href="#5-Founder’s-Departure-Marks-Decentralization" class="headerlink" title="5. Founder’s Departure Marks Decentralization"></a>5. Founder’s Departure Marks Decentralization</h3><p>BTC is unique because its founder remained anonymous from the start, which was a very smart move. This anonymity allowed BTC to be widely speculated upon. Why are there so many asset types on BTC, like colored coins, RGB++, Taproot Assets, inscriptions, runes, and L2 assets still competing? Because no one can come forward to define a roadmap for Bitcoin, and no one knows how it should develop next.</p><p>In contrast, ETH’s founder actively participates in global conferences and gives talks, outlining Ethereum’s roadmap and guiding L2’s technological direction. When ETH was attacked by hackers, the founder led the community to fork away the attack history and transitioned the consensus mechanism from PoW to PoS. Such influence shows that ETH is centralized. ETH cannot pass the Howey test and is likely to be classified as a security under SEC standards.</p><p>If you created a coin and promoted it, it would seem inappropriate. However, if a coin is decentralized, you can promote it freely. You just like Doge, you can promote it as you wish.</p><p>BSV’s CW also lost a lawsuit this year. Some in the community see this as positive, believing CW’s departure signifies BSV becoming truly community-driven. Regardless of BSV’s future, the departure of the founder is a significant indicator.</p><p>Another example is ETC and ETHW. Both were forked by Baory, a controversial figure, but their market value, price, and TVL are notable. During the 412 incident, these two coins showed resilience. Although buying them is risky due to lack of technical updates and low GitHub activity, their prices remain intriguing. ETC and ETHW are truly without founders and are PoW coins.</p><p>Additionally, since Ethereum transitioned from PoW to PoS, the ETH&#x2F;BTC exchange rate has been declining, from nearly 0.1 to around 0.05 now.</p><h3 id="6-Others"><a href="#6-Others" class="headerlink" title="6. Others"></a>6. Others</h3><p>Let’s take a simple comparison of the CMC top 10:</p><ol><li>BTC: Industry baseline, market cap dominance of 50%</li><li>ETH: Creator of EVM and DeFi market, with a vast ecosystem, market cap dominance of 16%</li><li>USDT: The most widely used stablecoin, backed by US Treasury reserves</li><li>BNB: The largest exchange platform token</li><li>SOL: PoH+DPoS consensus mechanism, centralized, relies on a few sequencers to order transactions before handing them to validators for packaging</li><li>USDC: The safest stablecoin, backed by gold reserves</li><li>XRP: RPCA consensus mechanism</li><li>DOGE: PoW consensus, the largest meme coin, favored by Musk</li><li>TON: Chain issued by Telegram</li><li>ADA: Founded by a famous figure, developed using Haskell, UTXO + PoS</li></ol>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h3 id=&quot;1-BTC-is-the-Industry-Baseline&quot;&gt;&lt;a href=&quot;#1-BTC-is-the-Industry-Baseline&quot; class=&quot;headerlink&quot; title=&quot;1. BTC is the Industry</summary>
        
      
    
    
    
    
    <category term="Crypto Trading" scheme="https://en.smallyu.net/tags/Crypto-Trading/"/>
    
  </entry>
  
  <entry>
    <title>Why PoW is More Decentralized than PoS</title>
    <link href="https://en.smallyu.net/2024/04/14/Why%20PoW%20is%20More%20Decentralized%20than%20PoS/"/>
    <id>https://en.smallyu.net/2024/04/14/Why%20PoW%20is%20More%20Decentralized%20than%20PoS/</id>
    <published>2024-04-13T16:50:00.000Z</published>
    <updated>2025-08-06T10:38:28.725Z</updated>
    
    <content type="html"><![CDATA[<p>I want to compare PoW and PoS from the perspective of entry barriers.</p><p>We often describe a blockchain as either permissionless or permissioned. This means whether becoming a block-producing node requires authorization or not.</p><p>PoW is universally recognized as a consensus mechanism that does not require authorization for mining. As long as you have a computer, you can join the network and start mining. If you can compute the required hash value, even if done manually, you have the right to produce blocks, and you decide which transactions to include in those blocks. Whether you can compute it is another matter.</p><p>BFT is a typical consensus mechanism that requires authorization. Many projects using BFT-like consensus directly require a CA center to issue certificates, and only nodes with certificates can undertake mining responsibilities in the network. The reason why the CA center issues a certificate to you is entirely an offline action. The authority to become a block-producing node is firmly controlled by the CA center.</p><p>There is some controversy with PoS.</p><p>The SEC once defined 66 cryptocurrencies as securities, including high-market-cap coins like SOL and ADA. However, ETH was not included, which gave many people hope and left ETH’s PoS in a somewhat ambiguous space.</p><p>A significant fact is that PoS is a permissioned consensus mechanism.</p><p>In PoS, nodes often need to stake a certain amount of tokens to become block-producing nodes, and staking these tokens is the entry barrier for PoS.</p><p>A node wanting to become a block-producing node needs to acquire many tokens. Where do these tokens come from? Either they are allocated by the project at the genesis stage or subsequently bought from miners because miners will increase the supply of tokens.</p><p>Here’s the problem: imagine an extreme scenario where all token holders are unwilling to sell their tokens. Wouldn’t the control of the entire network be in their hands? Whether they are ten people or ten thousand, it is still a closed circle. Moreover, in PoS, the more tokens you have, the greater your power, which further increases PoS’s centralization.</p><p>At this point, you might wonder, with Ethereum’s success and millions of holders, thousands of institutions managing tens of thousands of block-producing nodes, isn’t it decentralized enough?</p><p>Therefore, we must distinguish two concepts: a decentralized consensus mechanism and a decentralized blockchain. These are not the same.</p><p>Even if BFT-like consensus only supports a scale of dozens of nodes, if these nodes are distributed worldwide and held by large consortia with conflicting interests, the chain can still be considered decentralized because it is unlikely that more than two-thirds of these stakeholders will cooperate.</p><p>Similarly, Ethereum being decentralized does not mean PoS is a decentralized technology.</p><p>Why do many project teams choose PoS over PoW to issue coins? Because PoW is uncontrollable and has a high risk of being attacked. Observing the current PoW chains, almost all are forks of Bitcoin, and there are very few new ones. Most new altcoins come from Ethereum’s tech stack.</p><p>Why is PoS controllable? As long as you don’t distribute the initial funds too widely, you have control over the entire chain. Even if distributed, as long as the overall proportion is controllable, the chain remains under your control.</p><p>But then, isn’t the mining resource of Bitcoin also controlled by a few manufacturers? If they are unwilling to sell mining machines, Bitcoin would always be controlled within a certain range. Not exactly; even without advanced mining machines, you can still participate in mining. Accumulating many outdated mining machines can still yield high computational power. At least no one has the authority to deprive you of the qualification to become a block-producing node.</p><p>In contrast, PoS is different; without enough money, you do not qualify to become a block-producing node. If token holders are unwilling to sell, you cannot obtain this qualification no matter how much effort you put in. PoS is essentially a consensus mechanism where the door is closed, and everyone negotiates internally, randomly selecting a block-producing node among qualified nodes and then voting.</p><p>What if there is a PoS without an entry barrier? All nodes are block-producing nodes, and one is randomly selected each round to produce blocks. This mechanism would inevitably suffer from Sybil attacks, eventually becoming a game of competing node numbers. Competing node numbers are not necessarily bad, as the number of nodes ultimately reflects hardware resources. Nodes with more hardware resources have a higher chance of being selected. I think such a consensus mechanism has further room for thought, but it faces many practical issues, such as how to use VRF to select the next block-producing node and whether the required network bandwidth for such a large number of block-producing nodes is supported by existing technology. Also, a PoS without an entry barrier is not really PoS.</p><p>15 years have passed, and Bitcoin has never been surpassed…</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;I want to compare PoW and PoS from the perspective of entry barriers.&lt;/p&gt;
&lt;p&gt;We often describe a blockchain as either permissionless or</summary>
        
      
    
    
    
    
    <category term="Consensus Mechanism" scheme="https://en.smallyu.net/tags/Consensus-Mechanism/"/>
    
  </entry>
  
  <entry>
    <title>What a Bull Market Means for the Average Person</title>
    <link href="https://en.smallyu.net/2024/03/13/What%20a%20Bull%20Market%20Means%20for%20the%20Average%20Person/"/>
    <id>https://en.smallyu.net/2024/03/13/What%20a%20Bull%20Market%20Means%20for%20the%20Average%20Person/</id>
    <published>2024-03-13T15:58:55.000Z</published>
    <updated>2025-08-06T10:38:28.718Z</updated>
    
    <content type="html"><![CDATA[<p>If you held some cryptocurrencies during the market downturn, the biggest significance of a bull market is that it allows your limited assets to gain in value.</p><p>If you are a Bitcoin believer, the biggest significance of a bull market is to prove that your faith is correct and that your foresight from a few years ago was valid. But that’s about it if you didn’t invest a lot of money back then.</p><p>Many people now regret not buying more Bitcoin at 38K when they see it at 70K. But a year ago, would you have dared to buy Bitcoin at 38K? Probably not. Who knew how much lower it could go at that time? If I told you Bitcoin would rise to 200K in a year, would you dare to buy it now? Still, probably not. It’s simple; no one can predict the future. Only in hindsight does everyone look like a stock market genius.</p><p>Recently, Bitcoin has trended on Weibo twice. People start paying attention when prices rise. I’ve also watched ETH drop from 3400 to 1800 and then climb back to 4000. But really, what kind of change does such volatility bring? Turning 10K into 20K? It doesn’t seem to mean much.</p><p>Bull markets are often accompanied by many get-rich-quick stories. In my understanding, there are several ways to make money:</p><ol><li><p>Trading, holding spot, and value investing. This is relatively stable with controlled risks but limited returns. How much you dare to invest depends on how much investable funds you have. Don’t be fooled by whales making millions; their actual assets are at least five times more than their investments. Similarly, the returns for ordinary people are limited. Betting your house on Bitcoin is gambling. Usually, people who make and lose a lot of money do so in a cycle. Only a few can stop at the right time, and those who can already have self-control beyond human nature.</p></li><li><p>Leveraging contracts. This type of trading should be done with small amounts, like 10 or 20 bucks for fun. If you want to make money, don’t touch it. You could lose all your money and not get it back. Market makers can do it if they can control the market, but that’s not for ordinary people.</p></li><li><p>Issuing meme coins. Jumping on the current trend, anything hot can be turned into a coin: AI coin for new AI tech, ROCKET coin if Musk tweets a rocket photo. There will always be players who buy for the hype. This method relies heavily on luck. Additionally, you need some operational and technical skills, like setting up trading pools and promoting on social media, along with some graphic design skills to create a decent logo.</p><p> Even if it’s not a meme coin, issuing a low-quality token can make money as long as people are willing to play and buy it. However, this requires some costs for technology, graphics, and operations. Many get-rich-quick stories stem from such coins. I’ve seen people succeed with this, but I don’t envy them because I know I can’t make that kind of money.</p></li><li><p>Phishing websites. This is outright illegal and requires hacking skills and experience, so it’s not an option.</p></li><li><p>Airdrop hunting. Now, airdrop hunters have turned it into a small industry, participating in early projects on a large scale. This is highly random and requires luck. Many people spent money on transaction fees and ended up with nothing. Moreover, it’s about the return on investment. Some airdrop hunters make millions on a single project, but they must have substantial assets to invest. Given the opportunity, most people wouldn’t have enough money to capitalize on it. I don’t engage much in airdrop projects, perhaps due to a lack of information.</p></li><li><p>DeFi. Earning yields by staking funds on platforms to earn interest. This carries the risk of the project rug-pulling, so you need to choose reliable projects.</p></li><li><p>MEV (Miner Extractable Value). This multi-billion-dollar market is already targeted by experienced players, and making money from it might require competing on speed.</p></li><li><p>Developing a technically demanding project and being a core developer, receiving initial token allocations and waiting for their value to multiply. This method is safer but rare, especially in the current market where few dare to start new developments. Most projects are integrations of existing technologies. Projects with significant contributions in specific technical directions are not only rare but also have high technical barriers, which are beyond the reach of ordinary people.</p></li><li><p>Regular work, steady job. Working in a crypto exchange is not much different from working in an internet company, with the main differences being the non-traditional office environment and getting paid in tokens.</p></li><li><p>Mining. Mining might not be profitable anymore.</p></li></ol><p>There are two types of bull markets: one driven by favorable policies leading to price increases, and another driven by new technologies attracting more players. The current bull market is the former. Besides crazy prices, no significant new technologies or phenomena have emerged. Apart from price changes, nothing else seems to have changed. Or, you could say, we’re still in the early stages of the bull market, and those who dare should quickly invest more :P</p><p>Another point is that a bull market attracts more capital, leading to more new projects and companies, possibly creating more job opportunities. Lately, some small, obscure companies have appeared, suggesting the job market might be slightly improving. However, these small companies likely work on the usual types of projects…working anywhere is the same. For those facing layoffs, the job market might feel a bit easier.</p><p>For the average person, the current bull market doesn’t seem to mean much. Tonight, Ethereum completed the Cancun upgrade, and it’s unclear if this will trigger another Layer 2 boom. I’m not much of an Ethereum believer; Layer 2 feels incomplete to me, and Ethereum now focuses on Layer 2 development. Similarly, some companies are working on Bitcoin Layer 2 projects, which I’m also not optimistic about. Bitcoin Core isn’t interested in scaling and could make BRC-20 projects disappear entirely.</p><p>So, should we believe in Bitcoin? It seems Bitcoin doesn’t relate much to the average person either. I hope a project representing faith will emerge.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;If you held some cryptocurrencies during the market downturn, the biggest significance of a bull market is that it allows your limited</summary>
        
      
    
    
    
    
    <category term="Cryptocurrency" scheme="https://en.smallyu.net/tags/Cryptocurrency/"/>
    
  </entry>
  
  <entry>
    <title>Recent Work in the Past Six Months</title>
    <link href="https://en.smallyu.net/2024/02/17/Recent%20Work%20in%20the%20Past%20Six%20Months/"/>
    <id>https://en.smallyu.net/2024/02/17/Recent%20Work%20in%20the%20Past%20Six%20Months/</id>
    <published>2024-02-17T02:49:03.000Z</published>
    <updated>2025-08-06T10:38:28.692Z</updated>
    
    <content type="html"><![CDATA[<p>The main work over the past six months has focused on three main tasks.</p><h4 id="Building-the-Abstract-Account-ERC-4337-Project"><a href="#Building-the-Abstract-Account-ERC-4337-Project" class="headerlink" title="Building the Abstract Account (ERC-4337) Project"></a>Building the Abstract Account (ERC-4337) Project</h4><p>An AA account is essentially a smart contract that implements features such as zero fees and social recovery through additional bundler and paymaster components. ERC-4337 defines a set of standards, including the interfaces that the contract must support, how the bundler interacts with the contract, and the role of the paymaster. Currently, there are roughly three to five different implementations for each component, with some variations in details, but all follow the ERC-4337 standard.</p><p>Last year, the concept of abstract accounts gained some popularity, possibly because Vitalik mentioned Soulbound. Project teams used AA accounts as a solution for Soulbound, creating some hype. Innovations like ERC-4337, which define standards rather than change the underlying technology, generally don’t have long-lasting impacts. It’s a series of standardized usage methods. While it might provide short-term solutions, it’s not a bad thing.</p><h4 id="Using-Op-Stack"><a href="#Using-Op-Stack" class="headerlink" title="Using Op Stack"></a>Using Op Stack</h4><p>Since Optimism open-sourced the entire Op Stack toolkit, launching an Optimistic Layer 2 has become easier. This led to the trend of one-click chain launches last year, with Base, opBNB, and others going live in a short period. Although Optimism’s Fault Proof is not yet perfect, even a slightly centralized project can be stable enough. The Op Stack can fully support launching your own network.</p><p>We ran AA accounts on a Layer 2 network, which supported a small gaming event. Despite some challenges along the way, we gained valuable experience. Diving deeply into these two types of projects is impossible within a limited timeframe, as each direction can be a specialized field. Currently, the status is barely usable.</p><p>However, have you noticed that concepts like AA accounts and one-click chain launches are short-lived? They were hot last year, but no one talks about them this year. This year, the focus has shifted to Bitcoin’s Layer 2, inscriptions, ERC-404, etc. Hot topics are always changing.</p><h4 id="Building-an-Ethereum-PoS-Network"><a href="#Building-an-Ethereum-PoS-Network" class="headerlink" title="Building an Ethereum PoS Network"></a>Building an Ethereum PoS Network</h4><p>Since The Merge, building the Ethereum network has become more complex. Although it saves the computational power consumption of mining, it requires the introduction of a complex validator governance mechanism to ensure orderly block production. PoS inevitably involves issues like becoming a validator and determining valid validators. Previously, nodes were divided into two types, execution layer and consensus layer. PoS solves the ungraceful block production issue of PoW, but at the cost of a complex set of rules.</p><p>Ethereum is currently the most diverse ecosystem chain, with five or six clients each for the execution layer and consensus layer, all implementing standard interfaces but with different experiences, especially in performance. A lot of time was spent testing each client.</p><p>Ethereum’s greatest asset is the EVM, not PoS. EVM compatibility has become a selling point for various chains. PoS was not invented by Ethereum; Cardano used PoS from the start and retained the UTXO model. Occasionally, people say Bitcoin and Cardano are the future. Compared to Ethereum, Cardano’s consensus mechanism is more like a Bitcoin alternative rather than Ethereum.</p><p>Bitcoin and Ethereum belong to two camps. Bitcoin focuses on cryptocurrency, while Ethereum explores applications beyond currency. Under each camp, many altcoins are active.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;The main work over the past six months has focused on three main tasks.&lt;/p&gt;
&lt;h4 id=&quot;Building-the-Abstract-Account-ERC-4337-Project&quot;&gt;&lt;a</summary>
        
      
    
    
    
    
    <category term="Work" scheme="https://en.smallyu.net/tags/Work/"/>
    
  </entry>
  
  <entry>
    <title>How to Work Remotely in a Healthy Way</title>
    <link href="https://en.smallyu.net/2023/10/10/How%20to%20Work%20Remotely%20in%20a%20Healthy%20Way/"/>
    <id>https://en.smallyu.net/2023/10/10/How%20to%20Work%20Remotely%20in%20a%20Healthy%20Way/</id>
    <published>2023-10-09T16:39:09.000Z</published>
    <updated>2025-08-06T10:38:27.708Z</updated>
    
    <content type="html"><![CDATA[<p>In the past two months, I’ve been working remotely. However, remote work isn’t as glamorous as many imagine, like wearing swimsuits on the beach and closing million-dollar deals with a laugh. Remote work simply means a different office location. The work system and processes depend on the company’s and team’s culture and atmosphere, which we’ll not discuss here.</p><p>Remote work has its pros and cons compared to on-site work. One advantage is the convenience of creating a comfortable work environment. For instance, if the height of the desk isn’t right, you can change it to one that suits you, which isn’t easy to do with an office desk.</p><p>However, there are downsides too. For example, having the same place for living and working can blur the boundaries between life and work. I’ve had extreme situations where I was stuck on a bug with no clues, feeling frustrated. I went to bed but couldn’t sleep, got up at 1 AM to debug for an hour, made some progress, went back to sleep, and continued debugging at 8 AM the next day, then worked for the whole day. This is very unhealthy behavior that must be avoided.</p><p>To address and resolve bad habits, clear and feasible rules are needed to regulate personal behavior. As participants, we should know how to maintain our physical and mental health while working remotely.</p><h3 id="Work-Location"><a href="#Work-Location" class="headerlink" title="Work Location"></a>Work Location</h3><p>Because a suitable work environment is necessary, you can’t choose your work location too freely. Working in a mall, coffee shop, library, or study room is inappropriate. Not only do you need to buy coffee, but such seating isn’t suitable for long hours, and having video meetings in public places is inconvenient. Especially for programmers, you need a 27-inch external monitor, an ergonomic chair, and a focused environment. If you work late, coffee shops won’t be open, which is problematic.</p><p>Shared offices like WeWork have limited options and are very expensive, costing 100 to 300 yuan per day. Long-term use is costly, and many shared offices don’t allow you to store personal items. The industry is not mature and not a good choice.</p><p>Overall, the work location can only be in your own room. If you own a house with a spare study or room, that room can be used as a work location.</p><p>If you’re renting, the situation is slightly worse. Generally, you’d only rent a bedroom, so your desk becomes your workspace. Renting another room specifically for remote work is costly. Providing a workspace is originally the company’s responsibility, so passing this cost onto employees is unreasonable.</p><p>Another solution is to move to a low-cost city. Since remote work isn’t location-bound, reducing expenses while improving quality of life is feasible. However, this only applies if you have no friends in your current city. Otherwise, even for one person, you can’t change cities.</p><h3 id="Clear-Boundaries-Between-Life-and-Work"><a href="#Clear-Boundaries-Between-Life-and-Work" class="headerlink" title="Clear Boundaries Between Life and Work"></a>Clear Boundaries Between Life and Work</h3><p>On-site work offers a clear distinction between life and work as you move between home and the office. You may feel that no matter how tired you are, home is for rest. You might leave your computer at the office, not bring it home, or the work environment might be on the company intranet, making it impossible to work from home. Various reasons create a clear distinction between work time and personal time.</p><p>However, remote work blurs these boundaries. Imagine having a bed next to your office desk at work, with all living essentials provided. Waking up to see your desk is terrifying.</p><p>Imagine living a whole day, starting work an hour after waking up, ending work two hours before bed, and spending all your non-working time in the same room. It’s a maddening scenario.</p><p>The most important aspect of remote work is ensuring clear boundaries between life and work. Here are some behaviors to achieve this:</p><ul><li>Get up on time and reserve “commute” time.</li><li>Take a walk during your usual commute time, pretending to commute. Don’t sleep in.</li><li>Dress in proper clothes and shoes for work, not home wear or pajamas. Be ready to go out at any time.</li><li>Adjust the external webcam to indicate work time.</li><li>Turn on a desktop clock to indicate work time.</li><li>Open the window to indicate work time.</li><li>After work, take a walk to end the workday.</li><li>After work, mop the floor so it’s wet.</li><li>Don’t do work-related tasks on your computer after work.</li><li>…</li></ul><p>These actions aren’t specific or necessarily good, just examples. The point is to send yourself clear signals through a series of physical actions. After four or five actions, you’re in work mode; after another four or five, you’re off work. Relying solely on time concepts to switch between work and personal time is difficult. Self-disciplined people might manage it, but if you can’t, rely on physical behaviors to create boundaries.</p><h3 id="Outdoor-Activities"><a href="#Outdoor-Activities" class="headerlink" title="Outdoor Activities"></a>Outdoor Activities</h3><p>As mentioned earlier, taking a walk during your usual commute time helps maintain a similar routine to on-site work and, more importantly, ensures you spend enough time outdoors for health. Even a simple walk is better than staying home all day.</p><p>Some think the benefit of remote work is saving commute time for more sleep. This is wrong. The extra time should be used for exercise. No one can stand staying home all the time.</p><h3 id="Social-Activities"><a href="#Social-Activities" class="headerlink" title="Social Activities"></a>Social Activities</h3><p>After starting remote work, I even began to suspect that talking to people is a physiological need. Maybe due to serious work, spending the whole workday in the same place without seeing people or talking makes me extremely eager to go out and play on weekends.</p><p>It’s not about how fun the games are but about changing the environment, relaxing, meeting different people, playing different games, and doing things unrelated to work.</p><h3 id="Pomodoro-Technique"><a href="#Pomodoro-Technique" class="headerlink" title="Pomodoro Technique"></a>Pomodoro Technique</h3><p>In an office, various small events—someone talking to you, passing by your desk, making noise, or you getting a drink, buying a beverage, or using the restroom—distract you and break your concentration. These interruptions can be annoying but prevent prolonged focus.</p><p>Too much focus isn’t good. It dulls the mind and pressures the body, causing back and neck pain. People need to stand and stretch periodically.</p><p>The Pomodoro Technique means working for 25 minutes and resting for 5, which is one Pomodoro. This time distribution is popular for a reason—it’s effective.</p><p>Don’t use software like Stretchly that pops up on the screen. It’s frustrating and you’ll likely close it. Even with a 30-second warning, it doesn’t improve the experience. If you can’t stop within 30 seconds, the break is ineffective. Pop-ups covering the screen can cause slight anxiety, worrying about missing messages or screen updates.</p><p>Instead, use a countdown timer with an alarm. After 25 minutes, the alarm sounds and won’t stop until manually turned off. This persistent reminder encourages you to stand and relax. Of course, you must be disciplined enough to stand and turn off the alarm.</p><p>Sometimes, you might forget to start the timer. Setting multiple alarms to ring at specific times, like 25 and 55 minutes past each hour, can help. You don’t have to follow the alarm times strictly, but at least they remind you to rest.</p><p>Moderate breaks improve efficiency. Difficult problems often find solutions during relaxation.</p><h3 id="Ritual"><a href="#Ritual" class="headerlink" title="Ritual"></a>Ritual</h3><p>As a supplementary note, the behaviors described above create a sense of ritual. Both starting and ending work need rituals, often created by the environment. Sometimes, you can create them yourself. Life needs rituals.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;In the past two months, I’ve been working remotely. However, remote work isn’t as glamorous as many imagine, like wearing swimsuits on</summary>
        
      
    
    
    
    
    <category term="Work" scheme="https://en.smallyu.net/tags/Work/"/>
    
    <category term="Remote Work" scheme="https://en.smallyu.net/tags/Remote-Work/"/>
    
  </entry>
  
  <entry>
    <title>Why Bitcoin Doesn&#39;t Use Probabilistic Encryption Functions</title>
    <link href="https://en.smallyu.net/2023/10/04/Why%20Bitcoin%20Doesn&#39;t%20Use%20Probabilistic%20Encryption%20Functions/"/>
    <id>https://en.smallyu.net/2023/10/04/Why%20Bitcoin%20Doesn&#39;t%20Use%20Probabilistic%20Encryption%20Functions/</id>
    <published>2023-10-04T14:36:18.000Z</published>
    <updated>2025-08-06T10:38:28.722Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Probabilistic-Encryption-Functions"><a href="#Probabilistic-Encryption-Functions" class="headerlink" title="Probabilistic Encryption Functions"></a>Probabilistic Encryption Functions</h3><p>In common symmetric encryption, one plaintext corresponds to one ciphertext. There is a type of encryption called probabilistic encryption, which introduces randomness during the encryption process, resulting in one plaintext corresponding to multiple ciphertexts.</p><ol><li>Why Probabilistic Encryption Functions Are Rarely Used</li></ol><p>It’s essential to distinguish between three concepts: encryption, signatures, and hashing. Probabilistic encryption functions are a type of symmetric encryption, but in reality, encryption—whether symmetric or asymmetric—is rarely used in blockchain systems. Bitcoin’s white paper only mentions signatures and hashing; signatures are used to confirm asset ownership when initiating transactions, and hashing is used to confirm block creation during mining. It does not mention the use of encryption.</p><p>The main reason for the limited use of encryption is its limited application scenarios. Storage projects might use file encryption, but that falls under user behavior, and the blockchain system itself does not participate in data encryption protection.</p><p>Replacing signatures and hashing with probabilistic encryption functions is impossible since they do not have such capabilities.</p><ol start="2"><li>The Probability Distribution of Probabilistic Encryption Functions</li></ol><p>Where there is probability, there is a probability distribution, such as a normal distribution. For probabilistic encryption functions, a uniform probability distribution is ideal; otherwise, if the probability distribution is known, an attacker might infer the plaintext from the ciphertext, which is very dangerous. Only with consistent random strength can attackers be thwarted.</p><p>Therefore, probabilistic encryption functions have almost no choice but to strive for uniform distribution, which is a common approach.</p><h3 id="New-Style-Floor-to-Ceiling-Windows"><a href="#New-Style-Floor-to-Ceiling-Windows" class="headerlink" title="New Style Floor-to-Ceiling Windows"></a>New Style Floor-to-Ceiling Windows</h3><p>In a beautiful and harmonious animal forest, floor-to-ceiling windows suddenly became popular. These houses not only have good lighting but also boast beautiful and high-end designs. The little fox is a famous architect who can build these trendy houses with large floor-to-ceiling windows. The forest animals flock to the little fox to have houses built.</p><p>The little parrot, a jack-of-all-trades in the forest, is well-informed and eloquent. It is also the strategist beside the river’s overlord, the hippo, often giving the hippo advice. Upon hearing about the trend of floor-to-ceiling windows, the hippo also wanted to build one. However, the hippo, due to its high status, did not want to use the common design. So, it asked the little parrot to come up with an idea.</p><p>The little parrot, after much inquiry, accidentally heard the term “fiberglass,” a newly emerged synthetic material known for being shatterproof and highly resilient. Delighted, the little parrot hurriedly informed the hippo, claiming to have discovered a revolutionary new building material that could replace glass and lead the next generation of housing trends!</p><p>The hippo, satisfied, invested in and commissioned the little parrot to find someone to build the house, ensuring the construction plan remained confidential. The innovation had to be kept secret.</p><p>Hearing about this, the little fox became curious. Having built houses for years, the little fox had never heard of such a new material. It was surprising that the little parrot could make such a significant innovation. Coincidentally, the little parrot’s construction team was recruiting, so the little fox eagerly joined to participate in the hippo’s house construction team.</p><p>However, upon joining, the little fox was stunned. Fiberglass is not glass; it is opaque! How could it replace glass? If they insisted on using fiberglass, the house would be uninhabitable. If they didn’t use fiberglass, they would have to use glass, which would mean no innovation!</p><p>Eventually, the little fox left the little parrot’s construction team…</p><h3 id="Dunning-Kruger-Effect"><a href="#Dunning-Kruger-Effect" class="headerlink" title="Dunning-Kruger Effect"></a>Dunning-Kruger Effect</h3><p>The Dunning-Kruger effect is a type of cognitive bias, particularly describing the phenomenon of underestimating or overestimating one’s abilities. When experts in one field attempt to make revolutionary innovations in another field, it can be attributed to the Dunning-Kruger effect. However, there are nuances, and a more accurate description might be “overconfidence beyond one’s domain,” or more professionally, “professional illusion.”</p><p>From a psychological perspective, this phenomenon is explainable, but in reality, there is another critical factor—a kind of invisible force…</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h3 id=&quot;Probabilistic-Encryption-Functions&quot;&gt;&lt;a href=&quot;#Probabilistic-Encryption-Functions&quot; class=&quot;headerlink&quot; title=&quot;Probabilistic</summary>
        
      
    
    
    
    
    <category term="Psychology" scheme="https://en.smallyu.net/tags/Psychology/"/>
    
    <category term="Encryption" scheme="https://en.smallyu.net/tags/Encryption/"/>
    
  </entry>
  
  <entry>
    <title>The &quot;Obedience to Authority&quot; Psychology of Programmers</title>
    <link href="https://en.smallyu.net/2023/07/30/The%20%22Obedience%20to%20Authority%22%20Psychology%20of%20Programmers/"/>
    <id>https://en.smallyu.net/2023/07/30/The%20%22Obedience%20to%20Authority%22%20Psychology%20of%20Programmers/</id>
    <published>2023-07-30T14:35:34.000Z</published>
    <updated>2025-08-06T10:38:28.701Z</updated>
    
    <content type="html"><![CDATA[<p>Recently, I experienced something: I joined a startup and voluntarily resigned after working for two weeks. Although it was only a short two weeks, it felt like a long time, and I learned or realized many things from it. There are many reasons for leaving, involving specific issues, which I will continue to reflect on and summarize. Today, I thought of an interesting topic that can serve as a simple entry point. Of course, there are some inconvenient things that I won’t mention :P</p><p>I found that the programmer community generally has an “animalistic” trait: whoever has the best technical skills is the most powerful, and whoever is technically proficient, I will listen to and respect. I might even call them a god or a big boss, worship them, and believe in them. Conversely, if someone with poor technical skills becomes my team leader, technical director, or CTO, directing my work, I will not respect or be willing to listen to them. For managers, if their abilities are not convincing, it will be particularly difficult to advance things.</p><p>This issue was also mentioned by Luo Yonghao in a certain program, but I don’t remember if it was in his entrepreneurship podcast or some interview program. I specifically looked for it but couldn’t find it since he has too many quotes. At the same time, I realized that after having the experience of joining a startup and observing some phenomena, looking back at his <a href="https://www.youtube.com/@zhuangyuanli/videos">entrepreneurship podcast</a>, what he said is indeed quite valuable for startup companies.</p><p>This phenomenon is not only present in the programmer community but also in many films and TV dramas. For example, in the forest, the lion with the strongest fighting power is the king; in monkey groups, the strongest becomes the monkey king; or in a brave and skilled primitive tribe, power is contested by force, and the winner is obeyed. Similarly, in Western cowboy duels, the winner gains a certain status and symbol, and so on.</p><p>This phenomenon is called the “obedience to authority” psychology. Analyzing the word authority, authority is not actually a negative term. Although we see some opinions saying to overthrow authority and not blindly believe in authority, the authority in that context refers to those who have gained power illegitimately, those who are undeserving, and those who deceive the masses. The authority in “obedience to authority” refers to the true strong individuals within the group. Most people are not averse to true strong individuals.</p><p>Returning to workplace relationships, according to my superficial understanding, workplace relationships can be simply divided into “collaborative relationships” and “subordinate relationships.”</p><p>Typical collaborative relationships include cooperation between companies, cooperation between partners within a company, cooperation between two department heads, cooperation between two team leaders, and so on. The status is equal. In such collaborative situations, abilities can be complementary. One party has ability A, the other party has ability B, and cooperation can yield greater results. Many companies have roles like CEO, CTO, and COO, which are backed by extremely professional abilities.</p><p>Subordinate relationships are also easy to understand: between bosses and employees, between leaders and subordinates. As long as there is a superior-subordinate relationship, it belongs to a subordinate relationship. Generally, the abilities in subordinate relationships are vertical. For example, the CTO is responsible for setting the technical route and strategic direction, and frontline technical personnel complete specific work according to the plan. This belongs to different role divisions, but both the CTO and subordinates have technical backgrounds. If the company’s COO leads the technical team, wouldn’t things be messed up?</p><p>The “obedience to authority” psychology of programmers exists in subordinate relationships, requiring a vertical comparison to produce the so-called “authority.” In collaborative relationships, the abilities are not measured by the same standard, making it difficult to compare.</p><p>Since this psychological phenomenon is widespread and objectively exists, what inspiration does it offer us?</p><p>For the non-authoritative side: Understand what kind of authority you should pursue. For example, if you feel pressure from your superior at work, understand whether it is meaningful pressure or meaningless pressure. If the other party is an authority in your field, strive to improve your abilities, defeat them, and become the new authority. If the other party is not an authority in your field and is only directing you for some reason, you should resist or leave the difficult situation in time.</p><p>For the authoritative side: Understand the source of your authority. For example, technical ability is also hierarchical. If you have a broad technical vision and some non-authoritative person challenges you with how many words they can type in a minute, you can completely ignore it without worrying.</p><p>If you do not possess authoritative ability but are in an authoritative position, what should you do? Transform subordinate relationships into collaborative relationships, so you don’t have to worry about someone challenging authority, not being convincing, or someone being unconvinced. Because the “obedience to authority” psychology only exists in subordinate relationships and rarely appears in collaborative relationships. In simple terms, leaders who are not experts should know how to delegate power.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Recently, I experienced something: I joined a startup and voluntarily resigned after working for two weeks. Although it was only a short</summary>
        
      
    
    
    
    
    <category term="Programmer" scheme="https://en.smallyu.net/tags/Programmer/"/>
    
    <category term="Psychology" scheme="https://en.smallyu.net/tags/Psychology/"/>
    
  </entry>
  
  <entry>
    <title>Blockchain Technology Interview Questions</title>
    <link href="https://en.smallyu.net/2023/07/12/Blockchain%20Technology%20Interview%20Questions/"/>
    <id>https://en.smallyu.net/2023/07/12/Blockchain%20Technology%20Interview%20Questions/</id>
    <published>2023-07-11T17:01:09.000Z</published>
    <updated>2025-08-06T10:38:27.639Z</updated>
    
    <content type="html"><![CDATA[<p>Having gone through many interviews recently, I’ve noticed a common phenomenon: it’s hard to have a meaningful conversation with the interviewer. Usually, interviewers only ask about the technologies they know and care about, which are often not the ones I focus on. For example, my resume mentions work related to State channels. If an interviewer knows what State channels are, they would certainly ask about the principles of HTLC. However, only one interviewer from a company specializing in blockchain projects asked me about it. And they didn’t hire me.</p><p>Although I’ve had many interviews and been rejected many times, most of the questions I’ve been asked are heavily web2-centric technical details. Few people have stumped me on blockchain-related topics, especially those mentioned on my resume. Therefore, I don’t feel too frustrated; instead, I often complain about why they focus on things I find unimportant. If I can understand a blockchain technology that takes two to three months to master, how can I not grasp a programming language issue that takes only half an hour to understand?</p><p>So, I thought, if I were the interviewer, what questions would I ask a candidate applying for a blockchain developer position? These questions are generally applicable and can delve deeper and expand:</p><ol><li>What is Bitcoin’s consensus mechanism, and what is UTXO?</li><li>What is Ethereum’s consensus mechanism, and how is the block proposer selected?</li><li>What other chains do you know, and what are their technical characteristics?</li><li>What is the PBFT process, and which consortium chains are there in China?</li><li>What are the variants of PBFT, and which chains use them?</li><li>What are the types of Layer 2 technologies?</li><li>What are the principles of State channels and Rollups?</li><li>How is an account wallet generated, and what is a keystore file?</li><li>What are the storage-based blockchains, and what are their challenges?</li><li>What are the limitations of the Solidity language, and how does it differ from Go?</li><li>Do you understand object-oriented programming, and have you written Java?</li><li>Are there random numbers in blockchain, and how are they used?</li><li>How are contract transactions processed by the virtual machine, and how can support for another language be added?</li><li>What are eclipse attacks and Sybil attacks?</li><li>Have you studied cross-chain assets, and what is the general process?</li></ol><p>These questions do not have a specific order and are relatively basic, meant to spark further discussion. Suddenly, I remember being asked in an interview, “How are blocks connected in a blockchain?” The answer is that the next block contains the hash of the previous block. This kind of question is too elementary; let’s ask more advanced questions.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Having gone through many interviews recently, I’ve noticed a common phenomenon: it’s hard to have a meaningful conversation with the</summary>
        
      
    
    
    
    
    <category term="Blockchain" scheme="https://en.smallyu.net/tags/Blockchain/"/>
    
    <category term="Interview Questions" scheme="https://en.smallyu.net/tags/Interview-Questions/"/>
    
  </entry>
  
  <entry>
    <title>How to Distinguish Between Public Chains and Consortium Chains</title>
    <link href="https://en.smallyu.net/2023/07/12/How%20to%20Distinguish%20Between%20Public%20Chains%20and%20Consortium%20Chains/"/>
    <id>https://en.smallyu.net/2023/07/12/How%20to%20Distinguish%20Between%20Public%20Chains%20and%20Consortium%20Chains/</id>
    <published>2023-07-11T17:00:58.000Z</published>
    <updated>2025-08-06T10:38:27.708Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Short-Version"><a href="#Short-Version" class="headerlink" title="Short Version"></a>Short Version</h3><p>If it issues coins, it’s a public chain; if it doesn’t, it’s a consortium chain.</p><h3 id="Detailed-Version"><a href="#Detailed-Version" class="headerlink" title="Detailed Version"></a>Detailed Version</h3><p>Since I often dismiss consortium chains, a natural question arises: What exactly is a consortium chain? What is the fundamental difference between a public chain and a consortium chain, and where is the dividing line? I thought this was a simple question, but after careful consideration, it’s not so straightforward and not particularly easy to define clearly.</p><p>Simply put, a blockchain that is open for everyone to access and use is a public chain, while a blockchain used within a small range is a consortium chain. This distinction is like the difference between the internet and a local area network. But if a consortium chain is opened up for everyone to use, does it become a public chain? If the chain uses the original version of PBFT as its consensus mechanism, it remains a consortium chain. The distinction between public and consortium chains cannot be solely based on the size of the user group.</p><p>For example, there’s a subjective issue: what constitutes “everyone”? How large a range counts as everyone? If there are 100 people, then 100 people are everyone; does 99 count? In real life, it seems so. A chain used by 99 people cannot be said to be a consortium chain. What about 80 people? It also seems to count as a majority compared to a small group of 20 people. And 60 people? It exceeds half; can it represent everyone?</p><p>So how do you determine if a chain is a public or a consortium chain? After some thought, from a technical perspective, I believe that to be considered a public chain, the following three conditions must be met simultaneously:</p><ol><li>Network interconnectivity between nodes</li><li>Equal opportunity for each node to become a block-producing node</li><li>Reasonable threshold for becoming a block-producing node</li></ol><p>You may notice that in the short version, issuing cryptocurrency is used as the only indicator to distinguish public and consortium chains, while in the detailed version, cryptocurrency is not mentioned. This is mainly due to different evaluation dimensions. Issuing cryptocurrency is a usage pattern reflected in the entire system, while the three conditions listed above are more general technical features. A chain that meets the three conditions without issuing cryptocurrency can still be considered a public chain. However, cryptocurrency is an important incentive for miners and is generally an indispensable part of the system, so project teams usually design it into the system.</p><h4 id="Network-Interconnectivity-Between-Nodes"><a href="#Network-Interconnectivity-Between-Nodes" class="headerlink" title="Network Interconnectivity Between Nodes"></a>Network Interconnectivity Between Nodes</h4><p>This requires that nodes cannot set access permissions at the network level; anyone can access the nodes through the internet. If nodes are not deployed on the public network but run in a local area network, they do not belong to the public chain. If nodes are deployed on the public network but are limited to specified IP addresses for access and use, these nodes have set access permissions and are not open enough. If all nodes have similar settings, the entire chain is not considered a public chain.</p><h4 id="Equal-Opportunity-for-Each-Node-to-Become-a-Block-Producing-Node"><a href="#Equal-Opportunity-for-Each-Node-to-Become-a-Block-Producing-Node" class="headerlink" title="Equal Opportunity for Each Node to Become a Block-Producing Node"></a>Equal Opportunity for Each Node to Become a Block-Producing Node</h4><p>For example, in PoW, as long as the computational power is sufficient, one is recognized as a block-producing node. In PoS, as long as 32 ETH is staked, there is a chance to become a block-producing node. These are typical examples of public chains. In the original version of PBFT, block-producing nodes are fixed and cannot be changed, which belongs to consortium chains. Some chains add random consensus group changes on top of PBFT, randomly selecting nodes as consensus nodes responsible for block production at intervals. Chains with this design are public chains, though project teams need to consider the safety, fault tolerance, and risk of Sybil attacks of such approaches.</p><h4 id="Reasonable-Threshold-for-Becoming-a-Block-Producing-Node"><a href="#Reasonable-Threshold-for-Becoming-a-Block-Producing-Node" class="headerlink" title="Reasonable Threshold for Becoming a Block-Producing Node"></a>Reasonable Threshold for Becoming a Block-Producing Node</h4><p>Reasonableness is subjective and hard to quantify, requiring balance in project design. For example, in PoW, acquiring sufficient computational power to produce blocks has a high cost, which is the threshold. If the threshold is too low, nodes will easily produce blocks, causing chaos in the network. If the threshold is too high, no one can reach it, and blocks cannot be produced, which is also unsuitable. This threshold needs a balanced, appropriate position. In some PBFT consortium chains, becoming a block-producing node requires a CA-issued certificate controlled by the project team, requiring offline certification processes to join the consortium and obtain the certificate. This is a typical example of a consortium chain.</p><h3 id="Why-I-Like-Blockchain"><a href="#Why-I-Like-Blockchain" class="headerlink" title="Why I Like Blockchain"></a>Why I Like Blockchain</h3><p>Technically, blockchain has a rebellious spirit, advocating for decentralized technology with a self-contained system. Since centralized institutions are unreliable, we operate independently, first trusting ourselves, then others. In this mode, the accuracy of historical records is very high. Currently, only blockchain systems can achieve global data consistency.</p><p>In terms of asset attributes, cryptocurrency is highly resistant to geopolitical changes. You can easily hold currency assets pegged to world currencies, unaffected by local currency value fluctuations.</p><h3 id="Why-I-Don’t-Like-Consortium-Chains"><a href="#Why-I-Don’t-Like-Consortium-Chains" class="headerlink" title="Why I Don’t Like Consortium Chains"></a>Why I Don’t Like Consortium Chains</h3><p>Many domestic consortium chain projects are government-led information technology initiatives funded by the government. For instance, in a Xiongan New Area information platform project worth 20 million yuan, various technologies like AI, big data, IoT are involved, with blockchain being one aspect. Specifically, the blockchain portion might be 3 million yuan. This 3 million is not something small companies can easily secure, often requiring strong connections, like large outsourcing firms. The blockchain part includes many small components, such as a data management platform for a department, integrating blockchain for data on-chain. If the large outsourcing firm lacks blockchain development capabilities, it might subcontract 300,000 yuan to a specialized blockchain company to complete this function. The consortium chain development company ends up earning modestly, hoping to secure more projects in a year for better earnings.</p><p>These projects usually follow a bidding process, entangling multiple interests even in securing the project. The company’s overall strength is scored, including patent applications and past revenue capabilities. These projects have nothing to do with the blockchain ideology. If replaced with another term like 5G technology, the project process remains the same: bidding, project delivery, differing only in the specific technology used. That’s why I say consortium chains are not true blockchains; they use golden hoes to plow the fields.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h3 id=&quot;Short-Version&quot;&gt;&lt;a href=&quot;#Short-Version&quot; class=&quot;headerlink&quot; title=&quot;Short Version&quot;&gt;&lt;/a&gt;Short Version&lt;/h3&gt;&lt;p&gt;If it issues coins, it’s</summary>
        
      
    
    
    
    
    <category term="Public Chains" scheme="https://en.smallyu.net/tags/Public-Chains/"/>
    
    <category term="Consortium Chains" scheme="https://en.smallyu.net/tags/Consortium-Chains/"/>
    
  </entry>
  
  <entry>
    <title>Response to Ideas on Layer 2 Project Entrepreneurship</title>
    <link href="https://en.smallyu.net/2023/07/08/Response%20to%20Ideas%20on%20Layer%202%20Project%20Entrepreneurship/"/>
    <id>https://en.smallyu.net/2023/07/08/Response%20to%20Ideas%20on%20Layer%202%20Project%20Entrepreneurship/</id>
    <published>2023-07-08T05:25:31.000Z</published>
    <updated>2025-08-06T10:38:28.693Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Note: I have no intention of disrespecting the letter. The viewpoints on L2 in the email have given me a lot of inspiration. Since some of the content does not completely align with my understanding, I have seriously considered and thought about the meaning of the letter. I would like to express my views on L2 here. As there is little L2-related content on my blog, I’ll put it up here to purely discuss technical issues.</p></blockquote><h3 id="The-Letter"><a href="#The-Letter" class="headerlink" title="The Letter"></a>The Letter</h3><blockquote><p>Hello, are you still looking for a job?</p><p>Jul 6, 2023, 5:39 PM (2 days ago)to me</p><p>Hi Wangyu!I came across your blog by chance and am not sure if this email will reach you.L2 has become quite popular this year. Various large companies, as long as they have some money, are starting to focus on &gt; L2.According to L2beat, there are quite a few L2 projects about to launch: <a href="https://l2beat.com/scaling/tvl#upcoming">https://l2beat.com/scaling/tvl#upcoming</a>It’s unclear whether all L2s are just copying each other. But it feels like the current L2 technologies mostly come from &gt; the open-source codes of a few leading companies.If this is true, does it mean anyone can fork a version themselves?If so, then we are that “anyone” :)Our startup team is quite interested in jumping on the L2 public chain “trend,” and it seems you are an expert in this area.</p><p>If you are also interested, we can discuss collaboration methods further?My general idea is remote, with you freely leading the chain’s evolution.</p><p>PS: My telegram is @******. Feel free to contact me online.</p></blockquote><h3 id="Response"><a href="#Response" class="headerlink" title="Response"></a>Response</h3><p>Hello!</p><p>I am very pleased to receive your email, and I apologize for not responding promptly.</p><p>I tried to carefully understand the content of your letter. Regarding some of the points about L2, I want to describe my understanding.</p><h4 id="1-The-Difference-Between-“Technology-Types”-and-“Projects”"><a href="#1-The-Difference-Between-“Technology-Types”-and-“Projects”" class="headerlink" title="1. The Difference Between “Technology Types” and “Projects”"></a>1. The Difference Between “Technology Types” and “Projects”</h4><p>There are 4 types of Layer 2 technologies: State channels, Sidechains, Optimistic rollups, and ZK rollups. All projects fall within these 4 types. Among the upcoming projects, most are of the rollups type, but there is no information on whether their code is forked from existing projects.</p><img src="a.png" width="50%" /><p>There are specifically these 4 projects:</p><img src="b.png" width="30%" /><p>However, from the list of launched projects, even if they fork the same project, their application scenarios are highly customized and vary greatly:</p><img src="c.png" width="50%" /><h4 id="2-Existing-Projects-Are-Not-Simple-Forks"><a href="#2-Existing-Projects-Are-Not-Simple-Forks" class="headerlink" title="2. Existing Projects Are Not Simple Forks"></a>2. Existing Projects Are Not Simple Forks</h4><p>Take zkSync as an example. Three projects have this label in the list:</p><img src="d.png" width="30%" /><p>They are zkSync Era, zkSync Lite, and ZKSpace. zkSync Era and zkSync Lite are from the same company.</p><p>Looking specifically at ZKSpace, it indeed uses zkSync’s contracts but is not simply a fork of the entire project. Instead, it uses zkSync’s contract code and modifies it to fit its own business. Additionally, ZKSpace also uses code from other projects.</p><img src="e.png" width="50%" /><p>From ZKSpace’s (formerly ZKSwap) whitepaper, we can see that ZKSpace aims to be Uniswap on Layer 2, including AMM functions, which are those of a market maker.</p><img src="f.png" width="60%" /><p>zkSync is a general Layer 2 project that does not provide very specific functions. ZKSpace uses some of zkSync’s contract code to do things that are highly relevant to their business and have specific goals. It does not compete directly with zkSync itself.</p><p>Looking at projects with the OP label, which are forked from the OP project:</p><ul><li>Arbitrum initially forked OP, then changed some economic model aspects, and later restructured the project as it grew. Additionally, Arb’s operational capabilities are strong, having hosted several Odyssey events.</li><li>Boba’s feature is that it doesn’t require a 7-day wait to withdraw funds; withdrawals are immediate. Moreover, through its own so-called hybrid computing technology, it brings web2 capabilities to the blockchain.</li><li>Zora is a layer2 dedicated to the NFT field.</li><li>Mantle provides decentralized sequencers, among other things.</li></ul><p>In summary, these projects all have specific purposes and aim to achieve certain functions by reusing existing code. The focus is likely on the goals of these projects, i.e., what they aim to do. They combine their business scenarios rather than just being able to run by simply forking the code.</p><h4 id="3-L2-is-Not-a-Chain"><a href="#3-L2-is-Not-a-Chain" class="headerlink" title="3. L2 is Not a Chain"></a>3. L2 is Not a Chain</h4><p>Current rollup projects are centralized. They are not a chain themselves and do not have consensus mechanisms; the project team operates them.</p><h4 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h4><p>Regarding your idea of developing an L2 project, I mean that, based on your description, it may not be as simple as you think. It might involve specific issues. Innovations in application scenarios, combined with DeFi or GameFi, or technical innovations that can improve certain pain points, might be needed.</p><p>I also want to jump on the trend and hope for a suitable entrepreneurial opportunity. I am currently looking for a job, but from my perspective, I am quite confused. I don’t have a direct idea of what direction a project should take; I think those involve quite market-oriented aspects and require significant capital.</p><p>I’m not sure about your specific thoughts. As there is a lot of content, I replied via email. Feel free to contact me if you have any questions.</p><h3 id="Supplement"><a href="#Supplement" class="headerlink" title="Supplement"></a>Supplement</h3><p>There are some topics not mentioned in the reply, which I will briefly discuss.</p><p>First, why is Layer 2 hot? Because Vitalik has frequently mentioned zkEVM in his recent blogs. For example, in the article <a href="https://vitalik.ca/general/2021/12/06/endgame.html">Endgame</a>, he considers supporting ZK-rollup as an important task for Ethereum’s future. Some issues cannot be directly resolved on Layer 1, so they hope to solve them through Layer 2. With Vitalik, a highly regarded developer, leading the technical direction in the ecosystem, Layer 2 has become a development hotspot for Ethereum.</p><p>Vitalik is quite optimistic about ZK-SNARKs type zkEVMs. From a technical perspective, ZK-rollups will be the so-called Endgame. However, ZK development costs are very high and currently still in research and development. Small-scale capital cannot afford it; it is too expensive.</p><p>The Dapp-learning community has a technical sharing video on Scroll on Youtube, which is quite good. The entire Scroll technical team is based in China. From the video explanation, it seems Scroll’s technical solution involves some brute-force elements, such as creating a table for a certain type of circuit results and expanding various tables to support the entire EVM. This is how Scroll compares the ways each ZK project implements EVM completeness:</p><img src="g.png" width="80%" /><p>Vitalik’s blog post <a href="https://vitalik.ca/general/2022/08/04/zkevm.html">The different types of ZK-EVMs</a> also discusses the classification of zkEVMs. Anyway, the hype around Layer 2 should be referring to the heat around ZK-rollup projects.</p><p>Optimistic rollups are more like a transitional solution for L2. I believe once ZK rolls out, OP projects will be impacted, as OP does not rely on the reliability of cryptographic technology. From its name, you can see it is optimistic, assuming a transaction has no issues first and then giving a 7-day challenge period. If there are issues, users need to challenge it themselves or third-party verifiers to fully challenge, involving significant human intervention.</p><p>Another issue is the centralization of L2 projects. Except for Sidechains projects, L2 must be centralized because consensus is handed over to L1. L2 does not manage it. From a motivational perspective, L2’s role is to quickly collect transactions and package them to L1. The ultimate trust in a transaction falls on L1. Users trust L1’s transaction records, not L2, so L2 does not need decentralization. Users don’t need it, and project parties don’t need it. L2s are generally issued and operated by project teams. Users trust the project’s technical solution and are willing to engage with it and pledge assets.</p><p>There is also the issue of L2 user experience. Currently, few users use OP or ARB for low-cost asset transfers. They prefer using BNB or TRX for anonymous payment scenarios. The more common uses are governance token investments or interactions in DApp project forms. The 7-day wait for OP to redeem assets is quite inconvenient. Asset transfers between L2 chains are also an issue. For example, can USDT on OP be transferred to ARB? Otherwise, if I use OP and another person uses ARB, we cannot trade. There is still much room for improvement in this area.</p><p>L2 is a promising technical direction, and we look forward to it bringing us a better user experience. As for whether there are low-cost profit opportunities, that is uncertain.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;Note: I have no intention of disrespecting the letter. The viewpoints on L2 in the email have given me a lot of</summary>
        
      
    
    
    
    
    <category term="Layer2" scheme="https://en.smallyu.net/tags/Layer2/"/>
    
    <category term="Entrepreneurship" scheme="https://en.smallyu.net/tags/Entrepreneurship/"/>
    
  </entry>
  
  <entry>
    <title>Understanding Blockchain Consensus Mechanisms</title>
    <link href="https://en.smallyu.net/2023/07/01/Understanding%20Blockchain%20Consensus%20Mechanisms/"/>
    <id>https://en.smallyu.net/2023/07/01/Understanding%20Blockchain%20Consensus%20Mechanisms/</id>
    <published>2023-07-01T09:19:29.000Z</published>
    <updated>2025-08-06T10:38:28.713Z</updated>
    
    <content type="html"><![CDATA[<p>The role of a consensus mechanism is to ensure that the data across most nodes remains consistent. Consensus mechanisms can be broadly categorized into two types: PoW (Proof of Work) style and PBFT (Practical Byzantine Fault Tolerance) style. Almost all consensus mechanisms fall under these two styles.</p><p>Let’s start from scratch and think about how to maintain consistency among a group of humans. One method is to elect a leader whose opinion everyone follows. Another method is to make decisions collectively through discussion to reach a unified opinion.</p><p>For the first method, the challenge lies in how to elect the leader, the criteria for selection, and what kind of person can become the leader. For the second method, the challenge is who can participate in the discussion and how decisions are made.</p><p>First, let’s look at the first method, which mainly involves three steps:</p><ol><li>Elect a leader through some means.</li><li>Everyone listens to the leader within a time unit.</li><li>Everyone reaches a consensus within a time unit.</li></ol><p>The PoW process is as follows:</p><ol><li>The miner who solves the hash puzzle becomes the block-producing node.</li><li>All nodes receive and validate the miner’s block.</li><li>All nodes’ block data reach a consensus.</li></ol><p>In this PoW style consensus process, the biggest variable is the first step, which is how to elect the block-producing node. Therefore, there are many variants of PoW consensus.</p><ul><li><p>Proof of Stake (PoS): The consensus mechanism used by Ethereum, with the cryptocurrency named ETH. Nodes that stake a certain amount of assets randomly become block-producing nodes, with the randomness determined by the VRF function running on the beacon chain. The more assets staked, the higher the probability of becoming a block-producing node.</p></li><li><p>Proof of Authority (PoA): A consensus mechanism supported by the Ethereum testnet. The block-producing nodes are predetermined during the network initialization phase and produce blocks in sequence. The process of verifying validators is completed offline, and the network itself does not have the ability to correct validator nodes, making it a relatively centralized consensus.</p></li><li><p>Proof of Importance (PoI): The consensus mechanism used by Nem, with the cryptocurrency named XEM. Nodes are ranked based on certain scoring mechanisms, such as the number of transactions and transaction amounts over a certain period. Nodes with scores above a specified standard randomly become block-producing nodes.</p></li><li><p>Proof of Elapsed Time (PoET): The consensus mechanism used by the Hyperledger Sawtooth project, developed by Intel. Each node randomly generates a wait time, and the node with the shortest wait time becomes the block-producing node. The block-producing node must provide proof of the shortest time, which is combined with hardware devices to make it tamper-proof.</p></li><li><p>Proof of Burn (PoB): The consensus mechanism used by Slimcoin, with the cryptocurrency named SLM. Nodes obtain a burn hash by burning assets. The burn hash calculation includes the amount burned and the frequency of burns over a period. The system compares the hash values submitted by each node, and the node with the smallest hash value produces the block for that round.</p></li><li><p>Proof of Capacity (PoC): The consensus mechanism used by Burst, with the cryptocurrency named Burst. Nodes use a hard-to-pebble graph data structure to write files on disk, requiring sufficient disk space. After writing, nodes randomly open a file location and calculate the corresponding hash value until they find a satisfactory hash value, allowing them to produce a block.</p></li><li><p>Proof of History (PoH): The consensus mechanism used by Solana, with the cryptocurrency named SOL. The innovation of this consensus mechanism is that each transaction or other on-chain operation corresponds to a hash value. The PoH generator produces blocks, each composed of a series of continuous hash values, ensuring the consistency of on-chain data. The PoH generator is the block-producing node, selected based on the amount of staked assets.</p></li></ul><p>These are examples of PoW style consensus mechanisms. Despite their efforts to change the way block-producing nodes are selected, all these blockchains follow the three-step process.</p><p>Now, let’s look at the second method, which also involves three steps:</p><ol><li>Select decision-makers through some means.</li><li>Decision-makers communicate and reach a consensus.</li><li>Everyone else follows the decision to reach a consensus.</li></ol><p>The PBFT process is as follows:</p><ol><li>Select consensus nodes from all nodes, then rotate the role of proposer among them.</li><li>Consensus nodes undergo two rounds of voting on the proposal content.</li><li>Consensus nodes reach an agreement, and other nodes follow suit to reach a consensus.</li></ol><p>Compared to the first method, the single leader is replaced by multiple decision-makers. In this PBFT style consensus process, the biggest variable is also the first step, which is how to select consensus nodes and determine the order of proposer nodes. Here are some variants:</p><ul><li><p>Delegated Byzantine Fault Tolerance (DBFT): The consensus mechanism used by Neo, with the cryptocurrency named NEO. Every node holding assets can participate in the election of consensus nodes, delegating their assets to consensus nodes. The top-ranked consensus nodes are the proposers in sequence.</p></li><li><p>Federated Byzantine Agreement (FBA): The consensus mechanism used by Stellar, with the cryptocurrency named Stellar. All nodes in the network are consensus nodes and can participate in two rounds of voting. To reduce network congestion, nodes can delegate their voting rights to another node, using slices or sub-networks to improve consensus efficiency.</p></li><li><p>HoneyBadgerBFT: A type of BFT consensus that supports fully asynchronous networks, not relying on synchronized time sequences, which PBFT cannot achieve. However, consensus efficiency in asynchronous networks is relatively low.</p></li><li><p>HotStuff: A BFT consensus allowing partial network asynchrony. Its feature is that multiple proposals can exist simultaneously in the network, with proposer nodes selecting the best proposal for subsequent processes. This parallel proposal process improves overall consensus efficiency.</p></li><li><p>VBFT: The consensus used by Ontology, with the cryptocurrency named ONT. Proposal nodes are selected using the VRF random function, with each round’s proposal nodes being random and unpredictable.</p></li></ul><p>In summary, both PoW and PBFT styles filter out content that can ultimately achieve consensus through some means, but they fundamentally differ in how content is selected. In PoW, other nodes unconditionally accept the source block as long as it meets certain criteria. In PBFT, other nodes receive the block content first, then decide whether to accept it through a voting process before reaching a consensus.</p><p>There are also some innovative types of consensus, such as hybrid consensus combining multiple consensus mechanisms. These may evaluate node reputation, score based on historical transaction quality, or use hardware devices like mobile phones and IoT for data validation. Additionally, optimizations in PBFT, such as parallelism at certain stages, fault tolerance, and network efficiency, still fall within the frameworks of PoW and PBFT.</p><p>Therefore, it can be boldly stated that consensus mechanisms are essentially the same, differing only in their specific design and implementation.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;The role of a consensus mechanism is to ensure that the data across most nodes remains consistent. Consensus mechanisms can be broadly</summary>
        
      
    
    
    
    
    <category term="Blockchain" scheme="https://en.smallyu.net/tags/Blockchain/"/>
    
    <category term="Consensus Mechanism" scheme="https://en.smallyu.net/tags/Consensus-Mechanism/"/>
    
  </entry>
  
  <entry>
    <title>Pebbling Game</title>
    <link href="https://en.smallyu.net/2023/05/18/Pebbling-Game/"/>
    <id>https://en.smallyu.net/2023/05/18/Pebbling-Game/</id>
    <published>2023-05-18T08:36:33.000Z</published>
    <updated>2025-08-06T10:38:27.726Z</updated>
    
    <content type="html"><![CDATA[<p>This is an online web game: <a href="https://smallyunet.github.io/pebbling-game/" target="_blank">Pebbling Game</a>. You can view this embedded web page:</p><div><iframe src="https://smallyunet.github.io/pebbling-game/" width="900px" height="580px" frameborder="0" scrolling="yes" style="border: 5px double #e4e4e4;"> </iframe></div><p>To intuitively demonstrate the rules of the Pebbling Game, GPT-4 created this online game page after dozens of adjustments.</p><p>The rules of the game are:</p><ol><li>Click on the circle of a node to place a pebble in it.</li><li>A node can only have a pebble placed in it if all nodes pointing to it already have pebbles.</li><li>The goal of the game is to place a pebble in node 0.</li><li>Pebbles can be removed from any node at any time.</li></ol><p>If you directly click on node 0, you will see two red flashing circles indicating that nodes 1 and 2 have not yet had pebbles placed in them, so node 0 cannot have a pebble placed in it.</p><p>Node 7 has no incoming nodes, so a pebble can be placed directly in it. Clicking on node 7, you will see a solid black circle appear in the node. At this point, if you try to place a pebble in node 3, it will indicate failure because node 6 is still empty. Nodes 6 and 7 are the incoming nodes for node 3.</p><p>So, with these game rules, the question is: What is the minimum number of pebbles needed?</p><p>If there are enough pebbles, there are a total of 10 nodes in this diagram, and if you have 10 pebbles, you can simply fill the nodes in order without needing to remove any pebbles.</p><p>If pebbles are limited, seeking the solution with the least number of pebbles, this diagram should require at least 5 pebbles.</p><p>The characteristic of the Pebbling Game is that there is always a minimum value. If the number of pebbles is less than this value, the game cannot be completed because the final node depends on lower-level nodes, which in turn depend on even lower-level nodes. If a pebble is removed from an intermediate node, you have to start placing pebbles from the lowest level again.</p><p>The Pebbling Game has enlightening significance for the data structure of Hard-to-pebble graphs. Understanding the rules of the game helps in understanding how blockchain proves the size of disk space.</p><h3 id="Proof-of-Space"><a href="#Proof-of-Space" class="headerlink" title="Proof of Space"></a>Proof of Space</h3><p>Hard-to-pebble graphs are a type of DAG combined with a Merkle tree. The characteristic is that a certain amount of storage space is required to complete the computation of the top node. Just like in the game where you cannot complete it without enough pebbles, you cannot complete the challenge without enough storage space.</p><p>Due to the variety of graphs, there is no universal optimal solution for the number of pebbles required. It can only be calculated for a specific type of graph to determine the space complexity.</p><p>In blockchain scenarios, the requirement is to occupy large space and verify quickly. The graph structure of the Stack Expander Graph is widely used in Proof of Space. During the verification phase, you only need to verify certain nodes in the graph according to the characteristics of the Merkle tree to confirm the integrity of the graph. At the same time, you can estimate the amount of disk space occupied based on the depth of the graph.</p><p>If you need to verify both the size of the space and the duration of space occupation, you can add a time proof on top of the space proof. For example, Chia uses a Delay Verifiable Function, first verifying the space proof, then after some time, using the VDF to verify that enough time has indeed passed, and then verifying the space proof again, achieving the effect of Proof of Space-Time.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;This is an online web game: &lt;a href=&quot;https://smallyunet.github.io/pebbling-game/&quot; target=&quot;_blank&quot;&gt;Pebbling Game&lt;/a&gt;. You can view this</summary>
        
      
    
    
    
    
    <category term="Documentation" scheme="https://en.smallyu.net/tags/Documentation/"/>
    
  </entry>
  
  <entry>
    <title>Limitations of PDP Proof of Storage</title>
    <link href="https://en.smallyu.net/2023/05/17/Limitations%20of%20PDP%20Proof%20of%20Storage/"/>
    <id>https://en.smallyu.net/2023/05/17/Limitations%20of%20PDP%20Proof%20of%20Storage/</id>
    <published>2023-05-17T07:53:06.000Z</published>
    <updated>2025-08-06T10:38:27.718Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Proof-of-Storage"><a href="#Proof-of-Storage" class="headerlink" title="Proof of Storage"></a>Proof of Storage</h3><p>The most basic use of PDP (Provable Data Possession) for a file is to generate a corresponding TAG based on the file content, then send the file to another environment. Subsequently, use the saved TAG to verify if the other party has indeed stored the file. If the other party hasn’t stored the file, it is impossible to pass the initial verification. In the subsequent verifications, since the challenges are randomly generated and select segments from different parts of the file, the reliability of the verification can be probabilistically improved.</p><p>Therefore, this usage at least proves that the file is stored in the other party’s environment. However, this method of proof has a flaw: the file does not need to be complete, or in other words, it lacks proof of file integrity. If the file is very large and the number of challenges is generally fixed, the larger the file, the less comprehensive the challenges. Although the file segments for the challenges are random, there is still a possibility that the other party does not need the complete file but only a part of it—2&#x2F;3, 1&#x2F;2, or 1&#x2F;3—to complete the challenge.</p><h3 id="Proof-of-File-Integrity"><a href="#Proof-of-File-Integrity" class="headerlink" title="Proof of File Integrity"></a>Proof of File Integrity</h3><p>To enable PDP to prove file integrity, PDP proof can be combined with the data structure of a Merkle tree. PDP proof typically requires the file to be split into data segments and generates TAGs based on these segments, without emphasizing the serialization of the data segments.</p><p>The combination with a Merkle tree comes into play after splitting the file into data segments, then serializing these data segments into the Merkle tree. Due to the properties of a Merkle tree, the value of the parent node depends on the values of the child nodes to be computed. If the parent node is verified to be correct, it indicates that all child nodes exist, indirectly proving the file’s integrity.</p><p>In practical use, some nodes of the Merkle tree are often extracted, and the paths of these Merkle nodes are verified, which is a common method to verify the integrity of the Merkle tree. By using the Merkle tree as the data structure for the file and verifying the Merkle tree’s integrity while verifying the PDP proof, it can be ensured that the file exists in its entirety.</p><p>The coverage of Merkle tree verification cannot be 100%, but it is generally believed that the cost of forging Merkle tree nodes is higher than the cost of actually retaining the complete data.</p><h3 id="Proof-of-File-Size"><a href="#Proof-of-File-Size" class="headerlink" title="Proof of File Size"></a>Proof of File Size</h3><p>PDP proof itself does not include the file’s metadata; it can only prove that the file exists and is complete, but it does not provide information about what the file is, the file name, file type, or file size. PDP proof information does not include file metadata, and useful metadata includes file size. PDP is not a technology of the blockchain era, and it does not concern itself with this issue.</p><p>Some blockchains describe the computational power of nodes by the size of disk space or charge users based on file size or reward storage nodes according to the stored file size. This makes the file size information crucial.</p><p>To address the issue of missing file metadata, one approach is to associate metadata with file data outside the PDP proof system. Another approach is to modify the file by attaching metadata to the file data. As long as the integrity of the file data is proven, the accuracy of the file metadata can be confirmed.</p><p>However, neither method can guarantee the reliability of file metadata. In the blockchain scenario, the trust model has changed, differing from the issues PDP aims to solve. Previously, PDP was to let users trust storage nodes, but now, it is to let the blockchain trust storage nodes.</p><p>The first approach requires additional mechanisms to ensure the mapping relationship between metadata and file data, which incurs significant overhead. The second approach is simpler to implement, but the problem lies in who attaches the metadata to the file data. Is it trustworthy? What if incorrect information is maliciously attached? Additionally, how to read this metadata? Should the file data or part of the file data be downloaded? Even so, the downloaded information cannot be guaranteed to be correct.</p><p>In conclusion, within the realm of cryptography, PDP cannot solve the proof of file size.</p><h3 id="Proof-of-File-Continuity"><a href="#Proof-of-File-Continuity" class="headerlink" title="Proof of File Continuity"></a>Proof of File Continuity</h3><p>PDP proof requires continuous challenge requests, where successful challenges indicate the file is intact. For example, if a challenge is initiated now and another one an hour later, it at least shows that the file was intact at the time of each challenge. But what about the times when there is no challenge? There are no restrictions.</p><p>If, after the first challenge, the file is moved elsewhere and then brought back for the second challenge, this is entirely possible. PDP does not and cannot prevent such situations. PDP cannot provide proof of file continuity.</p><p>What impact does this limitation have on blockchain? The first thing that comes to mind is exchanging computational power for space. Because in some blockchain rules, the larger the file, the higher the miner’s earnings. Miners can utilize the interval between PDP proofs to free up space for other files, exchanging disk IO for disk space size.</p><p>Additionally, the cost of proof increases. The more frequent the challenges, the safer the file, which imposes pressure on the party seeking proof.</p><h3 id="Proof-of-Multiple-File-Copies"><a href="#Proof-of-Multiple-File-Copies" class="headerlink" title="Proof of Multiple File Copies"></a>Proof of Multiple File Copies</h3><p>PDP naturally does not have the ability to prove the existence of multiple copies of a file. If two copies of the file are required, but the other party only actually stores one, PDP will have no awareness of this, which is easy to understand.</p><p>If you want to disperse the risk of file loss by storing the file in different locations, using PDP as a verification method cannot achieve this goal.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h3 id=&quot;Proof-of-Storage&quot;&gt;&lt;a href=&quot;#Proof-of-Storage&quot; class=&quot;headerlink&quot; title=&quot;Proof of Storage&quot;&gt;&lt;/a&gt;Proof of Storage&lt;/h3&gt;&lt;p&gt;The most</summary>
        
      
    
    
    
    
    <category term="Proof of Storage" scheme="https://en.smallyu.net/tags/Proof-of-Storage/"/>
    
  </entry>
  
  <entry>
    <title>Half-Year Work Review</title>
    <link href="https://en.smallyu.net/2023/05/06/Half-Year%20Work%20Review/"/>
    <id>https://en.smallyu.net/2023/05/06/Half-Year%20Work%20Review/</id>
    <published>2023-05-06T11:24:50.000Z</published>
    <updated>2025-08-06T10:38:27.656Z</updated>
    
    <content type="html"><![CDATA[<p>A review of the past six months of work. Six months ago, I felt lost because I knew Filecoin was adapting to EVM, shifting the storage track towards the computing track. We couldn’t surpass Filecoin.</p><p>However, I still gained something, mainly a deeper understanding of file proofs and a more detailed familiarity with the project’s code, which I hadn’t grasped before.</p><h3 id="Sector-Proofs"><a href="#Sector-Proofs" class="headerlink" title="Sector Proofs"></a>Sector Proofs</h3><p>Sector proofs have always had a problem: the proofs can fail. Initially, I thought the issue was that the contract did not include the file list information during proof checks, leading to expired files not being deleted. Later, I discovered more issues. After fixing the code, if a file was stored on only one storage node, it was fine. But if there were multiple storage nodes, the proof still failed.</p><p>The final reason found was that when a file is stored on multiple nodes, and other nodes submit proofs to the contract, if they find the file has expired, they delete the node’s corresponding file information in the contract and broadcast to other nodes to delete this file. However, when other nodes received the notification, they only deleted the local issue, not the file information in the contract, leading to frequent discrepancies between local files and those recorded in the contract, causing the proof to fail.</p><p>Solving this problem involved thoroughly reviewing the proof-related code.</p><h3 id="EVM-Contracts"><a href="#EVM-Contracts" class="headerlink" title="EVM Contracts"></a>EVM Contracts</h3><p>In last year’s [Annual Work Review](&#x2F;2022&#x2F;08&#x2F;27&#x2F;One Year Work Review&#x2F;), I mentioned rewriting a Go language contract in Solidity, migrating the original contract to run on Ethereum.</p><p>The part of the project that supports Ethereum accounts was completed long ago, allowing storage nodes to use Ethereum nodes and implement file upload and download through Ethereum smart contracts. However, the contract proof section remained unfinished because the project used Bulletproof’s zero-knowledge proof, which was too difficult to rewrite in Solidity.</p><p>The current approach is to use the POA method, where the contract should perform the proof, replacing it with submitting proof parameters and recording them in the contract. Verification nodes then retrieve the proof parameters from the contract, verify the zero-knowledge proof locally, and submit the proof results back to the contract.</p><p>Having reviewed the proof-related code, I can now complete the proof-related part of the EVM contract.</p><h3 id="Why-Ignore-Layer2"><a href="#Why-Ignore-Layer2" class="headerlink" title="Why Ignore Layer2"></a>Why Ignore Layer2</h3><p>I once considered performing the proofs on Layer2 nodes. I made no progress in this direction for two reasons:</p><ol><li>Layer2 is positioned as EVM complete, without additional functionalities.</li><li>Layer2 is also difficult to validate.</li></ol><p>The first point means that for users or developers, the significance of Layer2 is to reduce fees. If it performs identically to Layer1, it would be exceptional. Adding extra features to Layer2 might not align with the purpose of such projects.</p><p>The second point means that Layer2 projects modify Layer1’s node header information, making it hard to implement file validation. It would require recognizing a transaction as a function call of a specific contract in the bytecode layer, verifying zero-knowledge proof parameters, and writing the verification results back into variables at the bytecode level. This is challenging but, if accomplished, would essentially create a business-specific EVM virtual machine, boasting high technical barriers and showing off potential.</p><p>In contrast, a simpler approach is to use a client to verify proof parameters and submit the results back. Whether the client is on Layer2 nodes or elsewhere doesn’t matter. I chose this simpler approach, which, though less impressive, can be completed within my lifetime and shows results, which is now achieved.</p><h3 id="Solidity-Contracts"><a href="#Solidity-Contracts" class="headerlink" title="Solidity Contracts"></a>Solidity Contracts</h3><p>A brief summary of the issues encountered when migrating Go contracts to Solidity.</p><p>Contract size cannot exceed 24 KB, or it will fail to compile. For business contracts, 24 KB is insufficient, requiring splitting into two or more contracts and achieving functionality through inter-contract calls. Splitting isn’t difficult; it just requires clarity on the functions, distinguishing external from internal ones.</p><p>Storage structures can’t include lists, as lists are not fixed-length, making it hard for contracts to calculate space usage. This requires separating lists from structures and using them independently. If familiar with business logic, this is not an issue; otherwise, encountering unfamiliar variable names can be annoying. I was lazy and didn’t write the full logic in the contract, taking two days to figure out the problem.</p><p>Mappings can’t be iterated. Simple original methods need complex rewrites using libraries.</p><p>Mappings return default values if elements don’t exist. It’s impossible to check if a mapping contains a key. If the default value type has meaning in the business, unexpected situations might arise.</p><p>These are minor issues but can complicate the coding process as they require different methods to achieve identical logic.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;A review of the past six months of work. Six months ago, I felt lost because I knew Filecoin was adapting to EVM, shifting the storage</summary>
        
      
    
    
    
    
    <category term="Work" scheme="https://en.smallyu.net/tags/Work/"/>
    
  </entry>
  
  <entry>
    <title>Don&#39;t Underestimate ChatGPT</title>
    <link href="https://en.smallyu.net/2023/03/30/Don&#39;t%20Underestimate%20ChatGPT/"/>
    <id>https://en.smallyu.net/2023/03/30/Don&#39;t%20Underestimate%20ChatGPT/</id>
    <published>2023-03-30T09:09:36.000Z</published>
    <updated>2025-08-06T10:38:27.654Z</updated>
    
    <content type="html"><![CDATA[<p>Previously, I didn’t understand how Filecoin manages disk space. Since it uses Proof of Space, the Sector must occupy disk space when it’s created. How does Filecoin release the occupied space promptly when a user’s file is stored in the Sector? Releasing the space every time a file is written seems too rigid.</p><p>I checked Filecoin’s <a href="https://docs.filecoin.io/basics/what-is-filecoin/storage-model/">documentation</a> and <a href="https://spec.filecoin.io/systems/filecoin_mining/sector/">specifications</a>, but I couldn’t find a direct answer. Running a Filecoin node is quite costly, requiring high-end hardware and close monitoring of disk capacity during operation.</p><p>I happened to ask ChatGPT about it, and to my surprise, it provided a detailed explanation, making me look at ChatGPT in a new light. Filecoin doesn’t release disk space in real-time. Instead, after a Sector is filled with files, there’s a Sealing process, which seals the Sector and replaces the previously generated random files with real data for mining and earning rewards.</p><p>I once heard in a video that Filecoin’s disk utilization is only 50%, but I didn’t understand why. Now it makes sense; before Sealing, the Sector occupies twice the disk space.</p><p>What’s most surprising is ChatGPT’s capability. In retrospect, if I had an experienced Filecoin researcher, they could easily answer my question. But the challenge is finding such an expert willing to answer my questions. Now I have found one.</p><p>On December 21, 2020, I wrote on <a href="/micro-blog/#2020-32">Weibo</a>:</p><blockquote><p>Simple memory has no meaning. Memorizing content from books and the internet only makes one “appear” knowledgeable, deceiving the ignorant. If we think of computers and the internet as another form of life, they would be more knowledgeable than any human.</p></blockquote><p>Unexpectedly, such “life” has now appeared. ChatGPT integrates professional knowledge from various fields and can converse in human language. I always knew that merely increasing my “dead knowledge” reserve was useless because there will always be someone you can’t surpass, even if that someone isn’t human.</p><p>Recently, there was a case of ChatGPT surpassing human abilities: <a href="https://www.zhihu.com/question/592511373">How to view a man’s pet dog being diagnosed by a veterinarian and later saved by asking GPT-4?</a>. The gist is, due to limited veterinary experience, the vet focused only on one possible cause of the dog’s illness. Later, the owner let ChatGPT analyze the dog’s health indicators, and ChatGPT provided two possibilities. At the hospital, it turned out to be the second one. Unlike vets, ChatGPT isn’t limited by past experiences, making it appear more knowledgeable.</p><p>As we age, we must abandon extreme thinking. We cannot believe AI will replace humans because current AI lacks true intelligence. Nor can we deny that AI excels in certain areas and can be a great assistant to humans.</p><p>The most advanced large language model now is GPT-4, which requires a $20 per month subscription on the ChatGPT website. The free preview version is GPT-3.5, which is also impressive. When people thought AI chat was limited to Microsoft’s Xiaoice and Apple’s Siri, GPT-3.5 emerged, gaining widespread attention. I used GPT-3.5 for various tasks, such as generating positive podcast reviews for friends and completing programming assignments for vocational school students.</p><p>ChatGPT’s translation ability is also strong, often surpassing Google Translate. For instance, the term “兜底机制” is translated by Google as “Pocket Mechanism,” whereas ChatGPT translates it as “fallback mechanism,” clearly showing ChatGPT’s understanding of the term’s meaning. Another example is “布偶猫,” translated by Google as “cat plush,” while ChatGPT translates it as “Ragdoll cat,” demonstrating a significant difference in accuracy.</p><p>However, GPT-3.5 has been criticized for “speaking nonsense seriously.” As a language model, programmers can understand why this happens—it’s like choosing from a set of templates, selecting the best-sounding answer from existing language templates. GPT-3.5 seems to work this way. Therefore, relying on GPT-3.5 for knowledge carries significant risk; it can provide correct information but also present fabricated content as knowledge.</p><p>Google’s large language model <a href="https://bard.google.com/">Bard</a> has comprehensive abilities inferior to ChatGPT, weak code handling capabilities, and also suffers from “speaking nonsense seriously” and often “answering off-topic.” Chinese products are even less competitive.</p><p>Compared to GPT-3.5, GPT-4 should be improved in all aspects. While it’s unclear how much the accuracy of information has improved, its language understanding is indeed superior to GPT-3.5, as discussed <a href="https://v2ex.com/t/927744">here</a>. GPT-4 uses a different training model architecture than GPT-3.5, and Microsoft has released a <a href="https://arxiv.org/abs/2303.12712">technical paper</a> on GPT-4. The paper indicates that GPT-4 supports multi-modality, meaning it can generate statistical graphs based on input data, which may not yet be publicly available.</p><p>GPT-4’s overwhelming capabilities have raised many concerns, even prompting Elon Musk to sign an <a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">open letter to pause training AI more powerful than GPT-4</a>. No one knows whether GPT-4’s emergence will benefit or harm human society.</p><p>Many products have already integrated GPT’s capabilities. Microsoft’s Office suite was the first to support it, being a self-developed product. It’s uncertain how effective it will be in actual use, but it could revolutionize many repetitive tasks, with GPT capable of handling them more effectively. You don’t need to know how to write a particular function in Excel; with GPT, you can describe it in natural language. Future computer education might include a new subject: how to communicate efficiently with ChatGPT.</p><p>Microsoft’s Bing search engine has also incorporated GPT capabilities. Without GPT, Bing’s search results cannot compete with Google. With GPT, Bing gains the ability to search using natural language. New Bing works by having GPT search the content, summarize it, and then describe it in natural language. The advantage is that GPT presents correct content, but the downside is slower processing. While it’s worth trying, for programmers, Google remains the go-to for quick solutions.</p><p>More exciting is the prospect of GPT-4 plugins, integrating GPT into more scenarios, such as replacing GitHub Copilot for code generation. Once you use Copilot, you can’t go back. It was considered advanced to have automatic code completion, but soon after Copilot’s release, GPT emerged. Copilot faces a threat and has introduced the Copilot X solution, but I have more faith in GPT’s future. I’ve canceled my $10 monthly Copilot subscription and subscribed to ChatGPT Plus for $20 a month, believing GPT will shine in the future.</p><p>Using ChatGPT outside the US still has some hurdles. You need to access the ChatGPT website normally, register with a US phone number, and subscribe to Plus with a US bank card. After several steps, buying a pre-configured account for 150 RMB is the most cost-effective option. Otherwise, even with high costs, success isn’t guaranteed.</p><p>You can buy a US phone number for 300 RMB from Ultra with no KYC, starting with +1, with long-term retention and a $3 monthly fee. With Wi-Fi Calling enabled, you get 100 free SMS. A US phone number is quite useful for opening a US PayPal account and using a US Apple ID with US PayPal. US PayPal can be linked to a domestic Visa credit card. Many IM apps also require a foreign phone number for verification.</p><p>For foreign bank cards, try Depay virtual cards, growing rapidly due to ChatGPT membership needs. You can recharge with cryptocurrency and spend in USD. However, ChatGPT orders have various risk control rules, with IP and order address inconsistencies potentially triggering risk controls, causing subscription failures. For just opening ChatGPT Plus, Apple Pay is available on iPhones accessing ChatGPT, and US PayPal can be tried. Overall, buying an account is the fastest and easiest way.</p><p>Additionally, text-to-image generation in the AI field is quite popular. I’ve tried several hot products.</p><ul><li><a href="https://labs.openai.com/">DALL-E</a> from the same company as GPT, but often produces distorted characters</li><li><a href="https://replicate.com/explore">Replicate</a> offers various model trials, such as <a href="https://replicate.com/stability-ai/stable-diffusion">stable-diffusion</a>, with the same issue of generating strange characters</li><li><a href="https://www.midjourney.com/">Midjourney</a> operates on Discord, producing quality images but with small scenes</li></ul><p>In my experience, current text-to-image generation isn’t very effective, heavily depending on precise input descriptions matching the model’s rules. Hopefully, future improvements with GPT’s natural language capabilities will make text-to-image generation more user-friendly.</p><p>Having ChatGPT is like having an unprecedentedly powerful knowledge base with rich language capabilities, dedicated to serving you. Shouldn’t you own one?</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Previously, I didn’t understand how Filecoin manages disk space. Since it uses Proof of Space, the Sector must occupy disk space when</summary>
        
      
    
    
    
    
    <category term="AI" scheme="https://en.smallyu.net/tags/AI/"/>
    
  </entry>
  
  <entry>
    <title>Why Trading Cryptocurrencies is Not a Good Idea</title>
    <link href="https://en.smallyu.net/2023/03/15/Why%20Trading%20Cryptocurrencies%20is%20Not%20a%20Good%20Idea/"/>
    <id>https://en.smallyu.net/2023/03/15/Why%20Trading%20Cryptocurrencies%20is%20Not%20a%20Good%20Idea/</id>
    <published>2023-03-15T10:38:01.000Z</published>
    <updated>2025-08-06T10:38:28.725Z</updated>
    
    <content type="html"><![CDATA[<p>Lately, I’ve been troubled by the pain of poverty for a long time, but I don’t think trading cryptocurrencies is a good way to gain wealth. Especially short-term operations and various leveraged contract trades.</p><p>The cryptocurrency world is like a casino filled with the temptation of money, with major exchanges and various DeFi Dapps being the games on the gambling table. Gamblers might win or lose money, but ultimately, it’s the casino that makes money. Very few gamblers can leave the table unscathed.</p><p>Smart people only treat cryptocurrencies as a financial tool, allocating a portion of their disposable assets based on investment nature. Long-term operations can be considered investments, but short-term trading is just gambling.</p><p>The fundamental reason for this phenomenon is that no one can predict the market trend.</p><p>Many people like to analyze the market changes with sound reasoning after they occur, discussing the favorable news, technical trends, and cyclical patterns. The biggest commonality of these analyses is that they are all retrospective. Before things happen, no one knows what will happen. Look at the several black swan events in the past year; how many were predicted by economists or blockchain scientists?</p><p>The reason is simple: no one can predict the future.</p><p>Moreover, if those self-proclaimed quant masters and market trend predictors really possessed the wealth code, why would they reveal it? Why are they eager for everyone to know? It indicates that they are just guessing, and the benefits of increasing their popularity outweigh the profits from the so-called wealth code.</p><p>From an investment perspective, the returns from cryptocurrency trading are quite limited, yet it requires bearing extremely high risks. Compared to traditional funds and stocks, the fluctuations are much larger, but the volatility of cryptocurrency markets is still far from the level that would make someone wealthy overnight. Perhaps ten years ago it was possible, but if you went back ten years, would you really dare to buy?</p><p>It’s easy to see everything clearly from the peak of history, but as a participant in history, it’s very difficult to be ahead of the times, requiring extraordinary vision and courage.</p><p>Additionally, the wild development of cryptocurrencies has somewhat deviated from the realm of value investing. The rise and fall of the market and the bull and bear cycles are not due to changes in people’s perception of cryptocurrencies themselves, at least not in recent years. They are mostly influenced by the Federal Reserve’s monetary policy. In other words, the current cryptocurrency market is only this big, and unless the market capacity is expanded, new chains are just competing for market share with existing chains.</p><p>Therefore, the opportunities to expand the crypto market lie in Web 3.0 and the metaverse. More people from non-crypto industries need to participate in the crypto market.</p><p>The only way to consistently profit from trading cryptocurrencies is through insider trading, which requires sources of information at that level. KOLs (Key Opinion Leaders) can influence the market to some extent. If a KOL has a huge number of followers, they can guide their followers to concentrate on a certain point, which is also a form of market manipulation. Ultimately, those who follow the trend are not the ones who profit, making it unreliable.</p><p>As for why it’s important to care about trading cryptocurrencies, it’s because work itself cannot make you wealthy. Working can be a process of accumulating wealth, but it won’t result in sudden wealth growth. It’s necessary to think and look for opportunities that can bring more returns.</p><p>Regarding the logic of running a business, typically, a company starts with investors’ money and then returns the profits to shareholders once it becomes profitable. Companies often have multiple product lines, and as long as the overall revenue exceeds the costs, the company can survive.</p><p>In fact, companies are also conflicted when it comes to layoffs. If due to profitability issues, a product line needs to be cut, the dilemma lies in whether to endure this difficult period, hoping the product might bring more profits in the future, or risk more losses by not cutting it in time. If it’s directly cut, more costs will be incurred to develop such a product line again in the future.</p><p>Another dilemma in layoffs is when one person scores 60 in field A and another scores 80 in field B. Now, if the entire product line of field B is cut, all people in field B are laid off, meaning the company loses more capable people. Therefore, layoffs are difficult and are closely related to the company’s operational situation and strategic direction.</p><p>In conclusion, trading cryptocurrencies is not advisable, and blindly relying on the company where you work is also not advisable.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Lately, I’ve been troubled by the pain of poverty for a long time, but I don’t think trading cryptocurrencies is a good way to gain</summary>
        
      
    
    
    
    
    <category term="Cryptocurrency Trading" scheme="https://en.smallyu.net/tags/Cryptocurrency-Trading/"/>
    
  </entry>
  
  <entry>
    <title>How Much Does It Cost to Eat a Meal in Beijing</title>
    <link href="https://en.smallyu.net/2023/03/11/How%20Much%20Does%20It%20Cost%20to%20Eat%20a%20Meal%20in%20Beijing/"/>
    <id>https://en.smallyu.net/2023/03/11/How%20Much%20Does%20It%20Cost%20to%20Eat%20a%20Meal%20in%20Beijing/</id>
    <published>2023-03-11T03:45:57.000Z</published>
    <updated>2025-08-06T10:38:27.656Z</updated>
    
    <content type="html"><![CDATA[<p>Looking back over the past six months of blog content, it seems a bit too serious and heavy. Recently, I’ve had a lot of meals and started to get a general idea of dining costs.</p><center style="font-size: 110%;"><strong>Chinese Cuisine</strong></center><p>According to Beijing’s consumption level, an average of 180 RMB per person can get you a decent Chinese meal. If it’s below ¥180, it might seem a bit shabby. Even if you can just get full, the girl sitting across from you might not be satisfied. The best state is when there are still half a plate of food left after you’re full, and you can chat for a while and still have a few more bites.</p><img src="a.png" style="width:40%;" /><p>This is a spicy grilled fish I had a few days ago at Wangjing Kaide MALL, at a place called Nanluo Feimao. It was delicious. The fish was tender, with few bones, slightly spicy, just the right level of heat. The photo turned out bright and colorful. The pot had some additional ingredients, like luncheon meat, yuba, and fried dough sticks, averaging ¥180 per person.</p><img src="j.png" style="width:50%;" /><p>This is from a grilled fish place at Blue Harbor. I’m not sure if this counts as grilled fish since it’s soaked in soup. The fish wasn’t tasty, not as good as spicy grilled fish, but it was boneless. The sausage in the middle was something I insisted on ordering, but it all got left over. It wasn’t bad, just couldn’t eat any more. This meal averaged ¥300 per person, quite expensive, but a lot was wasted. We didn’t think to pack it up at the time.</p><img src="e.png" style="width:50%;" /><p>Beijing roast duck is a famous local dish, a classic. This was at Jinghua Yunyan in Hopson One, a slightly down-to-earth place with close square tables. Prices are moderate to low for a roast duck restaurant. The sweet shrimp wasn’t very good, but the drink cups were very cute. It was winter at the time, and the cups had little hats, which could be taken home as souvenirs. You can get full with ¥140 per person; if you order a couple more dishes, it’s ¥180 per person.</p><img src="c.png" style="width:50%;" /><p>This is at Siji Minfu Roast Duck Restaurant in Wangjing, a very popular chain where you almost always have to wait for over 40 minutes during meal times. The roast duck here is definitely tasty, but I think the best part is the meat soup, especially the soup, which is very delicious. The dishes initially have a strange smell that might be off-putting, but after a couple of sips, you start to like it. The cold dish, which I’m not sure what it’s mixed with, is very fine and cool, with a great texture. I don’t remember much about the roast duck, just that there were many dishes and we couldn’t finish them. The average cost per person was under ¥200.</p><p>Xiaoda Dong is also a well-known chain with many branches in various commercial districts. There’s one on the third floor of Sanlitun Taikoo Li. The braised pork is really satisfying, a must for meat lovers. Xiaoda Dong’s Kung Pao Chicken is also better than Siji Minfu’s, very flavorful. It also costs under ¥200 per person, with many dishes you can’t finish, leaving you very full. Unfortunately, I forgot to take pictures.</p><p>The more expensive roast duck restaurant is Ti Du, where I had a company dinner. The environment is very elegant, and the dishes are quite sophisticated. I haven’t dined there alone, but I estimate it costs at least ¥300 per person.</p><img src="b.png" style="width:50%;" /><p>This is from a Taiwanese restaurant called Taixiangli in Wudaokou Shopping Center. The three-cup chicken is the signature dish with a heavy sauce flavor. The grilled meat rice bowl is also worth trying, very filling. However, the crab roe bun was mediocre, a bit bland, possibly because the three-cup chicken’s strong flavor overpowered it. The average cost was around ¥170 per person.</p><img src="p.png" style="width:50%;" /><p>This is a spicy hot pot, cheap and delicious. The price of hot pot is similar; Haidilao costs around ¥150 per person, enough to get full, with leftovers.</p><center style="font-size: 110%;"><strong>Western Cuisine</strong></center><p>For a more upscale environment, you have to go for Western cuisine. The atmosphere is better, with larger table distances and flower vases on the tables. It’s also more expensive than Chinese cuisine. Cheaper Western meals cost around ¥250 per person, while pricier ones go up to ¥500 per person. I haven’t had anything more expensive.</p><img src="k.png" style="width:50%;" /><p>At a Western restaurant in Sanlitun, I didn’t have time for steak, so I ordered pizza and pasta, finished all the dishes in 10 minutes. I remember the pasta here being the best I’ve ever had, but when I went back, the pasta, pizza, and burgers were all different. The ingredients and plates had changed, and the taste wasn’t the same. By the way, why do Western restaurants have Japanese slogans? 😂</p><img src="g.png" style="width:50%;" /><p>This is a small place in a small mall in Wangjing, on the -1 floor. The photo by the window turned out nice. It was a casual dinner, averaging ¥250 per person.</p><img src="i.png" style="width:50%;" /><img src="m.png" style="width:40%;" /><p>This is the famous Flower Restaurant, with a great environment and beautiful dishes. The second photo is a blue butterfly cocktail, which changes color from blue to pink when you pour in the liquor, quite fun. The average cost was under ¥300 per person.</p><img src="h.png" style="width:50%;" /><p>This is the most expensive Western meal I’ve had, at Steak House. The Wellington steak set was very tender and delicious. The average cost was ¥500 per person.</p><center style="font-size: 110%;"><strong>Korean Cuisine</strong></center><p>For Korean cuisine, you can try the simplest bibimbap, available in various mall fast-food joints, costing ¥50 per person. Or you can try army stew, with Shin Ramyun being the best, and it’s not expensive. You can also buy a few packs of Shin Ramyun for ¥5 each to try at home.</p><img src="n.png" style="width:40%;" /><p>This is from a place in Wangjing called Yuan Mama’s Andong Chicken, in a shopping district. The chicken is Korean-style, with a slightly spicy flavor. The place is small and looks like home cooking, but the chicken is quite delicious. The soup looks heavy but is drinkable, and I really like the taste. Especially pouring the soup over rice to make a mixed rice dish. The average cost was ¥120 per person.</p><img src="f.png" style="width:50%;" /><p>A more substantial dish is Korean BBQ. Pork belly is the best, must order two servings, along with beef brisket and seaweed rice. But be careful not to let the BBQ catch fire; once, we used a wire mesh to grill the beef brisket, and it caught fire, burning all the meat.</p><center style="font-size: 110%;"><strong>Mexican Cuisine</strong></center><img src="l.png" style="width:40%;" /><p>Mexican food is inexpensive and surprisingly delicious. The meat looks dark but isn’t burnt, with a layer of sauce on top. Mexican dishes are typically wrapped in tortillas. There are small cards on the table explaining how to eat them: lift your hand, hold the tortilla, keep your forearm parallel to the table, and tilt your head 45 degrees. It’s quite a particular way of eating. Of course, if you really eat like that, it might look weird.</p><center style="font-size: 110%;"><strong>Japanese Cuisine</strong></center><p>Japanese cuisine prices are similar to Western cuisine, with many raw dishes like sashimi. I don’t eat it often, but sukiyaki is a common dish, along with various small grilled skewers. However, Japanese restaurants seem to have small and cramped spaces. There’s a place in Beijing, I forgot the name, where you can wear kimonos and take Japanese-style photos at the entrance, but the clothes aren’t new, the food is mediocre, expensive, and the portions are small, mainly for photo ops.</p><center style="font-size: 110%;"><strong>Desserts</strong></center><p>If you didn’t have lunch, you’d need to have afternoon tea around two or three in the afternoon. Although it’s just desserts, serving as a snack, the price isn’t cheap. Dessert prices vary, depending on the style of the dessert shop. There are basically two types. Fast-food-style dessert shops cost ¥80 per person, with each person having a cake and a drink, and maybe another cake or ice cream. The other type is internet-famous dessert shops, luxuriously decorated, designed for girls to take pictures, costing ¥180 per person.</p><img src="d.png" style="width:40%;" /><p>This is a fast-food-style dessert</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Looking back over the past six months of blog content, it seems a bit too serious and heavy. Recently, I’ve had a lot of meals and</summary>
        
      
    
    
    
    
    <category term="Life" scheme="https://en.smallyu.net/tags/Life/"/>
    
  </entry>
  
  <entry>
    <title>Blockchain Needs a Technological Revolution</title>
    <link href="https://en.smallyu.net/2023/03/06/Blockchain%20Needs%20a%20Technological%20Revolution/"/>
    <id>https://en.smallyu.net/2023/03/06/Blockchain%20Needs%20a%20Technological%20Revolution/</id>
    <published>2023-03-06T10:45:05.000Z</published>
    <updated>2025-08-06T10:38:27.639Z</updated>
    
    <content type="html"><![CDATA[<p>I happened to see a video earlier, which was about an Internet conference in a certain year. Robin Li of Baidu mentioned that Baidu made a mistake by not seizing the opportunity of mobile Internet. Back then, they thought SMS was expensive, costing 0.1 yuan per message, so they didn’t believe mobile search would become popular and did not invest in the mobile sector. By the time they realized the trend, it was too late. Mobile search was not just about shrinking web pages.</p><p>Hearing this speech reminded me, wasn’t the 0.1 yuan SMS back then similar to the current $10 Ethereum transaction?</p><p>The expensive SMS protocol charged per message, discouraging widespread use. As a result, the cheaper TCP protocol for Internet usage, charged based on traffic rather than messages, led to the obsolescence of SMS.</p><p>Let’s make a simple analogy: what if Ethereum stopped charging per transaction and instead charged based on the transaction amount?</p><p>This would require a fundamental change in the basic operating logic of the blockchain. Without considering implementation details, under the premise of “charging based on transaction amount,” what would happen to the blockchain?</p><p>Charging based on transaction amount means, for example, setting a transfer fee of 1%, so a $100 transfer would incur a $1 fee. Transferring $100 at once or in 10 transactions of $10 each would cost the same fee. The biggest advantage of this is that it greatly favors the popularity of small transactions.</p><p>(Then the network transaction volume skyrockets, miners can’t handle such a massive volume, the network becomes congested, paralyzed, chaotic, leading to multiple forks…</p><p>The popularity of small transactions means Ethereum is no longer just a financial product but becomes true currency. Currency can better fulfill the role of value transfer, which was also the initial vision of Bitcoin.</p><p>In other words, the most fundamental factor limiting the expansion of cryptocurrencies is the blockchain network’s ability to process transactions, requiring high throughput and low fees.</p><p>Under the current technical framework, this is almost impossible. If Bitcoin is SMS, Ethereum is a service that uses SMS for information retrieval, the Lightning Network is like an SMS subscription package, DeFi provides SMS-based financial management capabilities, DAO is an SMS group, GameFi is using SMS to play Snake, ZK Rollups is the most secure encryption for SMS… Web 3.0 is the mobile era integrating various SMS services, and the Metaverse is a virtual world using SMS as IM.</p><p>Today’s blockchain is still centered around “SMS,” striving to expand SMS’s business capabilities. However, the truly revolutionary technology needed is the Internet.</p><p>Next, let’s consider the possibilities of causing a technological revolution.</p><p>First is the exponential growth in hardware performance. If network transmission performance is greatly improved, blockchain transaction speed will also see significant enhancement.</p><p>Secondly, there is breakthrough progress in consensus algorithms. If consensus algorithms require fewer interactions and less network bandwidth, transaction capabilities can also improve.</p><p>Finally, we await the arrival of the Lord to bring new hope to the earth.</p><p>For the current state of the blockchain industry, you can refer to this article, which is an interview record by BlockBeats at this year’s ETHDenver conference: <a href="https://www.theblockbeats.info/news/35283">Interviewing 75 ETHDenver Participants: What “Wealth Codes” Did They Find at the Conference?</a> I didn’t read it thoroughly, but the gist is, there’s nothing too new, technological development faces resistance, and the industry is waiting for an explosion of applications.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;I happened to see a video earlier, which was about an Internet conference in a certain year. Robin Li of Baidu mentioned that Baidu made</summary>
        
      
    
    
    
    
    <category term="Blockchain" scheme="https://en.smallyu.net/tags/Blockchain/"/>
    
    <category term="Blockchain Revolution" scheme="https://en.smallyu.net/tags/Blockchain-Revolution/"/>
    
  </entry>
  
  <entry>
    <title>A Mechanism for Generating Random Numbers on the Blockchain</title>
    <link href="https://en.smallyu.net/2023/02/22/A%20Mechanism%20for%20Generating%20Random%20Numbers%20on%20the%20Blockchain/"/>
    <id>https://en.smallyu.net/2023/02/22/A%20Mechanism%20for%20Generating%20Random%20Numbers%20on%20the%20Blockchain/</id>
    <published>2023-02-22T10:19:59.000Z</published>
    <updated>2025-08-06T10:38:27.628Z</updated>
    
    <content type="html"><![CDATA[<p>The blockchain itself does not allow for random numbers because all nodes need to synchronize their results. If the results differ each time, the entire network would be in chaos. In other words, on the blockchain, if there is a function that generates random numbers, it needs to meet two requirements: 1. The return value is unpredictable; 2. The return value is deterministic.</p><p>These two requirements seem contradictory, but there are solutions. Chainlink’s oracle provides a method for generating random numbers using VRF. Due to the characteristics of VRF, it is suitable for generating random numbers in the blockchain scenario.</p><p>However, now we need to discuss another issue: miner misbehavior. You can refer to this article: <a href="https://hackingdistributed.com/2017/12/24/how-not-to-run-a-blockchain-lottery/">How Not To Run A Blockchain Lottery</a></p><p>Suppose there is a lottery game running on the blockchain, and miners also participate in the lottery. Since winning the lottery results in huge rewards, as long as the reward exceeds the miner’s mining income, the miner has enough motivation to misbehave. The way to misbehave is that because the execution result of a transaction is deterministic, the miner will know the result first. If the result is unfavorable to them, the miner can refuse to produce the block. Economically, this may not be worthwhile for the miner, but this situation not only adds unfairness to the lottery game but also gives miners the right to misbehave. Miners can also be bribed, and if miners collectively misbehave, the network will be in chaos.</p><p>In the face of this situation, we need a way to generate random numbers where miners cannot know what the number is. The random number will only be revealed after the block is confirmed on the chain.</p><p>What is truly random and hard to predict? The future is unpredictable.</p><p>We can try using this method: use the block hash of the block height +2 of the current transaction as the random number seed.</p><p>For example, a transaction is initiated to generate a random number, the current block height is 1, after the transaction is submitted, the random number is null, and the actual random number will only be displayed when the block height reaches 3. Because this random number uses the block hash of height 3 as the random number seed, no one can know what this number will be before the block height reaches 3.</p><p>In the lottery scenario, the lottery result is determined at block height 1, users have already participated in the lottery in the transaction at block height 1, and the lottery result is only announced at block height 3. This almost avoids the problem of miner misbehavior because at block height 1, miners do not know what the result is, and at block height 3, the order and result of the lottery have been determined.</p><p>But can’t miners refuse to produce blocks at block height 3? Refusing 1 block or refusing 3 blocks makes no difference.</p><p>Here we need to distinguish between two situations:</p><ul><li>Requests made at block height 1, querying at block heights 3, 4, and 5 will all get the random number calculated using the block hash at height 3 as the seed.</li><li>Requests made at block height 1 use the block hash at height 3 as the seed; requests made at block height 2 use the block hash at height 4 as the seed.</li></ul><p>To achieve a completely random effect, the second method should be used.</p><p>But then the problem arises, the current block height is constantly changing, won’t this random value become a variable? Users generate a random number at block height 3 and want to know what this random number is, but they can never get this value because the number is actually produced at block height 5, and when querying at block height 5, they have to wait until block height 7…</p><p>Here we need to distinguish between two concepts: generating a random number and querying a random number. The above two situations are described based on the mechanism of querying a random number.</p><p>According to the mechanism of generating a random number, the second method is necessary, otherwise, the random number becomes a constant. What about querying? The undeniable fact is that as long as the user can query the result, the miner can also query it and will know in advance. The problem returns to the original dilemma, which seems unsolvable.</p><p>No, no.</p><p>Why set it to use the block hash of height +2 instead of +1? It is to avoid miners knowing the result in advance. If it is +1, miners can know the result after mining 1 block; if it is +2, miners generally find it difficult to lead the network by 2 blocks.</p><p>So a better approach is to request a random number at block height 1, and then use the block hashes of block heights 2 and 3 as the random number seed. In this case, the miner’s third block will have some influence on the random number, but not a decisive influence. It is possible that the second block has already determined that the miner will not win, so the miner has no reason to misbehave at the third block.</p><p>But what if the third block can still greatly influence the random number? Miners can still refuse to produce blocks.</p><p>From this perspective, the more delayed blocks, the less influence the miner has. If the random number is determined by the block hash of +10 blocks, the first 9 blocks have already eliminated all miners, so miners will not misbehave.</p><p>Are there better solutions? It seems not. If the block hash of +2 blocks is used as the private key for symmetric encryption, the random value is generated before the +2 block is produced but cannot be decoded. The problem is that the contract cannot use the +2 block as the key to encrypt the random value in advance.</p><p>We can only reduce the miner’s influence.</p><p>The future is unpredictable, but when it arrives, some will always have foresight.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;The blockchain itself does not allow for random numbers because all nodes need to synchronize their results. If the results differ each</summary>
        
      
    
    
    
    
    <category term="Blockchain" scheme="https://en.smallyu.net/tags/Blockchain/"/>
    
    <category term="MEV" scheme="https://en.smallyu.net/tags/MEV/"/>
    
  </entry>
  
  <entry>
    <title>Why the Private Key Calculation of Ethereum is Irreversible</title>
    <link href="https://en.smallyu.net/2023/02/20/Why%20the%20Private%20Key%20Calculation%20of%20Ethereum%20is%20Irreversible/"/>
    <id>https://en.smallyu.net/2023/02/20/Why%20the%20Private%20Key%20Calculation%20of%20Ethereum%20is%20Irreversible/</id>
    <published>2023-02-20T15:42:24.000Z</published>
    <updated>2025-08-06T10:38:28.726Z</updated>
    
    <content type="html"><![CDATA[<p>Have you ever wondered why the private key of Ethereum cannot be reverse-calculated from the account address? When you have a private key and want to get the account address corresponding to this private key, you can import the account into MetaMask, or use an SDK like ether.js to import an account into the wallet at the code level, and then print out the account address. Is there any black box operation in this account import process?</p><p>A few days ago, I accidentally saw an article on Medium, where the author wrote a very concise code to calculate the process from the private key to the address. The author’s code is here <a href="https://gist.github.com/RareSkills/eb51623908f348663cd6a241d9dbf115">RareSkills&#x2F;generate-ethereum-address-lower-level.py</a>.</p><p>I copied the code:</p><pre><code class="python">from ecpy.curves import Curvefrom sha3 import keccak_256private_key = 0xac0974bec39a17e36ba4a6b4d238ff944bacb478cbed5efcae784d7bf4f2ff80cv     = Curve.get_curve(&#39;secp256k1&#39;)pu_key = private_key * cv.generator # just multiplying the private key by generator point (EC multiplication)concat_x_y = pu_key.x.to_bytes(32, byteorder=&#39;big&#39;) + pu_key.y.to_bytes(32, byteorder=&#39;big&#39;)eth_addr = &#39;0x&#39; + keccak_256(concat_x_y).digest()[-20:].hex()print(&#39;private key: &#39;, hex(private_key))print(&#39;eth_address: &#39;, eth_addr)</code></pre><p>This code has only four or five lines, and there are two key points in the calculation: <code>private_key * cv.generator</code> and <code>keccak_256(concat_x_y)</code>. Apart from these two points, the other parts are constant calculations. At first glance, it seems complicated, but when you look at it carefully and break it down, it’s all very simple string concatenation.</p><p>Among them, <code>private_key * cv.generator</code> is the calculation of the elliptic curve. The private key <code>private_key</code> defined above is a hexadecimal number, note it is of <code>int</code> type, and then the generator of the elliptic curve is used to calculate a value. This calculation process is irreversible, which is the process of circling on the elliptic curve. It can be understood by analogy that after a number is taken modulo, you cannot restore the number before the modulo. The elliptic curve just uses a more complex method to provide a safer calculation result than RSA.</p><p>The second irreversible calculation is <code>keccak_256(concat_x_y)</code>, which is a process of calculating the hash value. Keccak is a kind of sha3. Digest algorithms are irreversible, which is undoubtedly the case.</p><p>In other words, in the calculation process from the private key to the address, there are two irreversible points, so overall, it is impossible to reverse calculate the private key from the Ethereum account address.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Have you ever wondered why the private key of Ethereum cannot be reverse-calculated from the account address? When you have a private</summary>
        
      
    
    
    
    
    <category term="Blockchain" scheme="https://en.smallyu.net/tags/Blockchain/"/>
    
  </entry>
  
  <entry>
    <title>On Ethereum Private Key Collision</title>
    <link href="https://en.smallyu.net/2023/01/18/On%20Ethereum%20Private%20Key%20Collision/"/>
    <id>https://en.smallyu.net/2023/01/18/On%20Ethereum%20Private%20Key%20Collision/</id>
    <published>2023-01-18T07:27:25.000Z</published>
    <updated>2025-08-06T10:38:27.722Z</updated>
    
    <content type="html"><![CDATA[<p>Would you try your luck if you had a 1&#x2F;100000000 chance to get rich?</p><h3 id="Ethereum-Private-Key"><a href="#Ethereum-Private-Key" class="headerlink" title="Ethereum Private Key"></a>Ethereum Private Key</h3><p>Ethereum accounts are entirely controlled by private keys, and an account’s address can be derived from its private key. A private key is a 64-character hexadecimal string, such as:</p><pre><code>0xd110227375ab838e8743192d278c105e30f253c966987c50b754412c9b986fe3</code></pre><p>You can import the corresponding account into any Ethereum wallet using this private key. The address for this private key is:</p><pre><code>0x00000006A3D4DA3A559829B1730603CAeE97cC3D</code></pre><p>You can also check account-related <a href="https://etherscan.io/address/0x00000006A3D4DA3A559829B1730603CAeE97cC3D">transaction records</a> on Ethereum explorers based on this address.</p><h3 id="Private-Key-Collision"><a href="#Private-Key-Collision" class="headerlink" title="Private Key Collision"></a>Private Key Collision</h3><p>Since a private key is just a string, is it possible to randomly generate a string such that the corresponding account address happens to have money in it? With the private key, you can control all assets in the account. There are many accounts on Ethereum with substantial balances. What if you happened to generate a private key corresponding to one of these accounts? You’d instantly become rich.</p><p>Of course, the randomly generated string must be a 64-character hexadecimal string. To avoid any collision prevention mechanisms in the Ethereum SDK, we can generate it straightforwardly, like this:</p><pre><code>```javascriptlet s = &quot;0123456789abcdef&quot;;let hex = &quot;0x&quot;;for (let i = 0; i &lt; 64; i++) &#123;  hex += s[Math.floor(Math.random() * 16)];&#125;</code></pre><pre><code>This method is straightforward, generating a 64-character string through random concatenation. Although Ethereum doesn&#39;t have collision prevention mechanisms.### Collision ProbabilityLet&#39;s calculate the probability of randomly generating a private key that collides with an existing account. If there&#39;s an address, how likely is it to randomly generate the private key for that address?In hexadecimal, each character has a 1/16 chance of matching a target private key character. For a 64-character string, the probability is (1/16)&lt;sup&gt;64&lt;/sup&gt;.</code></pre><p>p &#x3D; (1&#x2F;16)^64  &#x3D; 1 &#x2F; 16^64  &#x3D; 1 &#x2F; 115792089237316195423570985008687907853269984665640564039457584007913129639936</p><pre><code>Rounding off and considering just the order of magnitude:</code></pre><p>p &#x3D; 1 &#x2F; 115792089237316195423570985008687907853269984665640564039457584007913129639936  &#x3D; 1 &#x2F; 100000000000000000000000000000000000000000000000000000000000000000000000000000  &#x3D; 1 &#x2F; 10^77</p><pre><code>This is an extremely low probability. The lowest winning rate for the Chinese lottery, &quot;Daletou,&quot; is one in ten million, or 1/10^8. The probability of an Ethereum private key collision being a specific account is equivalent to winning the lottery ten times in a row. It&#39;s almost impossible.However, lottery winning has a speed limit, such as requiring a day to announce the result. Cryptocurrency private keys don&#39;t have such a limit. Can increasing the speed of random private key generation improve the collision probability?Currently, the [hash rate](https://www.blockchain.com/explorer/charts/hash-rate) of the entire Bitcoin network is 270M TH/s. Bitcoin mining involves continuous hashing until a string with a certain number of leading zeros is found. Thus, Bitcoin&#39;s hash rate can describe the private key generation rate. After [unit conversion](https://en.bitcoinwiki.org/wiki/Hashrate):</code></pre><p>r &#x3D; 270M TH&#x2F;s  &#x3D; 270000000 TH&#x2F;s  &#x3D; 270000000000 GH&#x2F;s  &#x3D; 270000000000000 MH&#x2F;s  &#x3D; 270000000000000000 kH&#x2F;s  &#x3D; 270000000000000000000 &#x2F;s  &#x3D; 100000000000000000000 &#x2F;s  &#x3D; 10^20</p><pre><code>This result is rounded to the nearest order of magnitude. If you had the global Bitcoin mining power to perform Ethereum private key collisions, the per-second probability would be:</code></pre><p>ps &#x3D; p * r   &#x3D; 1 &#x2F; 10^57   &#x3D; 1 &#x2F; 1000000000000000000000000000000000000000000000000000000000</p><pre><code>This is still a remote probability. What if the collision attempt continues for one year?</code></pre><p>py &#x3D; ps * 60 * 60 * 24 * 365   &#x3D; ps * 31536000   &#x3D; ps * 10000000   &#x3D; ps * 10^7   &#x3D; 1 &#x2F; 10^50   &#x3D; 1 &#x2F; 100000000000000000000000000000000000000000000000000</p><pre><code>What about 100 million years of continuous operation?</code></pre><p>pb &#x3D; py * 100000000   &#x3D; py * 10^8   &#x3D; 1 &#x2F; 10^42   &#x3D; 1 &#x2F; 1000000000000000000000000000000000000000000</p><pre><code>As shown, time increases the probability only slightly. Computing power may increase exponentially, like the speed improvements of Apple&#39;s M series chips over Intel chips. However, this is still insignificant compared to the order of magnitude with 70 zeros.Even with the computing power of 100 million Earths&#39; worth of Bitcoin miners running for 100 million years, you&#39;d only reduce a few zeros from the likelihood of collision success.### Giving It a TryDespite the improbability, I still want to try.I wrote a script, [eth-collision/eth-collision-random](https://github.com/eth-collision/eth-collision-random), which randomly generates private keys and checks the account balance on [etherscan.io](https://etherscan.io) for addresses derived from these keys. If the balance is greater than zero, it logs the private key. Due to Etherscan&#39;s API call rate limit, the script checks 20 addresses per second, attempting 1.72 million addresses per day.This speed isn&#39;t fast enough. Is there a better way? Most third-party services have API rate limits. To query without restrictions, you&#39;d need to run your own Ethereum node. The minimum hardware requirements for an Ethereum node are a 4-core CPU, 16GB of RAM, and a 1TB hard drive. Such a server costs at least $300 per month on [Vultr](https://www.vultr.com/). It&#39;s expensive. After setting up the node, you&#39;d need to write a program to collect addresses with balances from transaction data in each block, which takes a long time.I noticed that [this page](https://etherscan.io/accounts/1?ps=100) provides a list of Ethereum addresses with the highest balances, 100 per page, for a total of 100 pages. I wrote a crawler, [eth-collision/eth-address-top-list](https://github.com/eth-collision/eth-address-top-list.git), to fetch data from this page, giving me a list of the top 10,000 Ethereum addresses by balance.With these 10,000 addresses, the program can run faster without API rate limits or needing a full node. I used Golang to write a program, [eth-collision/eth-collision-match-address](https://github.com/eth-collision/eth-collision-match-address.git), starting 100 goroutines to speed up private key generation. The program loads the 10,000 addresses into a map and checks if the randomly generated account is in the target list. A JavaScript for-loop can max out the CPU, but intuitively, Golang feels faster.By the way, remember to add a mutex to the map in Golang because maps aren&#39;t concurrency-safe. Adding locks reduces speed. To solve the lock issue, since there are only 10,000 addresses, not much memory is needed, so instantiate multiple maps, one for each goroutine. This ensures the efficiency of private key generation and verification.Are 10,000 addresses too few? How many Ethereum addresses are there? According to Etherscan [statistics](https://etherscan.io/chart/address), there are currently about 230M, approximately 200 million addresses.I found a repository, [eth-collision/Wallet-private-key-collision-brute-force-tool](https://github.com/eth-collision/Wallet-private-key-collision-brute-force-tool), providing a OneDrive download link for a file containing 180 million account addresses with transaction records on the chain. The compressed file is 4.4GB, and after decompression, it&#39;s about 16GB in pkl format, which I converted to a txt file using Python.With this many account addresses, the question becomes how to use the data.First, load all data into a map. This amount of data in memory would require at least 16GB, necessitating a 24GB server. The cheapest suitable server on Vultr costs nearly $150 per month. Furthermore, Golang&#39;s query efficiency with such a large data set and the need for locking are concerns.Are there better solutions? MySQL can&#39;t handle billion-level data queries efficiently. In a previous project, the simplest query in a</code></pre>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Would you try your luck if you had a 1&amp;#x2F;100000000 chance to get rich?&lt;/p&gt;
&lt;h3 id=&quot;Ethereum-Private-Key&quot;&gt;&lt;a</summary>
        
      
    
    
    
    
    <category term="Blockchain" scheme="https://en.smallyu.net/tags/Blockchain/"/>
    
  </entry>
  
  <entry>
    <title>Guess 2/3 of the Average dApp Game Design</title>
    <link href="https://en.smallyu.net/2022/12/27/Designing%20a%20Guess%202_3%20of%20the%20Average%20dApp%20Game/"/>
    <id>https://en.smallyu.net/2022/12/27/Designing%20a%20Guess%202_3%20of%20the%20Average%20dApp%20Game/</id>
    <published>2022-12-27T07:48:46.000Z</published>
    <updated>2025-08-06T11:20:25.209Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://zh.m.wikipedia.org/zh-cn/%E7%8C%9C%E5%9D%87%E5%80%BC%E7%9A%842/3">Guess 2&#x2F;3 of the Average</a> is a classic game-theory exercise. This post adapts it into a blockchain-based dApp. The basic rules are:</p><ol><li>A player pays <strong>any amount</strong> to join a round.  </li><li>Sum the <strong>total amount</strong> paid by all players.  </li><li>Take two-thirds of the <strong>average</strong> of this total as the <strong>winning number</strong>.  </li><li>The player whose <strong>paid amount</strong> is closest to the winning number wins.</li></ol><p>Reward rules:</p><ol start="5"><li>The winner receives the round’s <strong>total amount</strong>.  </li><li>The contract collects a 1 % <strong>service fee</strong> from the total each round.</li></ol><p>A key question is how many players are in a round—i.e., when does a round end? The ending rule is:</p><ol start="7"><li>When a player joins, they learn they are the <strong>n-th</strong> participant.  </li><li>Generate a random number <strong>x</strong> (10 ≤ x ≤ 100).  </li><li>Define a random boundary <strong>l, r &#x3D; n − x, n + x</strong>.  </li><li>Draw another random number <strong>y</strong> within <strong>[l, r]</strong>.  </li><li>If <strong>y &#x3D;&#x3D; n</strong>, the round ends.</li></ol><p>Additional rules:</p><ol start="12"><li>If a user joins multiple times, only their <strong>first</strong> entry counts.  </li><li>If several users pay <strong>identical amounts</strong>, the one who joined <strong>first</strong> wins.</li></ol><p>Those are all the rules.</p><p>The ending rule is a bit involved, so here’s an example. Suppose a player is the <strong>n &#x3D; 50</strong>-th entrant and <strong>x &#x3D; 10</strong>. The boundary becomes <strong>l, r &#x3D; 45, 55</strong>. A new random number is picked in [45, 55]; if it happens to be 50, the round ends.</p><p><strong>Why do this?</strong> Because blockchain data are public. In the original game, every choice is hidden, which is hard to replicate on-chain. The dApp version therefore differs in two main ways:</p><ul><li>A player may pay <strong>any</strong> amount—even 0 or extremely large—whereas the original game had an upper cap.  </li><li>The number of players is <strong>unknown</strong>, while the original fixed it.</li></ul><p>Both changes stem from on-chain transparency, so randomness must be added. Without a random ending, later players would always have an advantage by seeing earlier entries.</p><p>Of course, the last player cannot always overturn the result, especially with an upper cap, but if the player count is random there is no guaranteed “last” player—no one knows when the round will stop. Even someone rich enough to swing the average could be overtaken instantly.</p><p>The original game required integer inputs; the dApp version lifts that restriction because a smart contract can handle arbitrary precision.</p><hr><h3 id="Why-the-ending-rule-works"><a href="#Why-the-ending-rule-works" class="headerlink" title="Why the ending rule works"></a>Why the ending rule works</h3><p>Its effect is to make a round end, in most cases, when the player count falls in **[10, 100]**—the range set by <strong>x</strong> in rule 9.</p><p>Think of it this way: every user has a random <strong>chance</strong> to end the round, between 1⁄10 and 1⁄100. If the chance were 1⁄10, a round would typically end after about 10 players; if 1⁄100, after about 100 players. Thus <strong>x</strong> roughly limits the player count. (The [10, 100] range is approximate, not an exact calculation.)</p><p>Using this rule, I simulated 100 000 rounds and recorded the player count at which each ended. Code: <a href="https://github.com/guessavg/emulate_tool">guessavg&#x2F;emulate_tool</a></p><img src="chart1.png" width="60%"><p>The horizontal axis is player count; the vertical axis is how many times a round ended at that count. Near 1, there are 2 500 occurrences—i.e., 2.5 % of rounds ended after a single player.</p><img src="chart2.png" width="60%"><p>If raw counts feel abstract, see the ratio chart: no single count exceeds 2.5 %. Early positions have higher odds because every round starts from zero.</p><img src="chart3.png" width="60%"><p>This ratio view is clearer: about 20 % of rounds end with fewer than 10 players, ~70 % within <strong>[10, 100]</strong>, and only 0.07 % need more than 300 players.</p><p>Although the distribution is not perfectly normal, it meets the goal: rounds finish at random yet reasonable times, avoiding too-few or too-many participants while still allowing a small chance (up to ~500 players).</p><p>I believe this is a sound design.</p><p><br/><br/></p><h3 id="Update-2025-04-22"><a href="#Update-2025-04-22" class="headerlink" title="Update (2025-04-22)"></a>Update (2025-04-22)</h3><p>Over a year ago I wrote “<a href="/2022/12/27/%E2%80%9C%E7%8C%9C%E5%9D%87%E5%80%BC%E7%9A%842-3%E2%80%9DdApp-%E6%B8%B8%E6%88%8F%E8%AE%BE%E8%AE%A1/">‘Guess 2&#x2F;3 of the Average’ dApp Game Design</a>”.</p><p>Thanks to modern ChatGPT, implementing the game is now easy; contract and front-end are quick to build. I spent only two hours today to create a demo page.</p><p>Play here: <a href="https://guessavg.oiia.network/">https://guessavg.oiia.network/</a></p><p>Some notes:</p><ol><li>The mini-game currently runs on Oiia Network. Contract address <a href="https://explorer.oiia.network/account/0x6eb079C9D3005Bd596E8a0E5065fA33C80aBA8F1"><code>0x6eb07...BA8F1</code></a>  </li><li>Joining simply calls a contract function and transfers funds—for example, tx <a href="https://explorer.oiia.network/tx/0x1bfb286c9ed796e16870cc36488bd3c11db6eef43e34c425e58ac76715010936"><code>0x1bfb2...10936</code></a>  </li><li>Contract code: <a href="https://github.com/guessavg/contract">guessavg&#x2F;contract</a>. It can be deployed anywhere; I used Oiia because it’s free.  </li><li>Front-end code: <a href="https://github.com/guessavg/game">guessavg&#x2F;game</a>, used with the contract.  </li><li>Get test OIIA from the faucet: <a href="https://faucet.oiia.network/">https://faucet.oiia.network/</a>  </li><li>The private key below holds 10 OIIA for testing. Duplicate entries from the same address are disallowed, so transfer OIIA to a fresh address first:<br><code>fdf0aec857f3ac4fe146e0d00fb3a7a729646a081719df3f4e168a541a21893b</code>  </li><li>Metamask shows an error when adding Oiia, but it actually succeeds; I haven’t debugged it. A month ago this code raised no error.  </li><li>Oiia Network may disappear at any time.  </li><li>Just for fun…</li></ol><br><h3 id="Update-2025-05-06"><a href="#Update-2025-05-06" class="headerlink" title="Update (2025-05-06)"></a>Update (2025-05-06)</h3><p>Oiia Network shut down today because I no longer wish to fund an unused chain. The demo has moved to Base.</p><ol><li>Demo: <a href="https://guessavg.github.io/game/">https://guessavg.github.io/game/</a>  </li><li>Contract on Base: <a href="https://basescan.org/address/0x4BbeE9F876ff56832E724DC9a7bD06538C8868D2"><code>0x4BbeE...868D2</code></a>  </li><li>You need ETH on Base to play.  </li><li>The game is easier now; a round ends after only two or three players.</li></ol>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://zh.m.wikipedia.org/zh-cn/%E7%8C%9C%E5%9D%87%E5%80%BC%E7%9A%842/3&quot;&gt;Guess 2&amp;#x2F;3 of the Average&lt;/a&gt; is a classic</summary>
        
      
    
    
    
    
    <category term="dApp" scheme="https://en.smallyu.net/tags/dApp/"/>
    
  </entry>
  
  <entry>
    <title>Differences Between Proof of Storage/Space/Replication</title>
    <link href="https://en.smallyu.net/2022/12/20/Differences%20Between%20Proof%20of%20Storage_Space_Replication/"/>
    <id>https://en.smallyu.net/2022/12/20/Differences%20Between%20Proof%20of%20Storage_Space_Replication/</id>
    <published>2022-12-20T09:58:48.000Z</published>
    <updated>2025-08-06T10:38:27.646Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Timeline"><a href="#Timeline" class="headerlink" title="Timeline"></a>Timeline</h3><style>table {    display: inline;}</style><center><table><thead><tr><th>Abbreviation</th><th>Full Name</th><th>Year</th></tr></thead><tbody><tr><td>PDP</td><td>Provable Data Possession</td><td>2007</td></tr><tr><td>PORs</td><td>Proofs of Retrievability</td><td>2007</td></tr><tr><td>PoS</td><td>Proofs of Storage</td><td>2009</td></tr><tr><td>PoS</td><td>Proofs of Space</td><td>2013</td></tr><tr><td>PoST</td><td>Proofs of Space-Time</td><td>2016</td></tr><tr><td>PoRep</td><td>Proof of Replication</td><td>2017</td></tr><tr><td>PoC</td><td>Proof of Capacity</td><td>2017</td></tr></tbody></table></center><h3 id="Proofs-of-Storage"><a href="#Proofs-of-Storage" class="headerlink" title="Proofs of Storage"></a>Proofs of Storage</h3><p>PDP and PORs were independently published in 2007, each having its own advantages and disadvantages in terms of file proof methods, addressing different branches of the same problem.</p><p>The concept of PoS (Proofs of Storage) emerged as early as 2009, serving as a general term for interactive protocols where a client verifies files on a server, encompassing both PDP and PORs. For example, the paper “Proofs of Storage from Homomorphic Identification Protocols,” with Giuseppe Ateniese as the first author.</p><p>Since blockchain was not well-developed in 2009, PoS (Proofs of Storage) had no relation to consensus mechanisms and merely shared an acronym with PoS (Proof of Stake) without any actual connection.</p><p>PDP and PORs are predecessors to PoS, which unified them under a single name.</p><h3 id="Proofs-of-Space"><a href="#Proofs-of-Space" class="headerlink" title="Proofs of Space"></a>Proofs of Space</h3><p>PoS (Proofs of Space) began with the 2013 paper “Proofs of Space,” with Stefan Dziembowski as the first author.</p><p>Coincidentally, PoS (Proofs of Space) and PoS (Proofs of Storage) share the same abbreviation, which can sometimes cause confusion. In this section, PoS refers to Proofs of Space.</p><p>The concept of PoS aims to parallel PoW (Proof of Work). Hence, from PoS onwards, it is a concept within blockchain, serving as a consensus mechanism.</p><p>PoW involves mining using CPU power, whereas PoS proposes mining using disk capacity, seeking ways to prove a server has a certain amount of disk space.</p><p>The most basic method involves a client generating a file, for example, 1GB, sending it to the server, and then verifying the server has saved that file, thereby proving the server indeed has 1GB of disk space. However, this method is too cumbersome, consuming the client’s disk space and putting immense pressure on network transmission.</p><p>PoS offers a method using a data structure known as hard to pebble graphs, such as a Merkle hash tree. This data structure’s feature is that generating upper-level data must rely on lower-level data.</p><p>For example, in a system using a Merkle hash tree, a client can request the server to return the entire chain of a certain upper-level node, and then verify the path’s correctness. Cross-verifying multiple paths can generally ensure the server’s reliability.</p><h3 id="Proofs-of-Space-Time"><a href="#Proofs-of-Space-Time" class="headerlink" title="Proofs of Space-Time"></a>Proofs of Space-Time</h3><p>PoST (Proofs of Space-Time) emerged in 2016 with the paper “Simple Proofs of Space-Time and Rational Proofs of Storage,” with Tal Moran as the first author.</p><p>PoST builds upon the PoS (Proofs of Space) scheme because while PoS can prove a server has a certain amount of disk space, it cannot prove that the server’s capacity consistently remains at the expected level. For example, during verification, the server’s disk space is 1GB, but once verification ends, the server uses the space for other purposes. During the next verification, the server regenerates the 1GB file for verification.</p><p>Hence, PoS suggests verifying every minute to ensure the server’s honesty. This is clearly not a smart approach.</p><p>PoST aims to solve this problem by increasing the difficulty of the initialization phase, that is, the phase where PoS generates the file, ensuring that the server must spend enough time to generate the file.</p><p>To ensure sufficient time is needed, PoW (Proof of Work) can be used, such as computing 2^30 hash values, which implies a certain amount of time spent.</p><p>PoST combines PoW and PoS by requiring the server to spend enough time generating the file during the initialization phase and then verifying the file generated during the proof phase.</p><h3 id="Proof-of-Replication"><a href="#Proof-of-Replication" class="headerlink" title="Proof of Replication"></a>Proof of Replication</h3><p>PoRep (Proof of Replication) originates from the 2017 paper “Proof of Replication,” with Juan Bene as the first author.</p><p>PoRep is a type of Proofs of Storage and is a research outcome of Protocol Labs, which also developed IPFS and Filecoin. PoRep is the consensus mechanism used by Filecoin.</p><p>PoRep builds upon Proofs of Space and Proofs of Retrievability, adding the capability to distinguish the number of replicas on the server. The approach is relatively simple: during the tag generation phase, a unique identifier is attached to each replica, making each replica unique.</p><p>Because Filecoin operates in a decentralized network, it needs to ensure multiple replicas exist throughout the network. If nodes collude maliciously, previous proof methods are inadequate, so Filecoin employs the PoRep consensus mechanism.</p><p>The 2017 version of PoRep is relatively simple. The 2018 version introduces the use of Depth Robust Graphs data structures. The paper is titled “PoReps: Proofs of Space on Useful Data,” with Ben Fisch as the first author.</p><h3 id="Proof-of-Capacity"><a href="#Proof-of-Capacity" class="headerlink" title="Proof of Capacity"></a>Proof of Capacity</h3><p>PoC (Proof of Capacity) is a consensus mechanism used by the Burstcoin blockchain in 2017.</p><p>PoC provides a mining method where generating new blocks requires a nonce value:</p><pre><code>1 nonce = 8192 hash value = 4095 scoops</code></pre><p>The hash value is calculated using the Shabal hash function, with every two hash values forming one scoop.</p><p>A scoop number is randomly selected from 0 to 4095, and then combined with the corresponding nonce to calculate a <code>deadline</code> value. Among all nodes, the one with the smallest deadline value can generate a new block.</p><p>PoC leans towards being a purely consensus mechanism.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h3 id=&quot;Timeline&quot;&gt;&lt;a href=&quot;#Timeline&quot; class=&quot;headerlink&quot; title=&quot;Timeline&quot;&gt;&lt;/a&gt;Timeline&lt;/h3&gt;&lt;style&gt;
table {
    display:</summary>
        
      
    
    
    
    
    <category term="Consensus Mechanism" scheme="https://en.smallyu.net/tags/Consensus-Mechanism/"/>
    
    <category term="File Proof" scheme="https://en.smallyu.net/tags/File-Proof/"/>
    
  </entry>
  
  <entry>
    <title>Proofs of Retrievability: Understanding Document Verification</title>
    <link href="https://en.smallyu.net/2022/12/16/Proofs%20of%20Retrievability:%20Understanding%20Document%20Verification/"/>
    <id>https://en.smallyu.net/2022/12/16/Proofs%20of%20Retrievability:%20Understanding%20Document%20Verification/</id>
    <published>2022-12-16T09:22:05.000Z</published>
    <updated>2025-08-06T10:38:27.727Z</updated>
    
    <content type="html"><![CDATA[<p>PORs (Proofs of Retrievability) and PDP were published in the same year, 2007. The paper is titled “PORs: Proofs of Retrievability for Large Files,” with Ari Juels as the first author.</p><p>PORs not only prove that a file is indeed stored on the server, but also whether the file has been modified or deleted, a capability that PDP lacks. However, the limitation of PORs is that they can only be used for encrypted files, meaning the file must be encrypted. The key to implementing PORs lies in the complex setup phase.</p><p>The idea behind PORs is that the client generates some random encodings recorded in an array, called sentinels. For example, <code>[6, 4, 0]</code> are three sentinels.</p><p>First, the client’s file is symmetrically encrypted, and it must be done using a block cipher method. During the encryption process, the sentinels are inserted into random positions in the file. Between two sentinels, there might be 1 block or countless blocks; the positions of the sentinels are random.</p><p>Then the encrypted file is sent to the server for storage.</p><p>The content of the client’s challenge is to ask the server to return the encodings at n random positions in the file. The challenge includes the positions of the sentinels.</p><p>Since the file is encrypted, the server cannot determine whether the challenge positions are from the original file data or the sentinel data. The server finds it difficult to predict the positions of the sentinels.</p><p>For the client, it only needs to verify the encodings corresponding to the sentinel positions to determine if the file exists and is intact. If the file is modified or some data in between is lost, the encoding at the sentinel positions will be vastly different, making the challenge impossible to complete.</p><p>Retrievability means that for the client, it can verify a part of the file by specifying the sentinel positions. For example, it can verify the file between the 1st and 3rd sentinels, or between the 5th and 9th sentinels, pointing and checking as needed.</p><p>As for why the file must be encrypted, on one hand, PORs rely on symmetric encryption’s block cipher, and on the other hand, for unencrypted files, the server can more easily predict the sentinel positions. Therefore, PORs can only be used for encrypted files.</p><p>The paper also introduces error-correcting codes to enhance the file’s fault tolerance. In the setup phase, error-correcting codes are added to the blocks before symmetric encryption. The advantage of introducing error-correcting codes is that within a certain error range between two sentinels, if the file is damaged, it can be repaired.</p><p>Why do error-correcting codes become important in the PORs mechanism? Because they combine with the characteristic of PORs, Retrievability. If the file is stored in multiple server environments and suffers different degrees of damage, the presence of sentinels makes it easier to recover parts of the file from other servers. In this context, the introduction of error-correcting codes further strengthens the file’s fault tolerance.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;PORs (Proofs of Retrievability) and PDP were published in the same year, 2007. The paper is titled “PORs: Proofs of Retrievability for</summary>
        
      
    
    
    
    
    <category term="File Proof" scheme="https://en.smallyu.net/tags/File-Proof/"/>
    
  </entry>
  
  <entry>
    <title>Example and Explanation of S-PDP File Proof</title>
    <link href="https://en.smallyu.net/2022/12/14/Example%20and%20Explanation%20of%20S-PDP%20File%20Proof/"/>
    <id>https://en.smallyu.net/2022/12/14/Example%20and%20Explanation%20of%20S-PDP%20File%20Proof/</id>
    <published>2022-12-14T13:39:59.000Z</published>
    <updated>2025-08-06T10:38:27.655Z</updated>
    
    <content type="html"><![CDATA[<p>What we now refer to as PDP generally refers to the PDP mentioned in the 2007 paper “Provable Data Possession at Untrusted Stores,” with Giuseppe Ateniese as the first author. Before this paper, there were already some concepts of file proof, such as B-PDP, but none could ensure that the server had actually stored the file.</p><p>S-PDP is a scheme first proposed in the paper, which can be used by the client to confirm that a file has indeed been saved to the server environment, which is untrusted.</p><p>PDP addresses the problem of saving a file to a server where you don’t just trust the server’s claim of having saved it. Instead, you need a mechanism to confirm the file is really on the server.</p><p>There are many types of PDP, including public, private, static, and dynamic. S-PDP is a basic type of public verification PDP.</p><p>Homomorphic encryption is key to implementing S-PDP.</p><h3 id="Example"><a href="#Example" class="headerlink" title="Example"></a>Example</h3><p>I want to give a simple example to illustrate the process of S-PDP. The paper contains a lot of general definitions and is not very detailed, so I am explaining based on my understanding.</p><p>Now the client has an original file with the content:</p><pre><code>F = 12345</code></pre><p>Divide this file into smaller blocks, say into 5 parts:</p><pre><code>F = [1, 2, 3, 4, 5]</code></pre><p>On the client side, generate an array W composed of random numbers, with the array length matching the number of file blocks. The content of W must be unpredictable:</p><pre><code>W = [8, 1, 7, 3, 6]</code></pre><p>Generating homomorphic encryption tags involves 2 steps. First, use additive homomorphic encryption on F and W, then use the client’s public key to perform asymmetric encryption on the homomorphically encrypted array:</p><pre><code>T = r[ h(9),  h(3),  h(10),  h(7),  h(11)]  =  [rh(9), rh(3), rh(10), rh(7), rh(11)]</code></pre><p>The client will send the original file F and the homomorphic encryption tags T to the server for storage, keeping only the locally generated random array W, which is the only private content that cannot be leaked. After sending, the client can delete the local original file F and the homomorphic encryption tags T.</p><p>When the client wants to verify the file on the server, the client generates a challenge, for example, to randomly verify the 1st and 3rd blocks:</p><pre><code>chal = [1, 3]</code></pre><p>Upon receiving the challenge, the server generates the proof in 2 steps. First, use the client’s public key to asymmetrically encrypt the 1st and 3rd blocks of the original file F, then use the homomorphic encryption tags T to perform additive homomorphic encryption:</p><pre><code>V = [rh(9), rh(10)] - r[h(1),  h(3)]  = [rh(9), rh(10)] - [rh(1), rh(3)]  = [rh(8), rh(7)]</code></pre><p>After the client receives the proof V, it uses the private key to perform asymmetric decryption on the proof:</p><pre><code>sW = r&#39;[rh(8), rh(7)]   = [h(8), h(7)]</code></pre><p>The decrypted sW corresponds to the values at the 1st and 3rd indices of the random array W. Due to the use of homomorphic encryption, the content of W is not leaked during the process.</p><p>As long as the user has the initially generated random array W, they can verify that the file exists on the server without the original file. The data occupied by this random array W is very small. Also, because of the use of asymmetric encryption, the server must have both the homomorphic encryption tags T and the original file F to complete the challenge. If the server cheats, the client will not be able to decrypt it, and the server will fail the challenge.</p><h3 id="Limitations"><a href="#Limitations" class="headerlink" title="Limitations"></a>Limitations</h3><p>There is an issue with PDP: since V &#x3D; T - F, if the server pre-saves the entire V, it can pass the challenge even after deleting T and F, and the client would not notice.</p><p>This is a limitation of PDP. PDP can only ensure that the server has saved the file at least once (if it doesn’t save it at all, it cannot generate V), but it cannot guarantee that the file is continuously stored on the server, nor can it repeatedly verify the validity of the proof.</p><p>If the first challenge is [1, 3], and the server passes the challenge and saves the proof for [1, 3], then for any future challenges of [1, 3], the server can directly return the pre-saved proof without needing to compute it again. The client cannot tell whether the proof was generated immediately or earlier. This is a limitation of all PDP proofs.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;What we now refer to as PDP generally refers to the PDP mentioned in the 2007 paper “Provable Data Possession at Untrusted Stores,” with</summary>
        
      
    
    
    
    
    <category term="File Proof" scheme="https://en.smallyu.net/tags/File-Proof/"/>
    
  </entry>
  
  <entry>
    <title>My Cryptocurrency Trading Bot</title>
    <link href="https://en.smallyu.net/2022/12/03/My%20Cryptocurrency%20Trading%20Bot/"/>
    <id>https://en.smallyu.net/2022/12/03/My%20Cryptocurrency%20Trading%20Bot/</id>
    <published>2022-12-03T07:29:27.000Z</published>
    <updated>2025-08-06T10:38:27.719Z</updated>
    
    <content type="html"><![CDATA[<p>Of course, it’s not really a robot, just a simple script. However, it’s worth mentioning that it can indeed bring in profits.</p><p>After running for about 10 days, the profit is around 5%, which I think is already a good result. It’s much more reliable than trading manually since I only end up losing money when I trade manually.</p><p>If the principal is $100, then with a 5% profit rate, you can earn $15 a month, which at least covers the cost of running a server. Breaking even is a reason to be happy.</p><p>Looking at it from another perspective, 5% in 10 days, 15% in a month, 150% in a year… this profit rate is simply phenomenal. And this is just using spot trading; the profits would be much higher if leveraging.</p><p>After recent days of running and debugging, fixing some common errors, the program has become fairly stable.</p><h3 id="Principle"><a href="#Principle" class="headerlink" title="Principle"></a>Principle</h3><p><a href="https://www.bi123.co/">https://www.bi123.co/</a> provides signals for various cryptocurrencies. At the top of the hour, it sends emails indicating whether a particular cryptocurrency is bullish or bearish. After long-term human observation, this signal is quite accurate, at least in terms of the overall trend.</p><p>So the script, upon receiving the email, automatically trades on Binance based on the signal. Binance provides a comprehensive API.</p><p>The script also pushes messages in real-time to a Telegram bot for easy monitoring and tracking of the trading results.</p><h3 id="Profit-Analysis"><a href="#Profit-Analysis" class="headerlink" title="Profit Analysis"></a>Profit Analysis</h3><p>In a price fluctuation cycle, if you can buy at a low point and sell at a high point, each upward segment is profit. It doesn’t matter if the price ultimately goes higher; as long as there is fluctuation, there is profit.</p><p>The bi123 signals are sent at the top of the hour, which might seem untimely and could miss profit opportunities or result in larger losses. However, considering a period of at least one hour helps prevent unnecessary buying and selling due to minor fluctuations.</p><p>Since the prices of various cryptocurrencies do not rise and fall uniformly, the script supports configuring multiple cryptocurrencies, allowing for personal preference selection.</p><h3 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h3><p>It’s not very technical, the code is here: <a href="https://github.com/smallyunet/txbot">smallyunet&#x2F;txbot</a></p><h3 id="2023-01-12"><a href="#2023-01-12" class="headerlink" title="2023.01.12"></a>2023.01.12</h3><p>More than a month has passed, so let’s summarize my actual usage and conclusions.</p><p>Firstly, due to many mistakes, my balance for the past month has been at a loss, around 3%. Initially, I didn’t notice that the signals are graded: 1-hour level, 4-hour level, and 1-day level. Different levels respond to the market at different speeds. The “Signal Trend” type of signal from bi123.co compares closing prices; for instance, if the current price is $1500 and it was $1300 four hours ago, it sends a bullish signal. It’s that simple and direct. Therefore, the strength of signals at different levels varies greatly. Generally, using the 1-hour signal is not recommended, and indeed, I experienced higher loss rates using it. Switching to the 4-hour signal improved results significantly. I recommend using the 4-hour signal.</p><p>Secondly, regarding signal types, bi123.co offers various signals such as “Signal Trend,” “RSI Divergence,” “MD5 Short-term,” and “Long-Short Arrangement.” Previously, I only used the “Signal Trend” type, which can lead to untimely market responses. I recommend using all types of signals together.</p><p>The trading bot script now supports configuration, using different signal strengths and types. The default configuration is what I find to be a good setup.</p><p>Looking at the bot’s performance, it cannot go against the market, meaning it’s hard to profit during a bear market since the bot only supports spot trading without short selling or leverage. This could be added later. The bot also incurs losses during short-term market fluctuations or sideways trends. From this perspective, the bot seems rather limited.</p><p>However, the bot is not completely useless. It can help you follow the market trends, selling in time when prices drop and buying in time when prices rise, preventing situations where you hold during a drop or miss a buy during a rise. All these operations are automated, so you don’t need to worry about your assets. The bot can help you not miss any market opportunities, cutting losses when the market drops and following gains when it rises.</p><p>Another use of the bot is supporting multi-currency configuration, allowing you to catch profit opportunities when a particular currency surges. It’s common for one currency to rise sharply while others don’t move much. Manual operations can easily miss such opportunities, but an automated bot can easily and naturally capture these opportunities.</p><h3 id="2023-01-15"><a href="#2023-01-15" class="headerlink" title="2023.01.15"></a>2023.01.15</h3><p>In just two days, the market surged, and the bot’s performance met expectations. As the market rose, the bot automatically bought in, following the gains in time. Here’s the change in my assets over the past month under the bot’s control (the units of the vertical axis are not important):</p><img src="balance.png" width="100%"><p>After a period of practice, I still recommend using such a bot.</p><h3 id="2023-03-16"><a href="#2023-03-16" class="headerlink" title="2023.03.16"></a>2023.03.16</h3><p>After trying out the bot for a while, I’ve decided to abandon and stop using it. I tracked 56 cryptocurrencies, receiving their signals and trading automatically based on these signals. Here’s the change in my assets over the past month:</p><img src="balance2.png" width="100%"><p>Perhaps the number of tracked currencies was too many, resulting in too small an amount invested in each one. For whatever reason, due to the bot’s unsatisfactory performance and my current disapproval of cryptocurrency trading, I no longer recommend using such a bot.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Of course, it’s not really a robot, just a simple script. However, it’s worth mentioning that it can indeed bring in</summary>
        
      
    
    
    
    
    <category term="Cryptocurrency" scheme="https://en.smallyu.net/tags/Cryptocurrency/"/>
    
  </entry>
  
  <entry>
    <title>Observations on the Blockchain Industry</title>
    <link href="https://en.smallyu.net/2022/11/15/Observations%20on%20the%20Blockchain%20Industry/"/>
    <id>https://en.smallyu.net/2022/11/15/Observations%20on%20the%20Blockchain%20Industry/</id>
    <published>2022-11-15T09:05:50.000Z</published>
    <updated>2025-08-06T10:38:27.721Z</updated>
    
    <content type="html"><![CDATA[<p>Recently, I’ve been feeling a bit lost, so I’m just writing randomly. This might be somewhat disorganized. Previously, I’ve only written about work retrospectives, not about conceptual content. This year has passed quickly with many events, yet no significant changes.</p><p>The past year has been a bear market, especially after May, with the blockchain industry entering a severe winter. Unlike before, where various concepts were emerging continuously, it seems like nothing major has happened, and everyone is still wondering what the next narrative in the cryptocurrency industry will be.</p><h3 id="ETH"><a href="#ETH" class="headerlink" title="ETH"></a>ETH</h3><p>Ethereum is half of the crypto industry. Many projects are built on Ethereum, many tokens are in Ethereum contracts, and many concepts were proposed by Ethereum, such as DAOs. Such a large ecosystem won’t collapse easily. If it does, those projects will go down with it. Bitcoin’s value lies in pioneering the entire industry, but for future blockchain applications and ecosystem expansion, it has to be Ethereum. Ethereum can thrive.</p><p>Another point is the long development cycle of public chains. Back in the day, Ethereum struggled to raise investments. “In 2017, Vitalik came to China to learn Chinese,” and later returned to Western countries to develop for two years before EVM took shape. Now, it has almost become the standard for smart contracts. Various chains are trying to be compatible with EVM because no virtual machine or ecosystem is as complete as EVM. The white paper initially released by Ethereum highlighted smart contracts, while PoS appeared in later versions of the white paper.</p><p>From 2017 to 2019, there was a boom in public chains with innovations in consensus mechanisms or application scenarios. Many chains from that period remain, and investors were willing to invest in underlying chains. Nowadays, few new chains are being launched because competition is minimal, and the return cycle is long. This year’s Aptos and Sui focus on the Move programming language, with no significant innovation in consensus mechanisms. I don’t think Move will become very popular.</p><p>The Ethereum merge, touted as the biggest upgrade in history, actually did nothing. For ordinary users, it felt the same whether it happened or not. After the merge, the price of ETH fell from 1700 to 1400. The expected reduction in issuance, deflation, and price increase did not materialize.</p><p>However, the fact that Ethereum’s price didn’t collapse after the merge indicates that its value doesn’t come from mining. Some believe that mining guarantees the coin’s price because there is a cost involved. Ethereum shows that it can work without mining power and hardware collateral.</p><h3 id="CEX"><a href="#CEX" class="headerlink" title="CEX"></a>CEX</h3><p>The price of cryptocurrencies is closely linked to US stocks, with fluctuations depending on the Federal Reserve’s interest rate hikes and CPI indicators. However, there are times when they are less correlated. If users lose confidence in US stocks, funds may flow into cryptocurrencies, and vice versa.</p><p>The cryptocurrency market is relatively small, seemingly only a few hundred billion dollars compared to the tens of trillions in the US stock market, so its impact is not significant. Some conspiracy theories suggest that cryptocurrencies are a reservoir for US currency to alleviate inflation.</p><p>Recently, FTX collapsed, misappropriating users’ cryptocurrency assets, causing users to lose confidence in cryptocurrencies, especially CEX. This led to another bear market, with Ethereum’s price falling back to around 1300 from 1700. Major exchanges began to disclose their proof of assets.</p><p>Trading on exchanges is truly gambling, and I can’t handle it. I once had a dream of getting rich quickly, holding $100 and leveraging 125x to short Mask, only to get liquidated in seconds. Later, I used $100 to long Sol, but ended up with only half left. I don’t dare to play anymore. The crypto market is full of gamblers, with prices driven by news. Doge coin relies entirely on Musk’s endorsement. FTX held more SHIB than ETH.</p><p>By the way, Liangxi is of low quality, Ma Yilong is uneducated, and KOLs are all clowns. Sun Yuchen actually despises these people, but uses their traffic and hype.</p><h3 id="Finance"><a href="#Finance" class="headerlink" title="Finance"></a>Finance</h3><p>The rise of NFTs was quite sudden, but now the hype has died down. I read an article that said there are two blockchain scenarios: one is migrating from Web 2 to Web 3, which isn’t innovation but chain transformation, and the other is native to Web 3. Initially, it was thought that NFTs could serve as on-chain proof of art, but it didn’t take off. Instead, blue-chip NFTs succeeded by creating original works on-chain and peripherals off-chain. Currently, NFTs still have more investment attributes, relying on brand and rarity.</p><p>Various Fi projects ultimately fall under Finance, such as SocialFi, GameFi, and DeFi. There are currently no reliable scenarios that work. The biggest Web 3.0 and metaverse are still conceptual stages. If it doesn’t work abroad, it definitely won’t work domestically due to a natural resistance to Fi. In this context, you might feel hopeless.</p><p>There are chat rooms and email services based on ENS, but who uses them? There are small games that combine on-chain assets, but neither players nor project teams make money. So what do they do?</p><p>When buying VPNs at some major airports, I found they support TRC-20, which was surprising. It turns out Tron is still alive and being used by merchants. This gave me a reason to download the Trx wallet. It can really be used to buy things, without worrying about domestic payment methods. However, it is still in the Finance scenario.</p><h3 id="DSN"><a href="#DSN" class="headerlink" title="DSN"></a>DSN</h3><p>There are two leaders in the distributed storage network: Filecoin and Arweave.</p><p>Filecoin is typical of off-chain storage or contract-based DSN, using IPFS to store data off-chain, with on-chain proof, settlement, and challenges. Filecoin has strong academic capabilities, first developing IPFS and leading in PoC with many innovations in file proof, surpassing basic PDP and Proof of Retrivailiabily. Their papers on chained file proofs are published in top conferences.</p><p>The advantage of off-chain storage is that files can be large without affecting chain efficiency. However, Filecoin is known for the risk of data loss. If data is lost, it’s really gone. Also, Filecoin’s nodes and SDK are not very user-friendly. It’s said that to calculate power based on disk space, they deliberately control the encoding speed of files, leading to a poor user experience, sometimes taking one or two hours to know if a file was successfully stored. Few projects use Filecoin to build.</p><p>Arweave is typical of on-chain storage or chain-based DSN. Arweave has less innovation compared to Filecoin. Its block structure is similar to Filecoin, recording a calldata in the block and randomly verifying 10% of the previous block’s calldata. Filecoin’s PoC consensus is purer, while Arweave relies on PoW mining, first verifying files and then mining with randomX.</p><p>Arweave uses an economic model where the rarer the file, the higher the mining probability, achieving permanent storage, unlike Filecoin’s temporary storage. Arweave’s collaboration with Meta also increased its price significantly.</p><p>The advantage of on-chain storage is that files are never lost. However, data bloating is a significant issue, making it less suitable for storing large files, but good for NFT data. Ethereum has long had a solution combining IPFS for off-chain NFT storage.</p><p>I understand the distinction between on-chain and off-chain storage or chain-based and contract-based storage simply by checking if generating new blocks relies on the previous block’s file data.</p><p>Some believe that the primary direction for blockchain is still distributed computing, and the path for distributed storage is not very clear. Filecoin is also working on actor nodes supporting EVM execution environments. Years ago, the TV show “Silicon Valley” already envisioned the future of distributed storage.</p><p>Following previous thought patterns, distributed storage aims to either replace Web 2’s cloud server market or innovate in Web 3.</p><h3 id="Layer-2"><a href="#Layer-2" class="headerlink" title="Layer 2"></a>Layer 2</h3><p>Firstly, layer 2 is still within the Finance scope. Ethereum plans to promote layer 2 to enhance the mainnet’s performance and distribute computational pressure.</p><p>Currently, layer 2 lacks a true leader. Each layer 2 project is isolated, unable to interact with one another, posing a significant user experience problem. Users need to choose a layer 2 platform, so only small projects are placed on layer 2. Large contracts on layer 1 are unlikely to move to layer 2.</p><p>Layer 2’s technical infrastructure is incomplete. zk is not yet feasible, op and arb are relatively usable but quite centralized, and interactions with layer 1 are slow. During this year’s Arbitrum Odyssey, the sudden increase in users caused gas fees to reach three times the mainnet, which became a famous issue, and the problem was hard to fix.</p><p>op’s challenge period is relatively long, reportedly one to two weeks, which is unacceptable for ordinary users. The question is, who validates transactions on the mainnet? Users won’t do it themselves, and trusting third parties means placing faith in them.</p><p>State channels and sidechains have greater limitations compared to rollups, being less secure. op seems to have evolved from plasma.</p><p>Ethereum has many blueprints for layer and sharding, but as someone said, “Ethereum is great at everything, just slow at everything.” We’ll have to wait a long time for Ethereum to meet our expectations.</p><h3 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h3><p>DID has been around for years, but no project has truly succeeded. Currently, it is still believed that MetaMask or wallets are the entry point to Web 3. If DID is to take off, it might require a major market shake-up.</p><p>Solana’s price dropped significantly during the FTX incident. Solana’s feature is its PoH consensus, but after several outages, it has lost much of its appeal.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Recently, I’ve been feeling a bit lost, so I’m just writing randomly. This might be somewhat disorganized. Previously, I’ve only written</summary>
        
      
    
    
    
    
    <category term="Blockchain" scheme="https://en.smallyu.net/tags/Blockchain/"/>
    
  </entry>
  
  <entry>
    <title>Randomized Block Confirmation Consensus Mechanism</title>
    <link href="https://en.smallyu.net/2022/09/25/Randomized%20Block%20Confirmation%20Consensus%20Mechanism/"/>
    <id>https://en.smallyu.net/2022/09/25/Randomized%20Block%20Confirmation%20Consensus%20Mechanism/</id>
    <published>2022-09-25T09:43:28.000Z</published>
    <updated>2025-08-06T10:38:27.728Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Steps"><a href="#Steps" class="headerlink" title="Steps"></a>Steps</h3><ol><li><p>Within a time window, a node will receive multiple validated blocks and randomly select one as its next block.</p></li><li><p>In the next time window, if a node does not receive a block and notices that the overall block height of the network is higher than its own, it will discard the previously confirmed block.</p></li><li><p>If block heights are the same, the minority obeys the majority.</p></li></ol><h3 id="Why-Do-This"><a href="#Why-Do-This" class="headerlink" title="Why Do This"></a>Why Do This</h3><ul><li>Receiving Multiple Validated Blocks</li></ul><p>The idea behind Proof of Work is that within a time window, there is only one correct answer, ensuring consistency across the network. Conversely, why can’t there be multiple correct answers within the same time window?</p><ul><li>Randomly Selecting a Block</li></ul><p>Since multiple valid blocks exist simultaneously in the network, a mechanism is needed to select one among them. For fairness, a completely random method is used.</p><ul><li>Discarding the Previous Block</li></ul><p>The block discarding mechanism provides the system with self-correction capability. The DAO attack on Ethereum required developers to lead the community in a hard fork, indicating that the system lacked self-correction capability and required human intervention. It seems all current blockchain systems are like this.</p><ul><li>The Minority Obeys the Majority</li></ul><p>In the absence of transactions, it is possible that all nodes are in a waiting state. In this case, since block heights are the same, no node is willing to discard its own block, causing a network split. This is a game state, so the principle of minority obeys majority is used to break the balance.</p><h3 id="Some-Issues"><a href="#Some-Issues" class="headerlink" title="Some Issues"></a>Some Issues</h3><ul><li>Why Random?</li></ul><p>To avoid the rich getting richer, nodes with computing power becoming wealthier, and nodes with assets getting wealthier, giving every node participating in the network a fair chance to receive block rewards.</p><ul><li>Who Randomizes?</li></ul><p>Each node randomizes and selects a block on its own, rather than using a method like a Verifiable Random Function where each node uses a confirmed result.</p><ul><li>Completely Random or Restricted Random?</li></ul><p>Completely random.</p><p>Completely random means that if a node receives 100 blocks, the probability of selecting a particular block is 1%. Restricted random means, for example, if the previous block was provided by a certain node, the next block will not use its block, and the block reward will not go to it either.</p><p>If it is restricted random, nodes that have already produced blocks and nodes that have not produced blocks will have different weights. No matter which side the weight leans towards, it is not reasonable. If nodes that have produced blocks have more weight, the rich getting richer issue persists. If nodes that have not produced blocks have more weight, participants in the network will create new accounts like crazy, using nodes that have not received block rewards to produce blocks.</p><ul><li>Does Randomness Lead to Forks?</li></ul><p>Definitely, but forks are small-scale. If the network is efficient, only the latest one or two blocks will be uncertain. Once the majority of nodes confirm, it becomes the mainstream chain.</p><ul><li>Will Forks Always Exist?</li></ul><p>No, because forks will be eliminated. New nodes joining the network will definitely choose to sync data with a particular node. For other nodes, random selection means choosing from validated blocks. Validation means that the historical data is the same as theirs. When a forked chain has no transactions, due to the self-correction mechanism, it will keep discarding its blocks until it aligns with the main network.</p><ul><li>What if New Nodes Do Not Sync Data?</li></ul><p>If new nodes do not sync existing data but start anew, they need to attract more than the majority of nodes in the network. For example, if there are 1000 nodes, due to the completely random mechanism, they need an additional 1000 nodes for their chain to become mainstream. This approach can be seen as a way to attack the network, and it seems more difficult than a 51% attack.</p><ul><li>Is There a 51% Attack?</li></ul><p>Due to the block height priority combined with the principle of minority obeys majority, it might be thought that an attacker only needs to control 51% of the highest block height nodes to attack.</p><p>This may be a conceptual misunderstanding. An attack refers to overthrowing existing data, not generating new data. A 51% attack does not exist.</p><ul><li>Does Rollback Cause Uncertainty?</li></ul><p>For users, it is indeed a bad experience. A transaction might be successful one minute, and the next minute, the node discards the block, and the transaction is canceled.</p><p>However, this uncertainty is short-lived. It can be considered that confirming a block requires two or more time windows. Because even if there are small-scale forks in the network, it will eventually trend towards majority consensus.</p><p>Thus, the issue becomes the timing of client confirmation of a transaction.</p><ul><li>Do Unconfirmed Blocks Cause Resource Waste?</li></ul><p>If a node receives 10 blocks and confirms 1, the other blocks are wasted. Repeated correction is also considered resource waste.</p><p>PoW wastes computational resources, while this random block confirmation method wastes network transmission resources. If a node wants its block to be confirmed, it must first let other nodes receive its block. So, if there are 1000 nodes in the network, each round requires broadcasting the block to all 1000 nodes.</p><p>Fortunately, the waste of network transmission resources has an upper limit. Blockchain networks inherently need to broadcast every transaction to the network. Compared to that, only needing to broadcast an additional block’s content is not too much of a burden. Also, since blocks are chosen completely randomly, nodes trying to broadcast their block multiple times through higher network configurations are futile.</p><ul><li>Will Nodes Discard All Blocks if the Network is Abnormal?</li></ul><p>If a node receives very low block heights from the network, according to rule 2, will it gradually discard all blocks?</p><p>No. It is crucial to distinguish between receiving abnormal information from the network and being unable to connect to the network to get information. If a node has 1000 connection records in its routing table but can only connect to 10 due to network conditions, it is an abnormal situation. The node should not discard blocks according to the normal consensus process.</p><ul><li>Are There Any Existing Proposals?</li></ul><p>In the paper <a href="https://arxiv.org/abs/2001.07091">Blockchain Consensus Algorithms: A Survey</a>, pages 16-17, there is a mention of a consensus method for randomly selecting block nodes and coin-age-based selection. This indeed is a random concept, but the paper describes randomness as random node selection, not for blocks, and discusses it in the context of PoS, implying that block nodes are selected and predetermined.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h3 id=&quot;Steps&quot;&gt;&lt;a href=&quot;#Steps&quot; class=&quot;headerlink&quot; title=&quot;Steps&quot;&gt;&lt;/a&gt;Steps&lt;/h3&gt;&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Within a time window, a node will receive</summary>
        
      
    
    
    
    
    <category term="Blockchain" scheme="https://en.smallyu.net/tags/Blockchain/"/>
    
    <category term="Consensus Mechanism" scheme="https://en.smallyu.net/tags/Consensus-Mechanism/"/>
    
  </entry>
  
  <entry>
    <title>VRF + BFT Consensus Causing Transaction Failure Issues</title>
    <link href="https://en.smallyu.net/2022/09/03/VRF%20+%20BFT%20Consensus%20Causing%20Transaction%20Failure%20Issues/"/>
    <id>https://en.smallyu.net/2022/09/03/VRF%20+%20BFT%20Consensus%20Causing%20Transaction%20Failure%20Issues/</id>
    <published>2022-09-02T22:39:51.000Z</published>
    <updated>2025-08-06T10:38:28.717Z</updated>
    
    <content type="html"><![CDATA[<p>Yesterday, I encountered an issue where Ontology’s node stopped producing blocks. The node uses VBFT consensus, the network connectivity was intact without any isolation, thus no forks occurred. The error reported was that the block coming from the proposal had a different expected block hash (MerkleRoot). For various reasons, we didn’t delve deeply into the problem yesterday and instead used a somewhat brute-force method to restore the network to normal. However, the mention of VBFT reminded me of some incidents at my previous company.</p><p>I first got involved with blockchain at my previous company. The project was touted as a self-developed blockchain and also used VBFT (VRF + BFT) consensus, though it wasn’t referred to as such, it was called UBFT or something similar.</p><p>I suspect that the idea of VRF + BFT was proposed by Ontology, and my previous company copied this concept and implemented it. Ironically.</p><p>What I mainly want to talk about is a hidden bug caused by the unreliable implementation of VRF + BFT at my previous company. This incident happened almost two years ago, and I didn’t document it in a blog back then, possibly because I was busy making PPTs? When I encountered the consensus-related issue yesterday, I remembered this incident and now have the time and inclination to write about it. Given the long passage of time, there might be some discrepancies in the details.</p><h3 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h3><p>First, let me introduce the project’s situation. It had several key features.</p><p>One feature was heterogeneous multi-chains, meaning that multiple heterogeneous chains could be included on the same node. Heterogeneous means that a chain can use different consensus mechanisms and run based on different databases. Multi-chain means multiple chains can run on the same node, as one chain was deemed insufficient, akin to a single data table in traditional business. Multiple chains facilitate data partitioning, better supporting business in consortium chain scenarios. Heterogeneous multi-chain can be understood as launching Ethereum chains with different chain IDs using the same binary package. Now, a certain open-source consortium chain still touts the flexible assembly evolved from heterogeneous multi-chain as a major feature, guess why.</p><p>Another feature was support for multiple databases, supporting many relational and non-relational databases simultaneously by writing a middle layer for data operations to adapt to various databases.</p><p>Then there was the consensus mechanism, based on the open-source Tendermint project. Tendermint core implements BFT-like consensus, and the modification made was to replace the round-robin selection of proposal nodes with the VRF function, enabling random selection of proposal nodes. Additionally, hierarchical consensus support was added, meaning the concept of a consensus group that changes every few blocks. The method of changing consensus groups borrowed from the BFT process, ensuring the safety of the group-switching process. The origin of the hierarchical consensus concept is unclear, perhaps it was popular in projects of that era?</p><p>These features were developed before my involvement, so I only had some understanding of them.</p><p>The issue I encountered was that if a failed transaction was sent to the blockchain, the node would immediately return a failed transaction result. If another failed transaction was sent again, the result of the second transaction would not be returned, and the node would stop producing blocks. Subsequently, any failed transactions would exhibit the same phenomenon. However, if a correct transaction was sent, the node would immediately return the result, and everything would return to normal. This phenomenon occurred probabilistically, not every failed transaction would trigger the issue.</p><h3 id="Preconditions"><a href="#Preconditions" class="headerlink" title="Preconditions"></a>Preconditions</h3><p>First, a failed transaction refers to a transaction where the contract returns a failed execution result. Blockchain systems can have two types of transaction failures: one where the transaction cannot be executed, and another where the transaction is executed but the contract returns a failure at the contract layer. The project did not strictly distinguish between these two types of failures, allowing contracts to return transaction-level failures, which is problematic design.</p><p>Invalid transactions would be ignored during the proposal because there was no need to record invalid transactions on the blockchain. Coupled with the project’s erroneous handling of failed transactions, the phenomenon was that contract-execution-failed transactions would be ignored. This is the first precondition.</p><p>The basis of BFT consensus is to vote twice to finalize a block. No matter what BFT, prefixing with any letter, no matter how complex the process to decide which node proposes and how to propose, no matter what optimizations for consensus efficiency like parallel proposals or pipelined consensus, as long as it is BFT consensus, it involves two rounds of voting. The names for these two stages may vary, whether using proposal or prepare to describe it, the process is essentially the same.</p><p>The BFT process involves one node generating a block, sending it to other nodes, and if more than 2&#x2F;3 nodes agree, proceeding to the next round of voting. If more than 2&#x2F;3 nodes agree in the second round of voting, the block is finalized. Understanding BFT consensus hinges on the two rounds of voting. Why two rounds of voting achieve 3f + 1 fault tolerance and why at least two rounds are required is something I don’t know either.</p><p>Ignoring failed transactions happens during transaction verification. There are two checks in the project, pre-consensus check and post-consensus check. Some transactions can’t be checked pre-consensus, such as database write operations in contracts. If the database is written pre-consensus and consensus fails, the data would be chaotic. Thus, checks can only be done post-consensus. This is the second precondition.</p><h3 id="The-First-Failed-Transaction"><a href="#The-First-Failed-Transaction" class="headerlink" title="The First Failed Transaction"></a>The First Failed Transaction</h3><p>Let’s analyze the bug based on the phenomenon. The first failed transaction proceeds normally. A failed transaction enters, it isn’t detected as a failure pre-consensus, so the pre-proposal node proposes a block as usual, distributing it to other nodes for the first round of voting. Then it proceeds to the second round of voting. During the block confirmation phase before writing the block, post-consensus checks are conducted. If a transaction failure is detected and the block contains only this transaction, the block is discarded, and no block is produced. Other nodes also return messages to the proposal node, indicating the block didn’t materialize and the transaction failed. Thus, the first failed transaction returns a normal result.</p><p>For the second failed transaction, the same processing flow should occur, everything should be normal. Even if the transaction fails during the block confirmation phase, the failure result would be broadcasted to other nodes. The protocol uses empty messages to represent voting or block finalization failures. Other nodes wouldn’t be left waiting due to transaction failures. Since the BFT protocol flow isn’t problematic, why does the bug still occur?</p><p>Here, the project’s VRF modifications come into play.</p><p>In the BFT protocol, one node generates a block, distributing it to others to initiate the first round of voting. Which node generates the block? It can’t always be the same node as that would be too centralized. Tendermint does this in round-robin fashion, e.g., A, B, C, D, then back to A.</p><p>The VRF (Verifiable Random Function) alters this selection method. If nodes are selected in order, it’s easy to predict the next node to generate a block, posing risks like node bribery or attacks. VRF, with consistent parameters, yields the same result; with different parameters, the result is random. Using block height and voting round as parameters, each block can be generated by a randomly selected node, avoiding predictability. This modification was a project highlight.</p><p>However, VRF has an issue. Given its randomness, there’s a chance that node A might be selected consecutively, which isn’t negligible. If node A is malicious and generates blocks twice in a row, it could burden the network, though not necessarily breaking it. To mitigate this, the project added a blacklist mechanism on top of VRF.</p><p>If node A generated the last block, it is blacklisted. If the VRF result is in the blacklist, VRF runs again to avoid re-selecting the same node.</p><h3 id="The-Second-Failed-Transaction"><a href="#The-Second-Failed-Transaction" class="headerlink" title="The Second Failed Transaction"></a>The Second Failed Transaction</h3><h4 id="No-Result-Returned"><a href="#No-Result-Returned" class="headerlink" title="No Result Returned"></a>No Result Returned</h4><p>Considering VRF and the blacklist, let’s examine the first failed transaction. Node A receives the transaction, broadcasts it to other nodes, and then packages it into a block for voting. At this point, node A is blacklisted. After the voting failure, node A returns a failure and the transaction is no longer in node A’s transaction pool because it’s already processed.</p><p>What about node B? The block’s transaction verification failed, but the transaction remains in node B’s pool as it hasn’t been processed yet. Should the transaction pool transaction be deleted? Yes, but it wasn’t. This led to node B, chosen to generate the next block, packaging and broadcasting the same transaction, resulting in another proposal failure. Now, both nodes A and B are blacklisted.</p><p>Following this logic, the same transaction blacklists all four nodes in one round. However, the transaction result return isn’t affected because node A already returned the result.</p><p>The second failed transaction arrives, and all nodes are blacklisted. What happens? If all nodes are blacklisted, the blacklist becomes ineffective. The VRF result dictates the node.</p><p>Let’s analyze the second failed transaction. Node A receives the transaction, assuming node B is responsible for generating the block this time. If node B’s block fails verification, it deletes the transaction and returns the failure result. Node B, chosen, generates the block and returns the notification. But the client submitting this transaction is connected to node A!</p><p>Why did the first failed transaction receive a response? Because the blacklist hadn’t failed yet, all nodes processed the transaction and returned the result. Now with the blacklist failed, only node B returns the result, so node A’s client doesn’t receive it.</p><p>Why can’t the failed blacklist work like the first transaction, processing by all nodes?</p><h4 id="Blocking-Subsequent-Transactions"><a href="#Blocking-Subsequent-Transactions" class="headerlink" title="Blocking Subsequent Transactions"></a>Blocking Subsequent Transactions</h4><p>Let’s continue analyzing the second failed transaction. Node C</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Yesterday, I encountered an issue where Ontology’s node stopped producing blocks. The node uses VBFT consensus, the network connectivity</summary>
        
      
    
    
    
    
    <category term="Blockchain" scheme="https://en.smallyu.net/tags/Blockchain/"/>
    
    <category term="BFT" scheme="https://en.smallyu.net/tags/BFT/"/>
    
  </entry>
  
  <entry>
    <title>One Year Work Review</title>
    <link href="https://en.smallyu.net/2022/08/27/One%20Year%20Work%20Review/"/>
    <id>https://en.smallyu.net/2022/08/27/One%20Year%20Work%20Review/</id>
    <published>2022-08-27T03:17:16.000Z</published>
    <updated>2025-08-06T10:38:27.722Z</updated>
    
    <content type="html"><![CDATA[<p>It’s been more than a year since I joined the company, and I want to do a simple phase review. Because I usually record the general work content on the internal Confluence, summarizing it now has some references to follow.</p><p>A lot has happened over the past year. I made a very good friend, which made me less focused at work. Compared to before, both my work efficiency and dedication have significantly decreased. However, overall, there have still been great gains.</p><h3 id="State-channels"><a href="#State-channels" class="headerlink" title="State channels"></a>State channels</h3><p>In the first month of joining the company, I mainly familiarized myself with the project. This project is much larger in scale than the previous company’s project, integrating functionalities equivalent to Filecoin, IPFS, Raiden Network, Ontology, and other public chain projects. It also implemented its own network module and network proxy similar to libp2p. Initially, it was a bit challenging, partly due to the large codebase and partly because I was unfamiliar with public chains. Although I knew the technical modules of blockchain itself, I didn’t know what Layer 2, IPFS, or PoC were. In the first month, I managed to set up and run the project, understood the basic process of uploading and downloading, and mainly looked at the interaction implementation of the p2p network at the protocol level, which was the first time I learned what DHT meant.</p><p>In the second month, besides delving into code details, I made one change: replacing the DFS in the State channels routing with Dijkstra’s algorithm. The project has a Layer 2 similar to Raiden Network, used to solve the issue of frequent payments to other nodes during file downloads. The routing change was relatively independent and wouldn’t cause trouble for the entire project. The optimization with Dijkstra’s algorithm, considering path length, was actually insignificant because our DNS nodes are not that numerous, unlike Raiden Network’s fully P2P mode.</p><p>In the third and fourth months, the main task was adding fees in State channels, deducting part of the transfer amount at the relay nodes. That was a painful process because I didn’t understand Layer 2 or State channels at the time. Fortunately, after two months, I figured out the protocol. Due to project scenario constraints, the transaction couldn’t be directly verified by the initiating node, causing some instability in channel states, but it was harmless.</p><p>After joining the company, I hardly asked colleagues about the project, whether it was the overall architecture or specific code details. I read the code and documentation on my own, especially facing many completely unfamiliar concepts. Doing so was intentional. The inefficiency of doing everything by oneself is natural, but the benefit is that after that process, I had enough confidence to understand and complete such a large-scale project on my own.</p><p>Since it was my first job change, I doubted my abilities, wondering if my feeling about the previous company’s project and technology was an illusion or reality. With a salary increase from job-hopping, I felt somewhat guilty, questioning if I could competently handle such a project in a new company and live up to the salary. Asking colleagues for help is so simple! In the previous company, I also received much care, but I hoped to have the ability to stand alone, and this was a perfect opportunity to solve problems without relying on external help.</p><h3 id="Solidity-contracts"><a href="#Solidity-contracts" class="headerlink" title="Solidity contracts"></a>Solidity contracts</h3><p>In the fifth month, I was conflicted about the direction to optimize Layer 2. It was difficult to start, and I was preparing to solve the performance issue but had no ideas. Later, a requirement came to rewrite the project’s native contracts in Solidity, as there were plans to support EVM. I spent about a week reading Solidity documentation, as I didn’t know Ethereum or Solidity at the time.</p><p>In the sixth month, January this year, I rewrote the contracts in Solidity. That was a pleasant time because it didn’t require much thinking about what to do or how to do it; I just followed the existing implementation. The code output was substantial. Switching programming languages isn’t stressful.</p><p>In the seventh month, February this year, I added support for the Ethereum SDK in the node’s SDK. I fiddled with Ethereum’s testnet, found it not very useful, and ended up using the node’s development mode.</p><p>Although Solidity’s syntax is easy to understand, due to EVM’s limitations, there are many things to pay attention to and many language details that need time to get familiar with. Although it took a month to write the contract, it took a lot of time afterward to modify and improve it. In short, during that process and requirement, I learned to write Solidity contracts and became familiar with Ethereum smart contract development, though still lacking experience with production-level contract security issues.</p><h3 id="Upload-and-download-of-folders"><a href="#Upload-and-download-of-folders" class="headerlink" title="Upload and download of folders"></a>Upload and download of folders</h3><p>Starting in March this year, I worked on uploading and downloading folders. This idea originated from the project’s support for Git, wanting to support the Git protocol and directly use the git command to clone Git repositories. It turned out that ordinary folder uploads and downloads were missing, only supporting file uploads and downloads.</p><p>Our project used part of the IPFS IPLD protocol, converting files into blocks for transmission, but didn’t use IPFS’s file management part. IPFS has a layer of API for file system operations, unifying file and folder processing, and easily converting between data structures. We directly read files and convert them into blocks, complicating folder upload and download implementation.</p><p>This task has been ongoing with various small issues, thanks to the patient cooperation of testing colleagues. Folder processing is slightly more complex than single files due to infinite nesting, containing both files and folders within folders, and handling empty folders and large files.</p><p>IPLD nodes are stored in a Merkle DAG data structure. A single file generates a Merkle Tree, while folder uploads need to organize multiple Merkle Trees into one tree, then deserialize this tree into a folder during download and write the content to the disk.</p><p>The implementation idea is simple: the tree structure has data blocks as raw nodes and proto nodes connecting data blocks as intermediate nodes. Just write the extra folder information into the links of proto nodes to store and transfer the association information between files to other nodes.</p><p>However, the actual implementation took much effort, with some detours. For example, adding extra data during upload caused block data validation failures, preventing the complete tree structure from forming, requiring deep debugging into IPLD code. During download, unfamiliarity with block data parsing and the unordered nature of block data transmission between nodes led to suspected overall logic issues when features failed.</p><p>Due to unordered block data transmission, sorting blocks during download was necessary. Confusing tree level-order traversal with pre-order traversal initially caused misordered blocks, taking a long time to debug and switch to breadth-first traversal.</p><p>This feature, though trivial, deepened my understanding of file upload and download.</p><h3 id="Asymmetric-encryption-of-files"><a href="#Asymmetric-encryption-of-files" class="headerlink" title="Asymmetric encryption of files"></a>Asymmetric encryption of files</h3><p>From April to May, during a severe pandemic period, I worked from home for over a month, focusing on supporting asymmetric encryption of files. Previously, only AES symmetric encryption was supported.</p><p>There’s not much to say about this, just noting that ECDSA is a digital signature algorithm, not for encryption&#x2F;decryption, requiring hybrid modes like ECIES, combining symmetric encryption to achieve asymmetric encryption&#x2F;decryption of files.</p><h3 id="Support-for-Ethereum-accounts"><a href="#Support-for-Ethereum-accounts" class="headerlink" title="Support for Ethereum accounts"></a>Support for Ethereum accounts</h3><p>From June to August, I focused on new Layer 2 solutions, aiming to implement Layer 2 based on Optimistic rollups.</p><p>Rollups haven’t been tackled much yet, currently focused on storage node support for Ethereum accounts. During this period, besides compiling and running the Optimism project and adding options for various network modes to storage nodes, much time was spent perfecting previous Solidity contracts, resolving issues like contract size limits and discrepancies between actual and expected results during node operation.</p><p>Since account addresses and public-private keys have a different format, protocol messages of storage nodes also require a new signature method. These changes are still ongoing.</p><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>Not much has been done, but I haven’t been idle either. Not too diligent, but I’ve gained a lot.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;It’s been more than a year since I joined the company, and I want to do a simple phase review. Because I usually record the general work</summary>
        
      
    
    
    
    
    <category term="Work" scheme="https://en.smallyu.net/tags/Work/"/>
    
  </entry>
  
  <entry>
    <title>Why Pay Attention to Programming Concepts</title>
    <link href="https://en.smallyu.net/2022/07/24/Why%20Pay%20Attention%20to%20Programming%20Concepts/"/>
    <id>https://en.smallyu.net/2022/07/24/Why%20Pay%20Attention%20to%20Programming%20Concepts/</id>
    <published>2022-07-24T14:53:55.000Z</published>
    <updated>2025-08-06T10:38:28.725Z</updated>
    
    <content type="html"><![CDATA[<h3 id="1"><a href="#1" class="headerlink" title="1"></a>1</h3><p>A couple of days ago, I encountered a small problem: a Solidity smart contract exceeding 24 KB couldn’t be deployed on the Ethereum mainnet due to EVM’s code size limitation. So, I considered how to reduce the contract size, but I was quite unclear about the concept of contract size.</p><p>I noticed that a contract can include other contracts and call their methods, just by passing the deployed contract’s address as a parameter to the contract:</p><pre><code class="solidity">contract Demo &#123;&#125;contract Main &#123;    Demo demo;    constructor(Demo _demo) public &#123;        demo = _demo;    &#125;&#125;</code></pre><p>Does the contract size include the imported contracts? When EVM executes the contract, does it load the code of other contracts first and then run them together? Does the code size calculation include all contracts? That would be troublesome.</p><p>Later, I realized that interfaces can be used instead of contracts:</p><pre><code class="solidity">contract IDemo &#123;&#125;contract Demo is IDemo &#123;&#125;contract Main &#123;    IDemo demo;    contract(IDemo _demo) public &#123;        demo = _demo;    &#125;&#125;</code></pre><p>The code for an interface is certainly less than the concrete implementation because the interface doesn’t contain method bodies. Replacing all imported contracts with interfaces would make the contract much smaller, wouldn’t it?</p><p>Of course, the concern here isn’t how to write Solidity contracts or how to calculate contract code size, which I later figured out. What puzzled me was the sudden realization of the difference between using interfaces and using contracts.</p><p>Previously, I defined interfaces for contracts to provide a description of external methods. Here, I realized that interfaces could replace contracts themselves, directly defining variables and using those interface-defined variables to call methods within the contract. But why is that possible? Isn’t it just an interface?</p><h3 id="2"><a href="#2" class="headerlink" title="2"></a>2</h3><p>If you’ve recently learned Java or use Java as your working language, you might find this problem laughably simple. Isn’t this just polymorphism?</p><p>In the first Java class, the teacher tells us that object-oriented programming has three main features: encapsulation, inheritance, and polymorphism. I can still remember this fundamental concept today. Yet, after years of work, I found myself puzzled by such a simple problem in practical work, failing to grasp the meaning of using an interface as a type. This is absurd. Maybe it’s because I haven’t written Java in a long time and have been using Golang instead.</p><p>Java is undeniably the benchmark for object-oriented programming languages. Solidity, though a seemingly new scripting language for smart contracts, combines features from multiple languages but is fundamentally based on object-oriented principles. Contracts are classes, deploying a contract is instantiating an object, a contract address is the object’s memory address, and calling a contract is calling a method on the object…</p><p>Any object-oriented programming language includes object-oriented features and can use object-oriented writing styles, relying on basic features like polymorphism. From an object-oriented perspective, what’s difficult about Solidity? It’s merely a change in form, with programming logic remaining the same, plus some blockchain-specific concepts like transactions and block height.</p><p>From a programming language perspective, Solidity can’t compare to mature languages like Java. Its object-oriented features are incomplete, and constructs like modifier and require, though seemingly convenient, add a lot to the cognitive load and make the code structure less uniform. How can EVM compare to JVM? Yet, as a lightweight scripting language, Solidity uses redundant static typing.</p><p>It’s essential to remember that programming concepts precede programming languages. I still believe that formal programming languages <a href="http://smallyu.net/2022/02/16/%E6%88%91%E4%B8%BA%E4%BB%80%E4%B9%88%E4%B8%8D%E5%AD%A6%E4%B9%A0%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80/">aren’t worth learning</a>, but I don’t deny that learning programming concepts can start from learning programming languages. For example, the concept of <a href="https://en.wikipedia.org/wiki/Polymorphism_(computer_science)">polymorphism</a> involves using a unified symbol to represent different types, including three interpretations: supporting multiple types of parameters (method overloading in Java), supporting multiple types of parameters (generics in Java), and subtypes (using interfaces as types, as in the polymorphism scenario mentioned above).</p><p>Object-oriented programming is a programming concept encompassing many computer science ideas, and Java is a fully object-oriented language. It not only covers many useful features but also implements them thoroughly and elegantly. If you’ve learned Java, you’ll naturally understand object-oriented principles, which are infinitely beneficial. From this perspective, does Golang have anything worth learning compared to Java? Is it the struct syntax or the use of the * symbol? Perhaps Golang is more of a fast-food language, allowing convenient go func(). However, it’s not highly recommended for learning purposes.</p><p>Spending a few minutes browsing the Java documentation, I quickly recall the content since it’s so fundamental. It’s also a reminder to myself not to forget how to code.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h3 id=&quot;1&quot;&gt;&lt;a href=&quot;#1&quot; class=&quot;headerlink&quot; title=&quot;1&quot;&gt;&lt;/a&gt;1&lt;/h3&gt;&lt;p&gt;A couple of days ago, I encountered a small problem: a Solidity smart</summary>
        
      
    
    
    
    
    <category term="Programming Languages" scheme="https://en.smallyu.net/tags/Programming-Languages/"/>
    
  </entry>
  
  <entry>
    <title>Understanding Web 3.0</title>
    <link href="https://en.smallyu.net/2022/06/19/Understanding%20Web%203.0/"/>
    <id>https://en.smallyu.net/2022/06/19/Understanding%20Web%203.0/</id>
    <published>2022-06-19T11:47:30.000Z</published>
    <updated>2025-08-06T10:38:28.713Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Web-3-0-Development"><a href="#Web-3-0-Development" class="headerlink" title="Web 3.0 Development"></a>Web 3.0 Development</h3><p>Web 3.0 is a concept that has existed for several years and has become more popular with the promotion of blockchain technology. When people were still unsure what the 3.0 version of the Web would look like, blockchain emerged. Especially with Ethereum’s dApp providing great possibilities, Web 3.0 became associated with blockchain, decentralization, and self-sovereignty.</p><p>A few days ago, I <a href="https://smallyu.net/micro-blog/#2022-18">mentioned</a> that “Web 3.0 Development” could be described as a career position, encompassing blockchain development and having a broader scope than just “blockchain development.”</p><p>In the Web 2.0 era, Web development referred to traditional front-end and back-end development. The front-end used frameworks like React.js, Vue.js, and Angular.js along with component libraries. The back-end used the Spring ecosystem, along with middleware like Zookeeper, Kafka, and Elasticsearch, and databases such as MySQL and Oracle, forming the common tech stack for Web development.</p><p>The tech stack for Web 3.0 development might evolve to include smart contract development tools and frameworks like Remix, Hardhat, and Ruffle. People will focus on Solidity’s language features, the setup and operation of blockchain nodes, secondary development, and even the development of blockchain nodes themselves. It’s hard to draw direct parallels between Web 2.0 and Web 3.0 tech stacks. For instance, in blockchain development, it’s challenging to describe your job as front-end or back-end development; it’s more accurately described as blockchain development or smart contract development.</p><p>Some positions are now using the term “web3 development,” but it’s important to distinguish between Web 3.0 and web3. Many current positions refer to Ethereum’s web3 framework. We need a new description and a better, more promising career positioning: Web 3.0 development.</p><p>What I want to convey here is to believe that we are on the right path.</p><h3 id="Primary-and-Secondary-Markets"><a href="#Primary-and-Secondary-Markets" class="headerlink" title="Primary and Secondary Markets"></a>Primary and Secondary Markets</h3><p>The primary market for blockchain refers to native chains like Bitcoin and Ethereum. The secondary market includes various projects derived from these chains, especially those based on Ethereum, such as Layer 2 solutions, oracles, NFTs, and ENS.</p><p>Some teams work on primary market projects like Solana, Filecoin, and Neo, which emerged after Ethereum. Dfinity’s IC is an example of an active primary market, and Bitcoin SV is working on “smart contract-enabled Bitcoin.”</p><p>Many startups are focusing on the secondary market. For example, some teams from 360 are working on smart contract security, scanning contracts for vulnerabilities. Others are developing NFT trading protocols, creating APIs similar to NFT exchanges, or designing different outfits for virtual characters in the metaverse. Decentralized email services based on IC also fall into this category. Various Ethereum scaling solutions are also part of the secondary market, with OP recently issuing tokens.</p><p>From a business perspective, there is no higher or lower value between these markets. Technically, it’s hard to say which is simpler or more complex. However, I believe the primary market is more foundational, albeit with slower technological development and fewer variations. The preference depends on personal inclination. Here, I want to emphasize that Web 3.0 development is a broad term, and understanding the differences between these market levels is crucial.</p><h3 id="Decentralization-as-a-Historical-Regression"><a href="#Decentralization-as-a-Historical-Regression" class="headerlink" title="Decentralization as a Historical Regression"></a>Decentralization as a Historical Regression</h3><p>Although Web 3.0 is seen as a promising direction, it also has its limitations.</p><p>This topic came to mind when considering wallet security. One problem is that once a private key is leaked, you lose control over your assets permanently, or someone else permanently gains control.</p><p>We know that an account address can be decoded from a private key. The private key is your asset. When backing up a wallet, you’re backing up the private key. If your private key is leaked, it’s like handing over your money to someone else. Whether they take it immediately or you can reclaim it before they act is another issue.</p><p>This differs from traditional account models. Your user password isn’t your property. Centralized accounts are based on KYC; you can retrieve your assets by proving your identity through ID, fingerprint, or facial recognition. Your account password can be changed, and even if leaked, others can only control your account temporarily.</p><p>Private keys cannot be changed. The only option is to transfer assets to another private key quickly. Decentralization intentionally differentiates between identity and digital identity, increasing digital identity sovereignty but weakening control over it.</p><p>The question arises: Is decentralized asset security? Is holding your money better than storing it in a bank? Considering Bitcoin’s origin, rooted in distrust of centralized institutions, decentralization was born.</p><p>Think about it! Initially, there were no centralized institutions. People bartered, living in a decentralized world. To reduce personal asset protection costs and enhance punitive mechanisms against wrongdoers, centralized institutions were formed to protect the majority’s interests.</p><p>Promoting decentralization now seems like a historical regression. Decentralization isn’t a new concept; it existed and was selectively abandoned by people.</p><p>However, the difference now is that advanced technology might achieve what was previously impossible, pushing the world toward a new vision. But current technology isn’t that advanced yet, with many blockchain technical bottlenecks.</p><p>Therefore, my view is that today’s decentralization concept isn’t an evolution of the centralized world but a supplement to it. Centralized and decentralized systems will coexist in the future.</p><p>It’s important to note that decentralization isn’t synonymous with Web 3.0. Web 3.0 is an evolution of Web 2.0, indicating a new version. Web 3.0 will be an era where centralized and decentralized systems coexist.</p><h3 id="LUNA-Collapse"><a href="#LUNA-Collapse" class="headerlink" title="LUNA Collapse"></a>LUNA Collapse</h3><p>Recently, something amusing happened. One day, LUNA’s price was $80 in the morning and dropped to $1 by the evening. In the next three to four days, LUNA’s price plummeted from $1 to $0.00001, a nearly ten-thousand-fold drop within days. A once top-ten cryptocurrency suddenly became worthless.</p><p>My basic understanding is that UST had a trading pool that tilted slightly when there was a large sell-off. Initially, there was a slight fluctuation, but as social media spread the news, retail investors lost confidence in UST and started selling off massively, driving the price lower. The Terra team had 50,000 Bitcoins as reserves and attempted to stabilize the balance, but Bitcoin’s value was also dropping. The Bitcoins pledged were worth less than expected, failing to stabilize the price. Eventually, the Terra team gave up, allowing the price to fall.</p><p>Shortly after the LUNA incident, some people discussed whether LUNA still had a chance. One possibility was that the Terra team, with $2 billion in reserves, could buy all UST when its market cap dropped below $2 billion, destroy the excess UST, and leave only $2 billion worth of UST, restoring its price to $1. However, the Terra team didn’t plan to do so and later issued a new LUNA.</p><p>LUNA’s failure doesn’t imply the failure of algorithmic stablecoins. Some teams are developing new algorithmic stablecoins, reportedly aiming to simulate the Federal Reserve’s operation model through algorithms, working on whitepapers.</p><p>In the grand era of Web 3.0, LUNA’s incident is just an early joke.</p><h3 id="Web5"><a href="#Web5" class="headerlink" title="Web5"></a>Web5</h3><p>Recently, a new concept, Web5, emerged, implying Web 5.0. The person who proposed it <a href="https://blog.web3labs.com/web5">said</a> they skipped Web4 because Web2 + Web3 &#x3D; Web5. Well, it’s impressive. Who else could propose Web5? Would anyone with some software engineering knowledge dare to say this?</p><p>In short, my conclusion is that Web5 will definitely not succeed. Whether it’s called Web5, Web6, or Web7, its concept still revolves around decentralization and SSI, falling within my understanding of Web 3.0. If you understand the principles of DIDs, you’ll know that the so-called Web5 is purely a gimmick at this stage.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h3 id=&quot;Web-3-0-Development&quot;&gt;&lt;a href=&quot;#Web-3-0-Development&quot; class=&quot;headerlink&quot; title=&quot;Web 3.0 Development&quot;&gt;&lt;/a&gt;Web 3.0</summary>
        
      
    
    
    
    
    <category term="Blockchain" scheme="https://en.smallyu.net/tags/Blockchain/"/>
    
    <category term="Web3" scheme="https://en.smallyu.net/tags/Web3/"/>
    
  </entry>
  
  <entry>
    <title>How to Deal with Misunderstandings</title>
    <link href="https://en.smallyu.net/2022/04/21/How%20to%20Deal%20with%20Misunderstandings/"/>
    <id>https://en.smallyu.net/2022/04/21/How%20to%20Deal%20with%20Misunderstandings/</id>
    <published>2022-04-21T13:31:39.000Z</published>
    <updated>2025-08-06T10:38:27.700Z</updated>
    
    <content type="html"><![CDATA[<p>All misunderstandings stem from interpreting others’ actions through our own mindset.</p><p>Each person is an independent individual, kind, free, and happy.</p><img src="1.png" style="width:80%"><p>Everyone has their own worldview, which has settled after experiencing a turbulent life, serving as a weapon to face a cruel world and complex human nature, perhaps like a magic mirror, rich and magical.</p><p>A worldview gives each person different levels of understanding, translating others’ words into meanings they can comprehend within their minds.</p><img src="2.png" style="width:80%"><p>When you want to express an idea, you convert the idea into words, a process governed by your ability to express. Your magic mirror is red, so the words you say are also red, and these red words are kind.</p><img src="3.png" style="width:80%"><p>Through some medium, your words reach the other party.</p><img src="4.png" style="width:80%"><p>Unfortunately, the other party’s magic mirror is blue. You understand this situation, as it is hard to expect everyone to have the same level of understanding and the same color magic mirror as you. This world is inherently diverse and colorful.</p><p>So, unfortunately, your red words, interpreted by a blue magic mirror, are understood as pink. Red is without malice, but pink carries some other connotations, deviating from your original intent.</p><img src="5.png" style="width:80%"><p>The other party responds to you based on the pink meaning with blue words. The response is already biased because the other party misunderstood your meaning.</p><img src="6.png" style="width:80%"><p>The blue content may be without malice or may carry a bit of malice, but it flies towards you.</p><img src="7.png" style="width:80%"><p>Again, unfortunately, your magic mirror is red. For the blue content from the other party, your magic mirror interprets it as yellow.</p><img src="8.png" style="width:80%"><p>This deepens the misunderstanding. Originally pure red and blue hearts both feel unforgivably hurt. How could the other party do this!</p><img src="9.png" style="width:80%"><p>Over time, the gap between the two people grows larger.</p><img src="10.png" style="width:80%"><p>As a clever magician, you strive to change this situation. Through your diligent practice, you find a way to acquire a blue magic mirror.</p><img src="11.png" style="width:80%"><p>In the future, when the other party communicates with you using a blue magic mirror,</p><img src="12.png" style="width:80%"><p>you can take out your blue magic mirror to interpret the other’s content.</p><img src="13.png" style="width:80%"><p>Through the interpretation of the blue magic mirror, the other party’s kind content can reach your mind unchanged.</p><img src="14.png" style="width:80%"><p>You will not be hurt by this.</p><img src="15.png" style="width:80%"><p>Of course, you have no reason to ask others to have the same red magic mirror as you. This is too difficult, not to mention whether others are willing or not, they may not have enough strength to handle your red magic mirror.</p><p>If you want to communicate with the other party, just take out your blue magic mirror.</p><p>In summary, make yourself stronger.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;All misunderstandings stem from interpreting others’ actions through our own mindset.&lt;/p&gt;
&lt;p&gt;Each person is an independent individual,</summary>
        
      
    
    
    
    
    <category term="Dreams" scheme="https://en.smallyu.net/tags/Dreams/"/>
    
    <category term="Perspective" scheme="https://en.smallyu.net/tags/Perspective/"/>
    
  </entry>
  
  <entry>
    <title>The Curse of Knowledge</title>
    <link href="https://en.smallyu.net/2021/11/24/The%20Curse%20of%20Knowledge/"/>
    <id>https://en.smallyu.net/2021/11/24/The%20Curse%20of%20Knowledge/</id>
    <published>2021-11-24T14:19:55.000Z</published>
    <updated>2025-08-06T10:38:28.702Z</updated>
    
    <content type="html"><![CDATA[<p>At the beginning, everyone is an empty container:</p><img src="1.png" style="width:20%"><p>As experiences grow, new contents are added to the container:</p><img src="2.png" style="width:20%"><p>And new contents continue to increase:</p><img src="3.png" style="width:20%"><p>When two containers meet, they contain different contents:</p><img src="4.png" style="width:40%"><p>The two containers will try to show the same side of the content, create connections, reach consensus on certain issues, and form closer relationships:</p><img src="5.png" style="width:40%"><p>As each continues to grow, the proportion of the same side decreases from 1&#x2F;2 to 1&#x2F;3, weakening their connection:</p><img src="6.png" style="width:40%"><p>When the proportion of the same content becomes 1&#x2F;4, they no longer continue to have a connection:</p><img src="7.png" style="width:40%"><p>At this time, a third container appears:</p><img src="8.png" style="width:60%"><p>The leftmost and middle containers, with a common proportion of 2&#x2F;4 &#x3D; 1&#x2F;2, establish a connection:</p><img src="9.png" style="width:60%"><p>As time continues and content continues to grow, the middle node acquires some unique and special content. This unique content is key to distinguishing one container from another, commonly known as independent thinking ability:</p><img src="10.png" style="width:70%"><p>This special part of the content not only is special itself but also influences the existing content, making the previous content more enriched and characterized by independent thinking:</p><img src="11.png" style="width:70%"><p>Due to the interference of special content on previous content, the proportion of the same previous content has decreased, weakening the relationship between the leftmost container and the middle container:</p><img src="12.png" style="width:70%"><p>Even to the point of having no connection:</p><img src="13.png" style="width:70%"><p>The leftmost container has never obtained such special content:</p><img src="14.png" style="width:70%"><p>Until one day, the rightmost node acquires some special content, only it is triangular:</p><img src="15.png" style="width:70%"><p>The middle container and the right container cannot reach a consensus:</p><img src="16.png" style="width:70%"><p>The content of the middle container does not stop growing. After having special content, the newly added content also becomes colorful:</p><img src="17.png" style="width:70%"><p>The middle container no longer has connections with the left and right nodes and finds it difficult to establish connections again:</p><img src="18.png" style="width:70%"><p>The middle container is left alone, just like in the beginning:</p><img src="19.png" style="width:70%"><p>The content of the middle container continues to grow:</p><img src="20.png" style="width:25%"><p>Together with other containers, each continues to accumulate content independently:</p><img src="21.png" style="width:60%"><p>In various forms and colors:</p><img src="22.png" style="width:40%;">]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;At the beginning, everyone is an empty container:&lt;/p&gt;
&lt;img src=&quot;1.png&quot; style=&quot;width:20%&quot;&gt;

&lt;p&gt;As experiences grow, new contents are</summary>
        
      
    
    
    
    
    <category term="Opinions" scheme="https://en.smallyu.net/tags/Opinions/"/>
    
  </entry>
  
  <entry>
    <title>Is GitBook Good to Use?</title>
    <link href="https://en.smallyu.net/2021/11/21/Is%20GitBook%20Good%20to%20Use_/"/>
    <id>https://en.smallyu.net/2021/11/21/Is%20GitBook%20Good%20to%20Use_/</id>
    <published>2021-11-21T06:21:20.000Z</published>
    <updated>2025-08-06T10:38:27.715Z</updated>
    
    <content type="html"><![CDATA[<p>On October 15, I wrote the following:</p><blockquote><p>Using Cloudflare’s DNS, I changed the subdomain <code>gub</code> from a CNAME pointing to GitBook to point to GitHub. Over 72 hours have passed, and with DNS proxy enabled, it still redirects to GitBook. It appears to be a 302 forward.</p><p>It’s not a caching issue. I’ve opened dev mode and purged everything multiple times. I suspect Cloudflare’s proxy service for forward records updates very slowly or has a bug. The elapsed time has definitely exceeded the TTL.</p></blockquote><p>A month later, the issue was inadvertently resolved. I’d like to elaborate on the problem I encountered.</p><h3 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h3><p>This involves two concepts: DNS (Domain Name System) and CDN (Content Delivery Network). If you’re not familiar with web services, you might want to understand their connection and differences first.</p><h3 id="The-Problem"><a href="#The-Problem" class="headerlink" title="The Problem"></a>The Problem</h3><p>Initially, I planned to write an open-source book and chose GitBook as the platform. GitBook is well-known, and the open-source rendering tool GitbookIO&#x2F;gitbook makes it the best choice for open-source books. After a brief trial, I didn’t notice any issues with the platform. I created a Workspace, then a new repository on GitHub, linked it to GitBook, and everything went smoothly. I tested GitBook and GitHub’s auto-sync capability, and while there could be minor conflicts, they were easy to resolve.</p><p>I bound a custom domain to GitBook. The domain <code>smallyu.net</code> is hosted on Cloudflare, and the subdomain <code>gub.smallyu.net</code> has its DNS records set on Cloudflare. It’s well-known that Cloudflare offers free CDN services, which can be enabled by toggling the orange button in DNS records:</p><p><img src="/1.png" alt="CDN Toggle"></p><p>The toggle was on when pointing to GitBook. A few days later, GitBook underwent a major upgrade, completely changing the writing interface. A day or two after the upgrade, I wanted to update some pages but found the new GitBook workflow counterintuitive and buggy. Each modification was like a Git Pull Request, and clicking the edit button each time created a new PR entry. With multiple PR records, the page state became uncontrollable, with no option to delete PRs, which was frustrating. Additionally, refreshing the edit page multiple times due to slow internet speed resulted in several PR entries, making it hard to identify recent changes. I even complained:</p><blockquote><p>The online editing on GitBook is too difficult to use. You can’t delete commits, create new documents, and the cursor jumps around… How are they being responsible to users?</p></blockquote><p>I decided to abandon GitBook and switched to docsify, deploying the pages on GitHub Pages, and changing the <code>sub.smallyu.net</code> domain to point to GitHub. After updating the DNS records, the change didn’t take effect (Cloudflare’s CDN Proxy was on). Visiting <a href="https://gub.smallyu.net/">https://gub.smallyu.net</a> still redirected to the old GitBook page.</p><p>I initially suspected a DNS TTL issue because in Proxied mode, the TTL value is set to Auto. Given Cloudflare’s numerous CDN nodes and my domain’s low traffic, DNS record updates might be slow. After waiting three long days, the issue persisted, with the domain still redirecting to the old page.</p><p><code>dig</code> results showed:</p><pre><code>gub.smallyu.net.300INA104.21.81.212gub.smallyu.net.300INA172.67.146.253</code></pre><p>No CNAME records were found. This indicated Cloudflare’s CDN IP. The domain resolved to the CDN, but the CDN didn’t return the expected new content.</p><p>Interestingly, disabling the CDN Proxy resolved the issue, with the domain correctly resolving to GitHub’s A and CNAME records, showing the new page.</p><p>What was the problem? Cloudflare’s CDN hadn’t refreshed the content.</p><p>Cloudflare offers Caching configurations and Purge capabilities:</p><p><img src="/2.png" alt="Caching Configuration"></p><p>Despite multiple “Purge Everything” attempts, the CDN content didn’t refresh. Developer mode was also ineffective:</p><p><img src="/3.png" alt="Developer Mode"></p><p>Even setting custom page rules to bypass caching was futile:</p><p><img src="/4.png" alt="Page Rules"></p><p>I even deleted the original Workspace and deactivated the account on GitBook to no avail.</p><p>Ultimately, as long as Proxy was off, domain resolution worked. I thought it might be a CDN bug or GitBook using a 302 forward that the CDN couldn’t refresh correctly.</p><h3 id="The-Cause"><a href="#The-Cause" class="headerlink" title="The Cause"></a>The Cause</h3><p>Recently, while visiting <a href="https://gub.smallyu.net/">https://gub.smallyu.net</a>, the page lagged, reminding me it wasn’t using CDN. Googling the issue led me to useful information. Previously, searches only yielded cache update tips; this time, I found different insights.</p><p>Cloudflare has partners with control over Cloudflare DNS. When the domain was pointed to GitBook, the CDN’s DNS fell under GitBook’s control, overriding Cloudflare settings.</p><p>Relevant links:</p><ul><li><a href="https://community.cloudflare.com/t/dns-subdomain-no-longer-works-nor-redirects-to-anything/240984/7">DNS subdomain no longer works nor redirects to anything</a></li><li><a href="https://community.cloudflare.com/t/subdomain-cname-does-not-update/280696/2">Subdomain CNAME does not update</a></li></ul><p>I emailed GitBook Support:</p><p><img src="/11.png" alt="Email to GitBook Support"></p><p>Surprisingly, GitBook Support resolved the issue within a day:</p><p><img src="/12.png" alt="GitBook Support Response"></p><p>Tests confirmed everything was normal, validating the cause.</p><h3 id="Lesson"><a href="#Lesson" class="headerlink" title="Lesson"></a>Lesson</h3><p>Who would have thought that a widely used service like Cloudflare would delegate domain resolution control on CDN to partners?</p><p>Who would have thought GitBook’s product wouldn’t delete domain records even after the user deleted the Workspace and deactivated the account?</p><p>The lesson here is to shift from a user mindset to a developer mindset. Influenced by the concepts of “official” and “authoritative,” we often doubt our methods and errors first when using platforms, rarely questioning the platform itself. Even if it’s clearly a platform issue, we don’t prioritize contacting platform support. This point can be expanded into many topics for future discussion.</p><h3 id="Tools"><a href="#Tools" class="headerlink" title="Tools"></a>Tools</h3><p>I now use the Rust team’s <code>mdbook</code>. GitBook feels outdated and not well-maintained. docsify, though suitable for project documentation, lacks the stylistic focus on text and inter-page links like a book. While mdbook’s style isn’t trendy, it’s functional, fast, and practical.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;On October 15, I wrote the following:&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;Using Cloudflare’s DNS, I changed the subdomain &lt;code&gt;gub&lt;/code&gt; from a CNAME</summary>
        
      
    
    
    
    
    <category term="Tools" scheme="https://en.smallyu.net/tags/Tools/"/>
    
  </entry>
  
  <entry>
    <title>A Method for Blockchain Node Storage Expansion</title>
    <link href="https://en.smallyu.net/2021/11/10/A%20Method%20for%20Blockchain%20Node%20Storage%20Expansion/"/>
    <id>https://en.smallyu.net/2021/11/10/A%20Method%20for%20Blockchain%20Node%20Storage%20Expansion/</id>
    <published>2021-11-10T14:25:28.000Z</published>
    <updated>2025-08-06T10:38:27.628Z</updated>
    
    <content type="html"><![CDATA[<p>Blockchain is inherently a system that supports horizontal scaling, with exceptional node expansion capabilities.</p><img src="1.png" style="width:50%"><p>However, vertical scaling of blockchain remains a frequently discussed topic. A single node’s hard drive capacity is always limited. If a node holds all the data, the performance requirements for a single machine are quite high; if a node does not have complete data, it cannot be considered one of the P2P network nodes.</p><p>The most straightforward solution is to use a distributed database. Since the database itself supports scaling, the storage module of the blockchain node also supports scaling (assuming there is no conflict between the blockchain and the database in principle).</p><p>Here, we describe a simple conceptual implementation idea.</p><p>Vertical scaling of nodes aims to use multiple nodes working together to replace the position of an original node, with the entire cluster providing the same input and output as a single node.</p><img src="2.png" style="width:80%"><p>Nodes can completely distribute block data across different sub-nodes, such as by using the classic database partitioning idea, modulo operation on block numbers, or random distribution.</p><img src="3.png" style="width:50%"><p>Nodes can be divided into index nodes and storage nodes. Index nodes only record the relationship between block numbers and sub-nodes, with the sub-node cluster acting as the storage module of the index node. The index node is also responsible for sending and receiving blocks and other operations. Apart from the reduced access speed due to network latency, there seem to be no major issues.</p><p>Is it necessary to have more than one type of node? Is there a way to achieve all functions with just one set of source code, one binary program, and one type of node? Of course, this does not mean simply packaging three types of nodes together. Due to the different functional focuses and especially the different “identities” of nodes, nodes might have to be differentiated. Should a single node providing capabilities to the outside and a cluster of nodes providing capabilities to the outside have the same status within the cluster?</p><p>After dispersing block data, “world state” data can be entirely stored on the index nodes.</p><img src="4.png" style="width:50%"><p>If state data also needs to be scaled, the index nodes can similarly retain only index data and distribute the state data across storage nodes.</p><img src="5.png" style="width:50%"><p>Such a solution may be overly simplistic, but what if it works effectively?</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Blockchain is inherently a system that supports horizontal scaling, with exceptional node expansion capabilities.&lt;/p&gt;
&lt;img src=&quot;1.png&quot;</summary>
        
      
    
    
    
    
    <category term="Blockchain" scheme="https://en.smallyu.net/tags/Blockchain/"/>
    
  </entry>
  
  <entry>
    <title>A Consensus Mechanism Based on &quot;Egocentrism&quot;</title>
    <link href="https://en.smallyu.net/2021/10/29/A%20Consensus%20Mechanism%20Based%20on%20%22Egocentrism%22/"/>
    <id>https://en.smallyu.net/2021/10/29/A%20Consensus%20Mechanism%20Based%20on%20%22Egocentrism%22/</id>
    <published>2021-10-29T14:28:52.000Z</published>
    <updated>2025-08-06T10:38:27.589Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>The meaning of “egocentrism” is that for each person, the size of the world depends on how much of the world they can reach. The world is vast and unrelated to me; the world is small and all related to me. The people one knows, the things one understands, and the information one receives are all limited, destined or not. You cannot know everyone in the world or understand everything in the world. So what if you are knowledgeable and experienced?</p><p>In blockchain, the consensus mechanism is a key means to ensure data consistency and also brings the most core decentralized feature to the blockchain. Consensus mechanisms are strongly consistent or achieve majority consistency with certain fault tolerance. Is it possible to have a consensus mechanism that does not prioritize data consistency?</p><p>The world is inherently complex. Attempting to synchronize all nodes to just one data state is counterintuitive. Moreover, whether it’s large-scale unauthorized consensus or small-scale identity-based consensus, the method to achieve data consistency is “multi-point to single-point,” meaning only one node processes data at a time. Other nodes either accept the data that meets the conditions after consensus or vote on whether to agree to the data operation before confirmation. In any case, a “hero” node must do something at the critical moment of data change.</p><p>Some heroes are powerful, acting first and reporting later. After changing the data, they inform you, “I changed the data.” Initially, you are dissatisfied, but you find that the hero indeed solved problems you couldn’t, and you recognize the hero’s actions.</p><p>Other heroes are elected by the public and act cautiously, asking each person, “Do you agree to change this data?” If most agree, the hero acts.</p><p>Of course, everyone has an equal chance to be a hero. Some are naturally powerful; others are clever. Opportunities are always there. If you can’t solve the problem, who can you blame? Everyone can be elected. If no one chooses you, who can you blame?</p><p>So, why can’t we be our own heroes? Why should we submit to others’ halos? Everyone is their own hero, in their world, in a world limited by personal contact range. A consensus mechanism where the node’s boundary is limited by the network scale it touches.</p><h3 id="Network-Overview"><a href="#Network-Overview" class="headerlink" title="Network Overview"></a>Network Overview</h3><p>In an unstructured peer-to-peer network, routing tables are an essential component. The size of the network a node can access depends on how many “contacts” are stored in the routing table. Consensus on data processing is based on the nodes in the routing table. If the routing table has 10 nodes, strive for consensus with these 10 nodes; if it has 10,000 nodes, strive for consensus with 10,000 nodes. No need for a distributed routing table; an ordinary array will do. In this case, the network nodes look like this:</p><img src="21.png" width="40%"><p>Centered on the current node, the number of connected nodes can be many or few, some far and some near. In the issue of route discovery, nodes also need seed addresses. For example, when a node starts, it first resolves the seed address record:</p><pre><code>lookup(&quot;seek.domain&quot;)     -&gt; 127.0.0.1    -&gt; 127.0.0.2</code></pre><p>Then sequentially requests the resolved node addresses to obtain the contents of their routing tables and adds them to its own. This is the usual approach, but it can lead to the node instantly acquiring the entire network’s routing information. This isn’t bad, just feels a bit fast. Meeting a person takes time, talking to people takes time, and you can’t talk to three people simultaneously. Even if you get many contacts, you can’t “multithread” and contact everyone. Our information processing “bandwidth” is limited, and so is the node’s. We can even slightly restrict the speed of network discovery, such as serially processing the action of adding records to the routing table: establish a connection with the node before adding information.</p><p>Slowing down route discovery may sound abnormal. Is it intended to keep the network out of sync? Many consensus bottlenecks are due to network bandwidth and protocol interaction complexity. Lowering the communication cost between nodes will also reduce the consensus’s fault tolerance. The network may be divided into different regions, forming various circles.</p><img src="22.png" width="50%"><p>For consensus algorithms, partitioning is a problem to avoid, but network segmentation is natural and normal. Human thoughts are divided and possibly opposed, but they may agree after some events. Thus, network segmentation is entirely permissible, forming small interconnected or isolated networks. The key is having a mechanism to “correct” such splits, allowing segmented networks to merge under certain conditions.</p><h3 id="Synchronizing-Data"><a href="#Synchronizing-Data" class="headerlink" title="Synchronizing Data"></a>Synchronizing Data</h3><h4 id="Active"><a href="#Active" class="headerlink" title="Active"></a>Active</h4><p>The concept of the blockchain genesis block is retained here, with all nodes having the same first block. A newly joined node starts from the genesis block, while other nodes have higher block heights. For example, the current node’s block height is 2, and it wants to synchronize block height 3 from the network. The node’s routing table has addresses of other nodes, all with block height 3. The current node requests block height 3 sequentially from other nodes.</p><img src="1.png" width="50%"><p>After the request, it finds that 2 nodes have identical blocks for height 3, with the same block content, hash, and previous block hash. The current node adopts this block as its 3rd block.</p><img src="2.png" width="50%"><p>If some nodes have block heights greater than 3, should the highest block height be prioritized? Considering the time dimension, things should follow an order. You can’t skip 3 years and live as a 4-year-old. Blockchain data should also follow a sequence. The current node needs block height 3 and requests block height 3, regardless of other heights. Higher block heights don’t matter if you need height 3.</p><p>If each node’s block differs after all requests, whom should you trust?</p><img src="3.png" width="50%"><p>You have to choose one. If you can’t determine which node or content is trustworthy, choose randomly. Preferably the last requested node, as missed nodes are already missed. The last node is the closest, and you can’t judge if other nodes have identical content until then. After discarding previous nodes, the last node is the choice you can’t let go of.</p><p>For actively requesting block data, the key point is requests must be sequential based on the routing table. Before getting a response from the first node, no request is made to the second. You shouldn’t be too capricious. If a node deliberately speeds up and requests multiple sets of data simultaneously, it doesn’t matter. After all, it’s just synchronizing data. Some like it fast, some slow, some enjoy fast living, and some slow living.</p><h4 id="Passive"><a href="#Passive" class="headerlink" title="Passive"></a>Passive</h4><p>Besides actively requesting block data, nodes also receive broadcast messages from other nodes. For example, the current node’s block height is 2, and it receives blocks 3, 4, and 4 from other nodes.</p><img src="4.png" width="50%"><p>According to the majority principle, should it choose the content of block 4 as its 3rd block? But this has a problem: you can’t predict how many blocks you’ll receive, and you can’t calculate the total amount and proportion of block content. For passively received blocks, take the content of the first received block as the standard.</p><p>The order of arrival in life is important. If the required block height is 3 and the received broadcast block height is also 3, then take it. If not, replace it with a more suitable one later. If a node aggressively broadcasts the same block marked from 1 to high heights, hoping a node needing the block will receive it, let it be. Nodes actively synchronizing blocks request content by height, so this aggressive approach doesn’t yield much benefit.</p><h3 id="Adding-Data"><a href="#Adding-Data" class="headerlink" title="Adding Data"></a>Adding Data</h3><p>Who generates data in the network? To solve this, we can define that every node can generate data. An extreme case is where everyone trusts only their data, playing solo, making the network a single-player version. So nodes need to spread their generated data, sending it to other nodes. For other nodes, it’s “passive data synchronization.”</p><h4 id="A-Node-Needs-It"><a href="#A-Node-Needs-It" class="headerlink" title="A Node Needs It"></a>A Node Needs It</h4><p>Active block data broadcasting has two cases: a node needs the block, and you happen to send it.</p><img src="5.png" width="50%"><p>The current node receives a content request, adds block height 4, and directly persists the block to the main chain. It then starts broadcasting block height 4, sequentially through the routing table. The current node won’t pack the next block until the broadcast ends. If a node’s block height is 3, you are the first to send it block height 4, and it will accept your block and respond. After receiving the response, you know at least one node accepted your block, and you can continue with the next block. Of course, the node won’t stop broadcasting this round even if it gets a response. This is logical, hoping more nodes accept the block content.</p><p>If the receiving node finds the block content is 5 and the previous block hash is 3, not matching its previous block hash 4, it still accepts the block, replacing its blocks until the hash matches.</p><img src="51.png" width="50%"><img src="52.png" width="50%"><p>This mechanism risks replacing the entire chain upon receiving a block, a serious unacceptable cost. But such risk exists. You met a bad person who undermined your values, leading you astray. Reflect on why your routing table has such</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h3 id=&quot;Introduction&quot;&gt;&lt;a href=&quot;#Introduction&quot; class=&quot;headerlink&quot; title=&quot;Introduction&quot;&gt;&lt;/a&gt;Introduction&lt;/h3&gt;&lt;p&gt;The meaning of “egocentrism”</summary>
        
      
    
    
    
    
    <category term="Blockchain" scheme="https://en.smallyu.net/tags/Blockchain/"/>
    
    <category term="Consensus Mechanism" scheme="https://en.smallyu.net/tags/Consensus-Mechanism/"/>
    
  </entry>
  
  <entry>
    <title>Common Linked List Algorithm Problems and Explanations</title>
    <link href="https://en.smallyu.net/2021/10/27/Common%20Linked%20List%20Algorithm%20Problems%20and%20Explanations/"/>
    <id>https://en.smallyu.net/2021/10/27/Common%20Linked%20List%20Algorithm%20Problems%20and%20Explanations/</id>
    <published>2021-10-27T03:04:20.000Z</published>
    <updated>2025-08-12T15:22:29.912Z</updated>
    
    <content type="html"><![CDATA[<p>Contents:</p><ul><li><a href="#Reverse-a-Linked-List">Reverse a Linked List</a></li><li><a href="#Detect-if-a-Linked-List-Has-a-Cycle">Detect if a Linked List Has a Cycle</a></li><li><a href="#If-the-List-Has-a-Cycle-Find-the-Cycle-Entry">If the List Has a Cycle, Find the Cycle Entry</a></li><li><a href="#Determine-Whether-Two-Linked-Lists-Intersect">Determine Whether Two Linked Lists Intersect</a></li><li><a href="#If-Two-Lists-Intersect-Find-the-First-Intersection-Node">If Two Lists Intersect, Find the First Intersection Node</a></li><li><a href="#Merge-Two-Sorted-Linked-Lists">Merge Two Sorted Linked Lists</a></li></ul><br><h2 id="Reverse-a-Linked-List"><a href="#Reverse-a-Linked-List" class="headerlink" title="Reverse a Linked List"></a>Reverse a Linked List</h2><h3 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h3><p>For a linked list like this:</p><img src="4.png" width="50%"><p>We want it to become this after processing:</p><img src="5.png" width="50%"><h3 id="Linked-List-Structure-Definition"><a href="#Linked-List-Structure-Definition" class="headerlink" title="Linked List Structure Definition"></a>Linked List Structure Definition</h3><p>Node definition:</p><pre><code>type Node struct &#123;    Value int    Next  *Node&#125;</code></pre><p>Method to construct a linked list:</p><pre><code>func createLinkedList(n int) *Node &#123;    head := &amp;Node&#123;Value: 0&#125;    node := head    for i := 0; i &lt; n; i++ &#123;        if i &lt; n &#123;            node.Next = &amp;Node&#123;Value: i + 1&#125;        &#125;        node = node.Next    &#125;    return head&#125;</code></pre><p>The function returns a pointer to the head of a linked list. We use a pointer instead of the struct type because, due to some of Go’s variable semantics, you can’t determine whether a variable is empty using <code>Node&#123;&#125; == nil</code>. Theoretically, <code>Node&#123;&#125;</code> is not <code>nil</code>. This means if you use <code>Node&#123;&#125;</code> as the head node’s type, you won’t have a reasonable stopping condition during traversal—you’d have to use something like <code>Node&#123;&#125;.Next == nil</code>, which would also miss the last node.</p><h3 id="Iterative-Reversal"><a href="#Iterative-Reversal" class="headerlink" title="Iterative Reversal"></a>Iterative Reversal</h3><p>We shouldn’t reverse by directly changing node values, e.g., by storing values in an array during one pass and then writing them back in reverse during a second pass. That defeats the purpose of the data structure. You can use iteration or recursion to reverse the list.</p><img src="6.png" width="50%"><p>Take the first node as an example: use a <code>temp</code> variable to store the location of the next node before reversal, then set <code>head.Next</code> to point to the node it should point to after reversal. The next of the first node should be the <code>nil node</code>, and the next of the second node should be <code>node 1</code>. After setting <code>head.Next</code>, move <code>head</code> to <code>temp</code> (the original next) to continue traversal. You also need a <code>curr</code> variable to store the position of <code>head</code> before it jumps, so that on the next step <code>head.Next</code> can point back to the previous node. This is a straightforward process.</p><pre><code>func reverseLinkedList(head *Node) *Node &#123;    curr := new(Node)    for head != nil &#123;        temp := head.Next        head.Next = curr        curr = head        head = temp    &#125;    return curr&#125;</code></pre><ul><li>Time complexity: O(n)</li><li>Space complexity: O(1)</li></ul><h3 id="Execution"><a href="#Execution" class="headerlink" title="Execution"></a>Execution</h3><p>After running, the result matches expectations:</p><pre><code>func main() &#123;    head := createLinkedList(4)    head = reverseLinkedList(head)    for head != nil &#123;        fmt.Println(head.Value)        head = head.Next    &#125;&#125;</code></pre><p><br><br></p><h2 id="Detect-if-a-Linked-List-Has-a-Cycle"><a href="#Detect-if-a-Linked-List-Has-a-Cycle" class="headerlink" title="Detect if a Linked List Has a Cycle"></a>Detect if a Linked List Has a Cycle</h2><h3 id="Problem-1"><a href="#Problem-1" class="headerlink" title="Problem"></a>Problem</h3><p>A cycle in a linked list means the “last” node points to one of the previous nodes.</p><img src="9.png" width="50%"><p>When traversing such a list, the program will loop forever. How can we detect whether a list has a cycle?</p><h3 id="Analysis"><a href="#Analysis" class="headerlink" title="Analysis"></a>Analysis</h3><p>A common approach is the two-pointer technique. Imagine a track: two people A and B start at the same point, but run at different speeds, with A’s speed v<sub>1</sub>&#x3D;1 and B’s speed v<sub>2</sub>&#x3D;2 (B is faster). As long as they keep running, B will eventually lap A and catch up again—this is intuitive.</p><img src="7.png" width="50%"><p>On a circular track, a fast and a slow runner will always meet again, and the distances they cover follow this relation:</p><pre><code>s2 - s1 = nR</code></pre><p>R is the circumference of the circle, and n is a positive integer. At the starting line, n&#x3D;0; at the first meeting, B has run one full lap more than A, so n&#x3D;1.</p><p>Compared to a linked list, this track scenario is missing an initial straight section before entering the loop. Before entering the circular part, A and B run along a straight path of length d. Their speeds remain unchanged throughout, but when they enter the circle, they are no longer at the same “relative” starting point.</p><img src="8.png" width="50%"><p>In this case, can s<sub>1</sub> and s<sub>2</sub> still satisfy a formula? Let the straight distance before the circle be d. Inside the circle, the paths still differ by n times the circumference R, only the expression becomes:</p><pre><code>(s2 - d) - (s1 - d) = nR    s2 - d - s1 + d = nR            s2 - s1 = nR</code></pre><p>After canceling out d, the result is the same as before.</p><p>Since A’s distance s<sub>1</sub>&#x3D;v<sub>1</sub>t and B’s s<sub>2</sub>&#x3D;v<sub>2</sub>t, with the same time t and known speeds v<sub>1</sub>&#x3D;1 and v<sub>2</sub>&#x3D;2, we have:</p><pre><code>    s2 - s1 = nR  v2t - v1t = nR     2t - t = nR          t = nR</code></pre><p>Taking n &#x3D; 1 gives <code>t = R</code>.</p><h3 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h3><p>Back to linked lists: to detect a cycle, we only need fast and slow pointers; we don’t need to know exactly where they meet, though the distance relation helps validate correctness.</p><p>For this list, let pointers A and B start from node 1 at speeds 1 and 2:</p><img src="9.png" width="50%"><p>Their positions over time:</p><table><thead><tr><th>Time t</th><th>0</th><th>1</th><th>2</th><th>3</th><th>4</th></tr></thead><tbody><tr><td>A’s pos</td><td>Node 1</td><td>Node 2</td><td>Node 3</td><td>Node 4</td><td><strong>Node 5</strong></td></tr><tr><td>B’s pos</td><td>Node 1</td><td>Node 3</td><td>Node 5</td><td>Node 3</td><td><strong>Node 5</strong></td></tr></tbody></table><p>At t&#x3D;4 they meet; the cycle length is exactly 4, matching <code>t = R</code>.</p><p><br><br></p><h2 id="If-the-List-Has-a-Cycle-Find-the-Cycle-Entry"><a href="#If-the-List-Has-a-Cycle-Find-the-Cycle-Entry" class="headerlink" title="If the List Has a Cycle, Find the Cycle Entry"></a>If the List Has a Cycle, Find the Cycle Entry</h2><h3 id="Problem-2"><a href="#Problem-2" class="headerlink" title="Problem"></a>Problem</h3><p>This extends the previous problem. Given a list that has a cycle, find the entry point of the cycle. In this example, the entry is node 3.</p><img src="20.png" width="50%"><h3 id="Analysis-1"><a href="#Analysis-1" class="headerlink" title="Analysis"></a>Analysis</h3><p>(1)</p><p>From the cycle detection problem, we obtained a crucial conclusion:</p><pre><code>t = R</code></pre><p>The fast and slow pointers meet at a time equal to the cycle length. For the list above, their positions are:</p><table><thead><tr><th>Time t</th><th>0</th><th>1</th><th>2</th><th>3</th><th>4</th><th>5</th><th>6</th></tr></thead><tbody><tr><td>A’s pos</td><td>Node 1</td><td>Node 2</td><td>Node 3</td><td>Node 4</td><td>Node 5</td><td>Node 6</td><td><strong>Node 7</strong></td></tr><tr><td>B’s pos</td><td>Node 1</td><td>Node 3</td><td>Node 5</td><td>Node 7</td><td>Node 3</td><td>Node 5</td><td><strong>Node 7</strong></td></tr></tbody></table><p>The cycle length is 6, and the pointers meet at t&#x3D;6 at node 7:</p><img src="21.png" width="50%"><p>(2)</p><p>By the earlier conclusion, at speed v<sub>1</sub>&#x3D;1 for the slow pointer, the distance traveled equals the time. From the start to the meeting point, the path length at time <code>t = R</code> is exactly the cycle length R:</p><img src="22.png" width="50%"><p>(3)</p><p>Suppose the slow pointer keeps that length R as a “window” and moves it forward by one step:</p><img src="23.png" width="50%"><p>Move one more step:</p><img src="24.png" width="50%"><p>(4)</p><p>Now let’s define variables: let the distance from <code>Start</code> to the <code>Cycle Entry</code> be l<sub>1</sub>, the total list length be l, and the cycle length remain R.</p><img src="25.png" width="50%"><p>These satisfy:</p><pre><code>l - l1 = R</code></pre><p>This is obvious.</p><p>(5)</p><p>Recall our initial conclusion: the distance from <code>Start</code> to the <code>Meeting Point</code> equals the cycle length R:</p><img src="22.png" width="50%"><p>Keeping l and l<sub>1</sub> unchanged, the figure becomes:</p><img src="26.png" width="50%"><p>Now l still equals <code>l1 + R</code>, but <code>l1</code> and <code>R</code> overlap.</p><p>(6)</p><pre><code>l - l1 = R</code></pre><p>Does the equality still hold after overlap? Of course, since the whole list is unchanged and variable magnitudes remain the same—though it may feel a bit counterintuitive.</p><p>Define a new variable l<sub>2</sub> as the distance from the <code>Meeting Point</code> to the <code>Cycle Entry</code>:</p><img src="27.png" width="50%"><p>Then:</p><pre><code>l - l2 = R</code></pre><p>(7)</p><p>From these comparisons, we find <code>l1 == l2</code>, i.e., the distance from <code>Start</code> to the <code>Cycle Entry</code> equals the distance from the <code>Meeting Point</code> to the <code>Cycle Entry</code>.</p><h3 id="Solution-1"><a href="#Solution-1" class="headerlink" title="Solution"></a>Solution</h3><pre><code>Start -&gt; Cycle Entry == Meeting Point -&gt; Cycle Entry</code></pre><p>This is important because the fast and slow pointers are at the <code>Meeting Point</code> (node 7).</p><p>If we introduce another pointer p<sub>3</sub> starting from the overall list <code>Start</code> (node 1) at the exact moment the slow and fast pointers meet (moving at speed 1), then p<sub>3</sub> and the slow pointer will meet at the cycle entry, because the distance from p<sub>3</sub> to the <code>Cycle Entry</code> equals that from the slow pointer to the <code>Cycle Entry</code>. The meeting point is the cycle entry.</p><img src="28.png" width="50%"><p><br><br></p><h2 id="Determine-Whether-Two-Linked-Lists-Intersect"><a href="#Determine-Whether-Two-Linked-Lists-Intersect" class="headerlink" title="Determine Whether Two Linked Lists Intersect"></a>Determine Whether Two Linked Lists Intersect</h2><h3 id="Problem-3"><a href="#Problem-3" class="headerlink" title="Problem"></a>Problem</h3><p>There are two linked lists that at some node point to the same next node:</p><img src="10.png" width="50%"><p>We have:</p><pre><code>1 -&gt; 2 -&gt; 3 -&gt; 4     5 -&gt; 3 -&gt; 4</code></pre><p>How do we determine if the two lists intersect?</p><h3 id="Analysis-2"><a href="#Analysis-2" class="headerlink" title="Analysis"></a>Analysis</h3><p>A simple approach is to traverse each list to its last node and check whether the last nodes are the same. If two lists intersect at some middle node, their last node must be the same.</p><p><br><br></p><h2 id="If-Two-Lists-Intersect-Find-the-First-Intersection-Node"><a href="#If-Two-Lists-Intersect-Find-the-First-Intersection-Node" class="headerlink" title="If Two Lists Intersect, Find the First Intersection Node"></a>If Two Lists Intersect, Find the First Intersection Node</h2><h3 id="Problem-4"><a href="#Problem-4" class="headerlink" title="Problem"></a>Problem</h3><p>For the two lists:</p><img src="31.png" width="50%"><img src="32.png" width="50%"><p>How do we find the first intersection node 3?</p><h3 id="Analysis-3"><a href="#Analysis-3" class="headerlink" title="Analysis"></a>Analysis</h3><p>One simple idea is to connect the tail of one list to the head of the other:</p><img src="33.png" width="50%"><p>It can be the tail of list 1 to the head of list 2, or the tail of list 2 to the head of list 1. After connecting, the problem reduces to finding the entry point of a cycle.</p><p><br><br></p><h2 id="Merge-Two-Sorted-Linked-Lists"><a href="#Merge-Two-Sorted-Linked-Lists" class="headerlink" title="Merge Two Sorted Linked Lists"></a>Merge Two Sorted Linked Lists</h2><h3 id="Problem-5"><a href="#Problem-5" class="headerlink" title="Problem"></a>Problem</h3><img src="11.png" width="50%"><p>Given two sorted linked lists, merge them into one sorted list.</p><h3 id="Analysis-4"><a href="#Analysis-4" class="headerlink" title="Analysis"></a>Analysis</h3><p>The idea is straightforward: iterate both lists simultaneously and merge in order. Mind the edge cases.</p><img src="12.png" width="50%"><img src="13.png" width="50%"><h3 id="Code"><a href="#Code" class="headerlink" title="Code"></a>Code</h3><p><code>Node</code> structure:</p><pre><code>type Node struct &#123;    Value int    Next  *Node&#125;</code></pre><p>Build two lists:</p><pre><code>func main() &#123;    root1 := &amp;Node&#123;        Value: 1,    &#125;    root1.Next = &amp;Node&#123;        Value: 1,    &#125;    root1.Next.Next = &amp;Node&#123;        Value: 3,    &#125;    root1.Next.Next.Next = &amp;Node&#123;        Value: 5,    &#125;    root2 := &amp;Node&#123;        Value: 1,    &#125;    root2.Next = &amp;Node&#123;        Value: 2,    &#125;    root2.Next.Next = &amp;Node&#123;        Value: 4,    &#125;    root := merge(root1, root2)    for root != nil &#123;        fmt.Println(root.Value)        root = root.Next    &#125;&#125;</code></pre><p>Merge function:</p><pre><code>func merge(root1 *Node, root2 *Node) *Node &#123;    var root *Node    var temp *Node    if root1.Value &lt;= root2.Value &#123;        root = root1        temp = root2    &#125; else &#123;        root = root2        temp = root1    &#125;    p1 := root    p2 := p1.Next    for &#123;        if p2 == nil || temp == nil &#123;            break        &#125;        if p2.Value &lt;= temp.Value &#123;            p1.Next = p2            p1 = p1.Next            p2 = p2.Next        &#125; else &#123;            p1.Next = temp            p1 = p1.Next            temp = temp.Next        &#125;    &#125;    return root&#125;</code></pre>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Contents:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;#Reverse-a-Linked-List&quot;&gt;Reverse a Linked List&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a</summary>
        
      
    
    
    
    
    <category term="Linked List" scheme="https://en.smallyu.net/tags/Linked-List/"/>
    
  </entry>
  
  <entry>
    <title>A Multi-Linked-List-Based Blockchain Idea</title>
    <link href="https://en.smallyu.net/2021/10/17/A%20Multi-Linked-List-Based%20Blockchain%20Idea/"/>
    <id>https://en.smallyu.net/2021/10/17/A%20Multi-Linked-List-Based%20Blockchain%20Idea/</id>
    <published>2021-10-17T03:27:17.000Z</published>
    <updated>2025-08-12T15:22:29.905Z</updated>
    
    <content type="html"><![CDATA[<p>Is it possible for a blockchain to move beyond a purely linear structure into a graph-like data structure with multiple links—say, evolving from a singly linked list to a multi‑linked list? If we assume a multi‑linked list form, what changes would it bring to a blockchain—or is it even feasible?</p><p>First, a forward (outward‑branching) multi‑linked list, like this:</p><img src="1.png" width="50%"><p>Then, a backward (converging) multi‑linked list suited for blockchains, like this:</p><img src="2.png" width="50%"><p>For a multi‑linked list, one variant fixes the number of successors (e.g., exactly 2 child nodes per node). Another allows a variable number of successors—each node can point to any number of children. The difference between the two is minor.</p><p>Another fork in the road is whether to retain the concept of block height. Block height indexes block order and plays an important role in synchronizing data across nodes. In a multi‑linked list, if we define block height by tree depth, it would look like this:</p><img src="3.png" width="50%"><p>Alternatively, we can define it by the order in which blocks are written—that is, the initial label implies block height:</p><img src="2.png" width="50%"><p>For blockchains, verifying data integrity is critical. When there’s only one child per node, other nodes can easily sync a block’s data and validate it via hash values. In a multi‑linked‑list scenario, validating a block becomes more complex—but not unmanageable. You simply repeat the original “validate one block” operation multiple times in a loop to verify more links.</p><p>The key difference between forward and backward multi‑linked lists is this: one diverges outward, so each higher level contains more nodes—growing exponentially. The other converges, so the number of nodes per level decreases until only one remains. In other words, a right‑side‑up tree versus an upside‑down tree.</p><img src="6.png" width="50%"><p>Blockchains have a genesis block. In a forward multi‑linked list, the genesis block remains singular, but as children expand, things become increasingly hard to control. If we keep block height, there’s no fundamental reason it couldn’t work—beyond some extra steps in the program. If we drop block height or replace it with an index, blocks can still be produced one by one; there’s no technical impossibility, though the handling remains essentially chain‑like. Simply switching the data structure from a linked list to a multi‑linked list doesn’t seem to offer clear benefits, because it’s hard to imagine what advantages it would bring.</p><img src="7.png" width="50%"><p>With a backward multi‑linked list, there’s a big question: what about the genesis block? In an upside‑down tree, the number of children shrinks and finally becomes one. Would the genesis block then have to specify a large initial number of nodes that gradually converges to one? That’s unreasonable—equivalent to hard‑coding a halting condition: once a certain block height is reached, you can no longer append content. Clearly undesirable.</p><p>Because tree structures either diverge or converge, the multi‑linked‑list idea runs into problems. So how about this: use <strong>parallel</strong> multi‑linked lists—would that work?</p><img src="4.png" width="50%"><p>Since you’d need multiple inputs and outputs—and the counts must match—this uses repeated pointers to achieve that.</p><p>Again, it’s technically feasible. The question is: what’s the benefit? What does this data structure actually bring—beyond extra program complexity?</p><p>Well, there is one thing: this structure allows producing two blocks at the same time. As long as two nodes use the same parent, even if they’re simultaneous with no ordering, both can be appended as children.</p><p>But then more problems arise. How do we prevent double‑spending? If the same account’s transactions appear in both blocks, which one wins? In distributed systems, synchronization is ultimately a process of many points becoming one. Even parallel programs face resource contention. After producing two blocks simultaneously, you still need some single‑point mechanism to process the data; producing simultaneous blocks becomes meaningless and doesn’t speed up the system’s overall throughput.</p><p>Moreover, a “parallel” multi‑linked list can essentially be viewed like this:</p><img src="5.png" width="50%"><p>Seen this way, parallel multi‑linked lists make even less sense.</p><p>All in all, is it possible for a blockchain to be based on a multi‑linked‑list data structure? It seems unnecessary. A singly linked list is simple, yet it truly fits a blockchain’s needs.</p><p><br><br></p><h3 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h3><h4 id="Singly-Linked-List"><a href="#Singly-Linked-List" class="headerlink" title="Singly Linked List"></a>Singly Linked List</h4><img src="10.png" width="50%"><p>A singly linked list is a linear data structure. Each node contains a field that points to the next node, explicitly representing relationships between nodes. In programs, this field is usually filled with the referenced object’s address. (You could also use the node’s value directly, but separating by type is clearer.)</p><pre><code>type Node struct &#123;    Value int    Next  *Node&#125;func main() &#123;    node1 := Node&#123;Value: 1&#125;    fmt.Printf(&quot;%p\n&quot;, &amp;node1) // 0x14000104210    node2 := Node&#123;Value: 2&#125;    fmt.Printf(&quot;%p\n&quot;, &amp;node2) // 0x14000104220    node1.Next = &amp;node2    fmt.Println(node1) // &#123;1 0x14000104220&#125;    fmt.Println(node2) // &#123;2 &lt;nil&gt;&#125;&#125;</code></pre><p><code>node1</code>’s memory address is <code>0x14000104210</code>, and <code>node2</code>’s is <code>0x14000104220</code>. Assign <code>node2</code>’s address to <code>node1</code>’s <code>next</code> field. At that point, accessing <code>node1</code> lets you reach <code>node2</code> via <code>next</code>. By extension, even with many nodes, knowing only the starting node <code>node1</code> lets you traverse all nodes in the linked list.</p><h4 id="Doubly-Linked-List"><a href="#Doubly-Linked-List" class="headerlink" title="Doubly Linked List"></a>Doubly Linked List</h4><img src="11.png" width="50%"><p>A doubly linked list adds one more field on top of a singly linked list to store a pointer to the previous node. With this structure, when you access any node, you can learn both the next and the previous node.</p><pre><code>type Node struct &#123;    Value int    Next  *Node    Prev  *Node&#125;</code></pre><h4 id="Doubly-Linked-List-−-Singly-Linked-List"><a href="#Doubly-Linked-List-−-Singly-Linked-List" class="headerlink" title="(Doubly Linked List) − (Singly Linked List)"></a>(Doubly Linked List) − (Singly Linked List)</h4><p>A singly linked list retains information about the next node; a doubly linked list keeps both previous and next. Is there a data structure that keeps <strong>only</strong> the previous node? For example:</p><pre><code>type Node struct &#123;    Value int    Prev  *Node&#125;</code></pre><p>Why build a linked list that retains only the previous node? Because there’s a scenario where, when creating the current node, the next node’s content and reference address are not yet determined—or don’t exist.</p><p>Once the next node is determined, should we modify the previous node? It’s easy to change in a demo, but what about in a massive database? Update costs are high. And in a distributed system? Network I&#x2F;O and consistency add even more cost.</p><img src="12.png" width="50%"><p>This structure might not be bad: it preserves the essence of a linked list while allowing the list to grow without altering prior nodes’ data. The traversal order, however, is the reverse of a singly linked list—you must traverse from the last node backward to visit all nodes, as if the singly linked list were flipped. But a flipped singly linked list is still a singly linked list.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Is it possible for a blockchain to move beyond a purely linear structure into a graph-like data structure with multiple links—say,</summary>
        
      
    
    
    
    
    <category term="Blockchain" scheme="https://en.smallyu.net/tags/Blockchain/"/>
    
  </entry>
  
  <entry>
    <title>Hash Functions and Serialization</title>
    <link href="https://en.smallyu.net/2021/10/13/Hash%20Functions%20and%20Serialization/"/>
    <id>https://en.smallyu.net/2021/10/13/Hash%20Functions%20and%20Serialization/</id>
    <published>2021-10-13T03:47:31.000Z</published>
    <updated>2025-08-12T15:22:29.928Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Hash-function"><a href="#Hash-function" class="headerlink" title="Hash function"></a>Hash function</h3><p>A hash function maps data to its hash values. A hash value is like a quasi-unique identifier for data, allowing the data to be represented in a smaller, memory-friendly form. There are many implementations of hash functions. You can think of them as a black box: data goes in, a hash value comes out.</p><img src="7.png" width="50%"><p>For example, we can take a character’s ASCII code as its hash value:</p><pre><code>HASH(&quot;a&quot;) = 97HASH(&quot;b&quot;) = 98HASH(&quot;c&quot;) = 99HASH(&quot;d&quot;) = 100</code></pre><p>For data consisting of two characters, add the two characters’ ASCII codes to produce the hash value:</p><pre><code>HASH(&quot;ab&quot;) = 97 + 98 = 195HASH(&quot;cd&quot;) = 99 + 100 = 199</code></pre><p>But it’s easy to see a problem: <code>HASH(&quot;ad&quot;) == HASH(&quot;bc&quot;) == 197</code>. For strings of length 3, 4, or more, collisions (duplicate hash values) become even more likely.</p><p>Collisions are allowed—hash values may repeat—but if there are too many of them, the hash function loses its utility and use cases. If everything collides, you can’t distinguish anything; what good is a hash then?</p><p>Unfortunately, even the best hash functions can’t eliminate collisions; they can only reduce the probability. One idea—by analogy to sharding in databases—is to give each character enough “headroom.”</p><p>We can redesign our hash function: for a single character, still output its ASCII code. For two characters, multiply the first character by a base and then add the second character. Since the first character becomes large after multiplication, adding the second character’s ASCII code on top of it should avoid collisions regardless of the second character.</p><pre><code>HASH(&quot;ab&quot;) = 97 * 1000 + 98 = 97098HASH(&quot;cd&quot;) = 99 * 1000 + 100 = 99100HASH(&quot;ad&quot;) = 97 * 1000 + 100 = 97100HASH(&quot;cd&quot;) = 98 * 1000 + 99 = 98099</code></pre><p>This at least solves collisions for two-character strings.</p><p>Generalizing to longer strings: choose a prime as the base to avoid repetitive patterns from addition. To ensure sufficient “space,” use increasing powers of the prime for each character. The formula:</p><pre><code>hashCodes = char1 * base^(l-1) + char2 * base^(l-2) + ...</code></pre><p>Here, <code>hashCodes</code> is the output hash value, <code>char1</code> is the first character, <code>char2</code> the second, <code>base</code> is the chosen prime, and <code>l</code> is the string length. For a 3-character string, the first character uses base^2, the second uses base^1, the third uses base^0, and so on.</p><p>If we choose 31 as the prime, an implementation looks like:</p><pre><code>public static int hashCode(byte[] value) &#123;    int h = 0;    for(int i = 0; i &lt; value.length; ++i) &#123;        h = 31 * h + value[i];    &#125;    return h;&#125;</code></pre><p>The exact code may not match your initial intuition, but you can trust it aligns with the formula above.</p><pre><code>hashCode(&quot;a&quot;) = 97hashCode(&quot;ab&quot;) = 97 * 31 + 98 = 3105hashCode(&quot;abc&quot;) = 97*31^2 + 98*31 + 99 = 96354</code></pre><p>This is how <code>hashCode</code> is implemented in the JDK (Java Development Kit).</p><h3 id="Cryptographic-hash-function-CHF"><a href="#Cryptographic-hash-function-CHF" class="headerlink" title="Cryptographic hash function (CHF)"></a>Cryptographic hash function (CHF)</h3><p>It’s not hard to see that, for simple hash functions, one can often reconstruct the original data from the hash value. Suppose we already know the data length is 2, and characters use ASCII (0–255). We can write a program that enumerates all pairs <code>(x, y)</code> that satisfy the target hash value:</p><pre><code> public static String deHashCode(int code) &#123;    for (int x = 0; x &lt;= 255; x++) &#123;        int y = code - 31 * x;        if (y &lt; 0 || y &gt; 255) &#123;            continue;        &#125;        System.out.println(((char) x)+&quot;,&quot;+((char) y));    &#125;    return &quot;&quot;;&#125;</code></pre><p>For example, when <code>hashCode = 3105</code>, we might get output like:</p><pre><code>\,ý],Þ^,¿_, `,a,bb,Cc,$d,</code></pre><p>The original data <code>ab</code> appears among the (few) possibilities.</p><p>Is there a way to make it harder to infer the original data from the hash value? In public-key cryptography, <code>%</code> (modulus) plays a major role. Hash functions can also borrow ideas from cryptography.</p><p>“Cryptographic” is a modifier on “hash function,” meaning a hash function that incorporates cryptographic techniques.</p><img src="8.png" width="50%"><p>MD5 is a very widely used—and nearly obsolete—cryptographic hash function that maps inputs of arbitrary length to a 128-bit hash value.</p><pre><code>md5(&quot;a&quot;) = 0cc175b9c0f1b6a831c399e269772661md5(&quot;ab&quot;) = 187ef4436122d1cc2f40dc2b92f0eba0</code></pre><p>MD5’s internal steps are numerous; it is a one-way, non-reversible hash function, so you can’t easily derive the original data from the hash value. The input can be any size—even a 1 GB binary file—and it will be hashed to a 128-bit string.</p><p>Beyond MD5, SHA-1 offers higher security, and BLAKE2 is faster to compute; both are typical cryptographic hash functions.</p><br><h3 id="Serialization"><a href="#Serialization" class="headerlink" title="Serialization"></a>Serialization</h3><p>Serialization is a very common operation in programming. It converts complex, structured data into a format that’s easy to process uniformly across different environments—like defining an interface format for network transmission.</p><img src="9.png" width="50%"><p>The process of converting data into a uniform format is called serialization; converting from the uniform format back to a specific structure is deserialization. JSON’s <code>stringify</code> can be viewed as a form of serialization:</p><pre><code>let object = &#123;    field1: &quot;abc&quot;,    field2: 123&#125;let str = JSON.stringify(object)    print(str)    // &#123;&quot;field1&quot;:&quot;abc&quot;,&quot;field2&quot;:123&#125;</code></pre><h3 id="Serialization-CHF"><a href="#Serialization-CHF" class="headerlink" title="Serialization + CHF"></a>Serialization + CHF</h3><p>It’s clear that the result of <code>JSON.stringify</code> is a string, which we can feed into a cryptographic hash function:</p><pre><code>md5(str) = d79152b724c5f1e52e6bd4bfaf6e1532</code></pre><p>As long as we define how to serialize the data, we can obtain a hash value for any data format.</p><h3 id="Serialization-CHF-Linked-List"><a href="#Serialization-CHF-Linked-List" class="headerlink" title="Serialization + CHF + Linked List"></a>Serialization + CHF + Linked List</h3><p>Links in a linked list are usually represented by references (pointers), but pointers aren’t the only option. We can extend the idea of the data structure and use the node’s data hash value as the linkage:</p><img src="10.png" width="50%"><p><code>98</code> is the hash value of <code>b</code>, indicating that the node with value <code>a</code> points to the next node whose hash value is <code>98</code>, i.e., the node with value <code>b</code>.</p><p>We can also use a reverse linked list:</p><img src="11.png" width="50%"><p><code>a</code> has a hash value of 97, indicating that the node with value <code>b</code> points backward to a previous node whose hash value is <code>97</code>.</p><p>Of course, these “values” can be more complex structures. As long as we define a serialization format, we can apply more sophisticated hash functions. For example, a forward linked list like this:</p><pre><code>type Node struct &#123;    Value int    Next  string&#125;node1 = Node&#123; Value: &quot;a&quot; &#125;node1_str = JSON.stringify(node1)   // &#123; &quot;Value&quot;: &quot;a&quot; &#125;node1_hash = md5(node1_str)         // 9ad06e8a44d0daf821f110794fb012c7node1.Next = node1_hash</code></pre><p>This constructs one node; and so on.</p><p>Another form—perhaps better or more suitable in some scenarios—is a reverse linked list:</p><pre><code>type Node struct &#123;    Prev string    Value int&#125;node1 = Node&#123; Value: &quot;a&quot; &#125;node1_str = JSON.stringify(node1)   // &#123; &quot;Value&quot;: &quot;a&quot; &#125;node1_hash = md5(node1_str)         // 9ad06e8a44d0daf821f110794fb012c7node2 = Node&#123; Value: &quot;b&quot; &#125;node2_str = JSON.stringify(node2)   // &#123; &quot;Value&quot;: &quot;b&quot; &#125;node2_hash = md5(node2_str)         // 7e332b78dbaac93a818a6ab639f5a71bnode2.Prev = node1_hash</code></pre><p>This kind of reverse linked list is the fundamental data structure of blockchains.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h3 id=&quot;Hash-function&quot;&gt;&lt;a href=&quot;#Hash-function&quot; class=&quot;headerlink&quot; title=&quot;Hash function&quot;&gt;&lt;/a&gt;Hash function&lt;/h3&gt;&lt;p&gt;A hash function maps data</summary>
        
      
    
    
    
    
    <category term="Cryptography" scheme="https://en.smallyu.net/tags/Cryptography/"/>
    
  </entry>
  
  <entry>
    <title>Where Consortium Chains Fall Short Compared to Public Chains</title>
    <link href="https://en.smallyu.net/2021/09/29/Where%20Consortium%20Chains%20Fall%20Short%20Compared%20to%20Public%20Chains/"/>
    <id>https://en.smallyu.net/2021/09/29/Where%20Consortium%20Chains%20Fall%20Short%20Compared%20to%20Public%20Chains/</id>
    <published>2021-09-29T06:27:43.000Z</published>
    <updated>2025-08-06T10:38:28.722Z</updated>
    
    <content type="html"><![CDATA[<p>In the Chinese context, there is no clear standard definition for “public chain” and “consortium chain.” In 2018, the National Institute of Standards and Technology (NIST) in the United States classified blockchains into Permissionless blockchain and Permissioned blockchain in the <em><a href="http://vpb.smallyu.net/[Tech]%20blockchain/Blockchain%20Technology%20Overview%20-%20NIST.IR.8202.pdf">Blockchain Technology Overview</a></em>. However, this classification does not strictly correspond to public chains and consortium chains. Perhaps the difference between public chains and consortium chains lies in the size of the node network, or maybe the difference lies in whether the blockchain is oriented towards the public internet or a private local area network. Regardless of the definition, we can at least roughly distinguish between public chains and consortium chains.</p><p>The merits of public chains and consortium chains are not purely based on technology or certain evaluation metrics. Some might instinctively believe that public chains face more complex network environments and user volumes than consortium chains. However, technological gaps can always be bridged, and consortium chains do possess some superior technical characteristics compared to public chains.</p><p>There is a story called <em><a href="https://baike.baidu.com/item/%E7%9A%87%E5%B8%9D%E7%9A%84%E9%87%91%E9%8B%A4%E9%A0%AD/23725819">The Emperor’s Golden Hoe</a></em>:</p><blockquote><p>In ancient times, two old farmers fantasized about the luxurious life of the emperor. One said, “I think the emperor must eat his fill of white bread every day!” The other said, “Not just that, I think the emperor must use a golden hoe when he works in the fields!”</p></blockquote><p>Consortium chains are essentially using blockchain for traditional industry businesses, or even disguising blockchain to deceive people. The problem with consortium chains is that their vision is too limited.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;In the Chinese context, there is no clear standard definition for “public chain” and “consortium chain.” In 2018, the National Institute</summary>
        
      
    
    
    
    
    <category term="Blockchain" scheme="https://en.smallyu.net/tags/Blockchain/"/>
    
    <category term="Public Chain" scheme="https://en.smallyu.net/tags/Public-Chain/"/>
    
    <category term="Consortium Chain" scheme="https://en.smallyu.net/tags/Consortium-Chain/"/>
    
  </entry>
  
  <entry>
    <title>Saving Paths in Dijkstra Algorithm</title>
    <link href="https://en.smallyu.net/2021/09/18/Saving%20Paths%20in%20Dijkstra%20Algorithm/"/>
    <id>https://en.smallyu.net/2021/09/18/Saving%20Paths%20in%20Dijkstra%20Algorithm/</id>
    <published>2021-09-18T11:00:45.000Z</published>
    <updated>2025-08-06T10:38:28.698Z</updated>
    
    <content type="html"><![CDATA[<p>In Layer 2 of blockchain, there’s a scaling solution called State Channels, where it’s necessary to find the nearest routing node.</p><h3 id="Dijkstra-Algorithm-Concept"><a href="#Dijkstra-Algorithm-Concept" class="headerlink" title="Dijkstra Algorithm Concept"></a>Dijkstra Algorithm Concept</h3><p>The Dijkstra algorithm solves the single-source shortest path problem. It only outputs the shortest distance from one point to other points. For example, in this graph with A as the starting point, we want to know the shortest distance to point D:</p><img src="g1.png" width="50%" /><p>The Dijkstra algorithm is essentially a combination of dynamic programming and greedy strategy. To find the shortest path, traverse all nodes, updating the shortest distance records at each step. Once all nodes are visited, the shortest distances are finalized. The initial state set:</p><table><thead><tr><th>A</th><th>B</th><th>C</th><th>D</th></tr></thead><tbody><tr><td>0</td><td>-</td><td>-</td><td>-</td></tr></tbody></table><p>Currently at point A, the distance to itself is 0, and distances to other nodes are unknown.</p><p>From A, we can reach B and C with distances of 4 and 2 respectively. Update the state:</p><table><thead><tr><th>A</th><th>B</th><th>C</th><th>D</th></tr></thead><tbody><tr><td>0</td><td>-</td><td>-</td><td>-</td></tr><tr><td></td><td>4</td><td>[2]</td><td>-</td></tr></tbody></table><p>Brackets indicate the current shortest distance. Since C is closer, the next move is to C:</p><img src="g2.png" width="50%" /><p>At point C, it can reach A, B, and D. Since A has already been visited, we define <code>prev = []</code>. Now with A and C visited: <code>prev = [A, C]</code>.</p><p>At this point, the distance to B becomes 3 (<code>A -&gt; C -&gt; B</code>), shorter than the direct path. Update states and now D is reachable:</p><table><thead><tr><th>A</th><th>B</th><th>C</th><th>D</th></tr></thead><tbody><tr><td>0</td><td>-</td><td>-</td><td>-</td></tr><tr><td></td><td>4</td><td>[2]</td><td>-</td></tr><tr><td></td><td>[3]</td><td></td><td>5</td></tr></tbody></table><p>B is closer than D, so the next move is to B:</p><img src="g3.png" width="50%" /><p>Now <code>prev = [A, C, B]</code>, and update:</p><table><thead><tr><th>A</th><th>B</th><th>C</th><th>D</th></tr></thead><tbody><tr><td>0</td><td>-</td><td>-</td><td>-</td></tr><tr><td></td><td>4</td><td>[2]</td><td>-</td></tr><tr><td></td><td>[3]</td><td></td><td>5</td></tr><tr><td></td><td></td><td></td><td>[5]</td></tr></tbody></table><p>Only D is left:</p><img src="g4.png" width="50%" /><p><code>prev = [A, C, B, D]</code>, all nodes visited. Final result:</p><table><thead><tr><th>A</th><th>B</th><th>C</th><th>D</th></tr></thead><tbody><tr><td>0</td><td>3</td><td>2</td><td>5</td></tr></tbody></table><p>We now know the shortest distance from A to D is 5.</p><h3 id="Tracking-the-Shortest-Path"><a href="#Tracking-the-Shortest-Path" class="headerlink" title="Tracking the Shortest Path"></a>Tracking the Shortest Path</h3><p>The algorithm yields shortest distances, but what if we also want the exact path, like A -&gt; D?</p><h4 id="Forward-Greedy-Approach"><a href="#Forward-Greedy-Approach" class="headerlink" title="Forward Greedy Approach"></a>Forward Greedy Approach</h4><p>We can infer <code>A -&gt; C -&gt; D</code> is the shortest path. The <code>prev</code> list is <code>[A, C, B, D]</code>. Since going through B to D is longer, B is excluded.</p><p>We might consider excluding any node unless:</p><ul><li>It can reach D,</li><li>Going through it gives the shortest distance to D.</li></ul><p>Only when both are true, we keep the node. For instance, if B is selected but doesn’t meet the criteria, it’s removed from <code>path = [A, C, B]</code> back to <code>path = [A, C]</code>. If E is selected next and fails, again it’s excluded. Until D is selected.</p><p>This works in complex scenarios:</p><img src="g5.png" width="50%" /><img src="g6.png" width="50%" /><p>However, this breaks in cases like:</p><img src="g7.png" width="50%" /><p>If the shortest path is <code>[A, E, C, D]</code>, and E can’t directly reach D, it gets wrongly excluded. Removing the “can reach D” condition causes other problems.</p><p>The forward greedy approach fails because we can’t determine if a node belongs to the final path during traversal.</p><h4 id="Reverse-Greedy-Approach"><a href="#Reverse-Greedy-Approach" class="headerlink" title="Reverse Greedy Approach"></a>Reverse Greedy Approach</h4><p>Once D is selected as the current shortest node, the full shortest distance from A to D is determined. If we know where D came from (e.g., C), and where C came from (e.g., A), we can reconstruct the path backward.</p><img src="g4.png" width="50%" /><p>We need a way to track predecessors during traversal. This approach is common in DFS or tree traversals.</p><p>Is maintaining distance in DFS equivalent to Dijkstra? No.</p><p><strong>Recursion vs Tail Recursion</strong></p><p>Dijkstra is usually written in loops:</p><pre><code class="go">for &#123;&#125;</code></pre><p>Or as tail recursion:</p><pre><code class="go">func recursion() &#123;        recursion()&#125;</code></pre><p>It’s a one-way loop. Full recursion like:</p><pre><code class="go">func recursion() &#123;    for &#123;        recursion()    &#125;&#125;</code></pre><p>might enter multiple branches at once to find the best one. At C, we might explore both <code>C -&gt; B -&gt; D</code> and <code>C -&gt; D</code>, keeping only the better path.</p><p>But where to branch? C? B? A? If every node branches, it creates massive overhead. Trees allow this since nodes don’t overlap.</p><h4 id="Second-Dynamic-Programming"><a href="#Second-Dynamic-Programming" class="headerlink" title="Second Dynamic Programming"></a>Second Dynamic Programming</h4><p>The first DP maintains distance data. The second maintains path states:</p><pre><code class="js">pathList = &#123;    A: [],    B: [],    C: [],    D: []&#125;</code></pre><p>At the start, A can reach B and C:</p><img src="g1.png" width="50%" /><pre><code class="js">pathList = &#123;    A: [A],    B: [A, B],    C: [A, C],    D: []&#125;</code></pre><p>After moving to C, since <code>A -&gt; C -&gt; B</code> is shorter than <code>A -&gt; B</code>, update <code>pathList[C].push(B)</code>. Also update D path.</p><img src="g2.png" width="50%" /><pre><code class="js">pathList = &#123;    A: [A],    B: [A, C, B],    C: [A, C],    D: [A, C, D]&#125;</code></pre><p>In this round, B is chosen, but <code>A -&gt; C -&gt; B -&gt; D</code> is longer than <code>A -&gt; C -&gt; D</code>, so don’t update pathList.</p><img src="g3.png" width="50%" /><p>Upon reaching D, traversal ends.</p><img src="g4.png" width="50%" /><p>The result path is <code>A -&gt; C -&gt; D</code>.</p><p>Can we save only the path to D? No, because updates to other nodes rely on current node paths. Path state must be complete.</p><h3 id="Tracking-Non-Shortest-Paths"><a href="#Tracking-Non-Shortest-Paths" class="headerlink" title="Tracking Non-Shortest Paths"></a>Tracking Non-Shortest Paths</h3><p>Dijkstra is greedy and always picks the nearest node. If we need to store non-shortest paths, it’s possible but not ideal. DFS&#x2F;BFS is better suited.</p><p><br><br></p><h3 id="Supplement-2025-05-11"><a href="#Supplement-2025-05-11" class="headerlink" title="Supplement (2025.05.11)"></a>Supplement (2025.05.11)</h3><p>This Dijkstra-related work was originally part of a State Channels project called <a href="https://github.com/saveio-backup/pylons">pylons</a>, used to find the shortest path among multiple channels. Initially, it used <a href="https://github.com/saveio-backup/pylons/blob/master/route/dfs.go">DFS</a>, but later I added a <a href="https://github.com/saveio-backup/pylons/blob/master/route/dijkstra.go">Dijkstra</a> implementation, which included a blacklist feature and used transaction fees as the basis for path distance calculation.</p><p>Now, the routing portion of the code has been split out into a separate repository: <a href="https://github.com/smallyunet/dijkstra-demo/">smallyunet&#x2F;dijkstra-demo</a> as a memento.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;In Layer 2 of blockchain, there’s a scaling solution called State Channels, where it’s necessary to find the nearest routing</summary>
        
      
    
    
    
    
    <category term="Algorithm" scheme="https://en.smallyu.net/tags/Algorithm/"/>
    
  </entry>
  
  <entry>
    <title>Why Using Blockchain for Digital Currency is a Political Issue</title>
    <link href="https://en.smallyu.net/2021/04/18/Why%20Using%20Blockchain%20for%20Digital%20Currency%20is%20a%20Political%20Issue/"/>
    <id>https://en.smallyu.net/2021/04/18/Why%20Using%20Blockchain%20for%20Digital%20Currency%20is%20a%20Political%20Issue/</id>
    <published>2021-04-18T15:33:54.000Z</published>
    <updated>2025-08-06T10:38:28.725Z</updated>
    
    <content type="html"><![CDATA[<p>I originally didn’t want to mention blockchain specifically again. Due to work-related reasons, I frequently encounter related topics.</p><p>Recently, a senior technical manager complained to me that “it’s an entirely layman’s opinion to say digital currency can’t use blockchain. Even just recording large transactions of the four major banks on the blockchain is a great thing, and it can use a hierarchical transaction technology architecture to smoothly solve the issue of limited performance for small payments on the blockchain…”</p><p>My logic is very simple.</p><p>If blockchain had never appeared in the world, never existed. In this case, if “the higher-ups” required that the transaction data of major banks must be synchronized, consistent, and traceable. Could the people below achieve this?</p><p>Not only can they achieve it, but they can do it very well.</p><p>Problems that blockchain can solve can also be solved without blockchain. This is almost a well-known fact. This is also why some people say “there is no new technology in blockchain”.</p><p>Of course, the “digital currency” here specifically refers to China’s digital currency, and “blockchain” means—before discussing how to use blockchain, shouldn’t we first figure out what “blockchain” is? Strangely, it seems that no one cares about this issue.</p><p>In this regard, artificial intelligence contrasts with blockchain. What artificial intelligence can do, if the technology doesn’t keep up, it really can’t be done.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;I originally didn’t want to mention blockchain specifically again. Due to work-related reasons, I frequently encounter related</summary>
        
      
    
    
    
    
    <category term="Blockchain" scheme="https://en.smallyu.net/tags/Blockchain/"/>
    
  </entry>
  
  <entry>
    <title>Blog Theme Sharing Plan (Draft)</title>
    <link href="https://en.smallyu.net/2021/02/11/Blog%20Theme%20Sharing%20Plan%20(Draft)/"/>
    <id>https://en.smallyu.net/2021/02/11/Blog%20Theme%20Sharing%20Plan%20(Draft)/</id>
    <published>2021-02-11T06:48:31.000Z</published>
    <updated>2025-08-06T10:38:27.640Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Preface"><a href="#Preface" class="headerlink" title="Preface"></a>Preface</h3><p>I wrote this draft two months ago, and only remembered it today (04.10), so I decided to publish it. One reason I didn’t publish it earlier is that I couldn’t keep the project well-maintained. It’s challenging to create software that everyone likes and finds suitable, especially when it comes to blog themes that are dependent on various environment versions. Borrowing a line from the movie “Legend of the Demon Cat,” “The events are fake, but the emotions are real.” Best wishes.</p><h3 id="Main-Text"><a href="#Main-Text" class="headerlink" title="Main Text"></a>Main Text</h3><p>The blog theme I’m currently using is modeled after Yining Wang’s blog <a href="http://www.yinwang.org/">Of course I’m talking nonsense</a>. A few years ago, I open-sourced the mimicked blog theme on Github (<a href="https://github.com/smallyunet/hexo-theme-yinwang">smallyunet&#x2F;hexo-theme-yinwang</a>). Although I frequently update and optimize my own blog theme, the open-source repository hasn’t been updated for a long time.</p><p>On one hand, I’m unsure whether imitating the theme constitutes infringement. On the other hand, I’ve always been troubled by the fact that I don’t want to “earn stars” through such a project. I don’t even want this project to appear on my GitHub homepage, so I had to start customizing the project panel on my homepage. Overall, since this isn’t my original work, it’s like Xia Luo in “Goodbye Mr. Loser,” who became famous in Xihong City by using Jay Chou’s works after traveling back to 1997, only to realize those things weren’t his. He just had a beautiful dream.</p><p>Now, I want to continue maintaining this open-source blog theme project.</p><p>Hiding it from others or making it uncomfortable for others to use is obviously wrong. Ignorance won’t stop the spread of truth; useful things should be better utilized. I even hope this theme style can become a symbol—a symbol of those inspired by Yining Wang, a symbol of people with integrity and kindness, a symbol of those with true insight.</p><p>This isn’t religious fervor. We don’t blindly trust or worship anyone. We advocate <a href="http://www.yinwang.org/blog-cn/2017/11/01/power-of-reasoning">the power of reasoning</a> (by Yining Wang). We don’t form cliques, we don’t promote or force others to use or not use something, we don’t force others to believe or disbelieve something. We idolize someone and consider ourselves their “fans” not because we feel an inexplicable sense of superiority from belonging to a certain group, but because we have learned many valuable and indescribable things from them. When we say we “like someone,” we’re not saying that person is so great, but rather, “we’ve learned something from them, and because of what we’ve learned, we are also great.”</p><p>It’s quite surprising that I suddenly thought of this today. It’s a bit unexpected, a bit joyful, and a bit fearful and anxious. Today happens to be Lunar New Year’s Eve. Happy New Year.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h3 id=&quot;Preface&quot;&gt;&lt;a href=&quot;#Preface&quot; class=&quot;headerlink&quot; title=&quot;Preface&quot;&gt;&lt;/a&gt;Preface&lt;/h3&gt;&lt;p&gt;I wrote this draft two months ago, and only</summary>
        
      
    
    
    
    
    <category term="Plan" scheme="https://en.smallyu.net/tags/Plan/"/>
    
  </entry>
  
  <entry>
    <title>Blockchain: The Cornerstone of the Next Generation Digital Identity Authentication System</title>
    <link href="https://en.smallyu.net/2020/12/08/Blockchain:%20The%20Cornerstone%20of%20the%20Next%20Generation%20Digital%20Identity%20Authentication%20System/"/>
    <id>https://en.smallyu.net/2020/12/08/Blockchain:%20The%20Cornerstone%20of%20the%20Next%20Generation%20Digital%20Identity%20Authentication%20System/</id>
    <published>2020-12-08T12:02:38.000Z</published>
    <updated>2025-08-06T10:38:27.640Z</updated>
    
    <content type="html"><![CDATA[<p>How can one prove “I am me” in the world of the internet? Authenticate identity information on site A, and then need to authenticate again on site B? Taking a photo with an ID card and uploading it, manual verification—too cumbersome? Multiple accounts and passwords that are hard to remember, easy to mix up, and difficult to manage? The concept of Self-sovereign identity (SSI) is precisely the idea that can solve these problems.</p><p>SSI is a concept in the digital identity movement, where only the user owns all and complete digital identity information, without other managers and organizations involved. In the concept of SSI, users have their own decentralized identifiers (DIDs) and can fully control their identity information. They can use, update, or delete information at any time. Users can create and manage their own verifiable credentials and decide when to use and share their credentials without needing to request authorization from centralized institutions.</p><p>Using an SSI system, all key information can be managed through a digital identity wallet, allowing users to log in to all websites with one account. In the wallet terminal, users can apply to authoritative institutions for certificates such as ID cards, driver’s licenses, and residence permits, all stored in digital form on phones or computers. Digital certificates are machine-readable and verifiable, allowing safe presentation to third-party applications. Third-party applications can directly verify the certificate’s validity without human intervention and without the issuing institution’s participation.</p><p>Thanks to the continuous development of blockchain technology, the realization of the SSI concept is gradually becoming possible. Blockchain systems are inherently decentralized, with unique data structure designs and cryptographic technology applications. Combined with consensus algorithms’ excellent capabilities in multi-node data synchronization, blockchain can protect data privacy and security. Once data is written into the system, no one can tamper with it, providing a highly credible storage environment. In constructing an SSI system, using blockchain as a verifiable data registry is undoubtedly the best choice.</p><p>There are already many precedents for SSI. In 2017, the Sovrin Foundation released the world’s first public distributed ledger network for self-sovereign digital identity. The entire system runs on open standards and the open-source Sovrin protocol, maintained by the Linux Foundation’s Hyperledger Indy project. Sovrin’s white paper in 2018 posed and answered the question, “Why is there no certificate to prove identity in the network world like in the physical world? Until the advent of blockchain technology, we solved this problem!” Combining W3C’s DIDs, Sovrin proposed a complete solution for digital identity and credentials. Sovrin’s idea has always been clear: to build and use an open, accessible blockchain network like Bitcoin and Ethereum.</p><p>eSSIF-Lab (European Self-Sovereign Identity Lab) is another case. The European Blockchain Partnership proposed the EBSI (The European Blockchain Services Infrastructure), a cross-European distributed node network providing cross-border public services, with 28 member states signing related declarations. The eSSIF-Lab project, funded by the European Commission, aims to promote SSI as the next-generation open, trusted, and secure digital identity solution. On July 23, 2014, the EU established the eIDAS (electronic IDentification, Authentication and trust Services) regulation for electronic transactions in the common EU market. In May 2019, eIDAS announced support for self-sovereign digital identity based on W3C-related specifications.</p><p>Microsoft has also been active in this field. In October 2018, Microsoft released the white paper “Decentralized Identity,” introducing the technical solution for constructing a decentralized digital identity system based on blockchain. This includes DIDs specification, decentralized data systems, DID user terminals, DID universal resolvers, DID identity hubs, DID authentication systems, decentralized clients, and services. It detailed the components of each module and the interaction processes of various roles in the system, providing an excellent template for constructing SSI systems. Currently, Microsoft offers an open service platform to experience related products and capabilities.</p><p>In addition, uPort on Ethereum and IPFS networks, Blockstack with its self-developed blockchain and third-party DApp support, and ShoCard, adaptable to the Bitcoin network, are excellent examples. Domestic companies and institutions are also working in this area. For example, AntChain provides Decentralized Identity Service (DIS), Tencent Cloud’s digital identity solutions, and WeBank’s WeIdentity, a blockchain-based distributed multi-center technical solution, all utilizing blockchain’s decentralized, highly credible data characteristics to construct reliable digital identity identification and authentication systems.</p><p>Blockchain is an advanced technology with tremendous potential, broad development prospects, and application space. Whether in national policy support or practical application cases, the countless possibilities of blockchain in the future are evident. We are also actively exploring and promoting the development of blockchain-related technologies and application scenarios, combining blockchain with homomorphic encryption, federated learning, multi-party computation, zero-knowledge proofs, and other cutting-edge technologies to use the best technical capabilities to usher in the next internet era.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;How can one prove “I am me” in the world of the internet? Authenticate identity information on site A, and then need to authenticate</summary>
        
      
    
    
    
    
    <category term="Blockchain" scheme="https://en.smallyu.net/tags/Blockchain/"/>
    
  </entry>
  
  <entry>
    <title>Can Web Technologies Achieve 3D Modeling?</title>
    <link href="https://en.smallyu.net/2020/09/20/Can%20Web%20Technologies%20Achieve%203D%20Modeling?/"/>
    <id>https://en.smallyu.net/2020/09/20/Can%20Web%20Technologies%20Achieve%203D%20Modeling?/</id>
    <published>2020-09-20T14:58:39.000Z</published>
    <updated>2025-08-06T10:38:27.643Z</updated>
    
    <content type="html"><![CDATA[<p>Can web technologies (HTML5, CSS3, JavaScript) achieve stunning 3D modeling or even 3D animation effects? For now, I think not. For example, consider expecting such a page effect:</p><img src="preview.png" class="no-shadow" width="100%"><p>d3.js is out of consideration; it is merely a data visualization tool and is not in the domain of 3D modeling.</p><p>Three.js seems to be the more popular 3D modeling library at present. If three.js can do it, how should it be done? The initial idea is to draw a cube like this:</p><img src="cube_target.png" class="no-shadow" width="20%"><p>A cube in 3D modeling is equivalent to “hello world” in programming; it’s very easy to create:</p><img src="cube_1.png" class="no-shadow" width="20%"><p>Add lighting to the scene, and the cube will no longer be pitch black. Then, add color to the cube, change the scene’s background color, and move the light above the cube to make it look decent:</p><img src="cube_2.png" class="no-shadow" width="20%"><p>The edges of the target cube are glowing and gradient-colored. How to add an edge to the cube? The cube itself does not have this attribute; you can only draw another cube using linear materials (LineBasicMaterial in three.js, while the cube uses MeshPhongMaterial) and overlay it on the solid cube:</p><img src="cube_3.png" class="no-shadow" width="20%"><p>How to make the linear cube glow? Linear materials (LineBasicMaterial) cannot use gradient colors; only shader materials (ShaderMaterial) can use gradient colors. Shader materials can achieve colorful effects, like this (from <a href="https://stackoverflow.com/questions/52614371/apply-color-gradient-to-material-on-mesh-three-js">StackOverflow</a>):</p><img src="line_1.png" class="no-shadow" width="20%"><p>But here lies the problem. In three.js, rendering an object requires two parameters: geometry and material. Linear materials and shader materials are both types of materials. (TorusKnotGeometry is the geometric shape used in the above image)</p><pre><code>Line Cube = EdgesGeometry + LineBasicMaterialGradient Line = TorusKnotGeometry + ShaderMaterial</code></pre><p>Combining linear materials and shader materials (LineBasicMaterial and ShaderMaterial) is illogical; I have not found a way to achieve glowing cube edges. Applying the shader to the cube results in this effect (color from 0x215ec9 to 0x000000):</p><img src="cube_4.png" class="no-shadow" width="20%"><p>So what next? I realized that even if a nice-looking cube is achieved, it’s still far from rendering the entire image. For instance, how to achieve such text effects?</p><img src="part_1.png" class="no-shadow" width="30%"><p>Three.js’ Texture itself works well, but how to stably place text on the cube with a transparent black background box? Moreover, what about these colorful lines and precise arrow directions:</p><img src="part_2.png" class="no-shadow" width="15%"><p>And the positioning layout and animation effects of more than a dozen elements on the whole picture.</p><p>I believe three.js (WebGL) can technically achieve such effects. Even the official examples include web games. However, if developing a web game, image assets would definitely be used. Where do these assets come from? Back to tools like PS and AI. If such productivity tools are used, there is no need to write layouts and animations in JS. Pure web technologies seem difficult to fully solve the problem of 3D modeling. H5 animations face a similar situation.</p><p>Another issue with coding for 3D modeling is its non-intuitiveness. Coding defies intuition and visuals, which might work for writing web or APP interfaces (2D). If it were possible to directly place cubes and lines on a canvas, drag to change positions with a mouse, adjust colors, and add various other elements, like playing a game (such as Minecraft), wouldn’t it be much better than coding… isn’t that Adobe Animate?</p><p>Unfortunately, Adobe Animate has no Linux version, and the Linux alternative, Blender, has some performance issues.</p><img src="blender.png" class="no-shadow" width="100%"><p>Returning to the expected effect, the image comes from a big-screen UI <a href="https://www.zcool.com.cn/work/ZMjg2NTA1Njg=.html">design demonstration</a>. The original effect is not actually 3D; the tools used are PS and AI. So, can web technologies achieve this under the premise of needing only 2D effects? If code is used to create various graphics, it still boils down to 3D modeling issues. The simplest way is to take a background image and overlay text on it. Where does the background image come from?</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Can web technologies (HTML5, CSS3, JavaScript) achieve stunning 3D modeling or even 3D animation effects? For now, I think not. For</summary>
        
      
    
    
    
    
    <category term="Work" scheme="https://en.smallyu.net/tags/Work/"/>
    
  </entry>
  
  <entry>
    <title>Do the Right Thing, Then Wait to Get Fired</title>
    <link href="https://en.smallyu.net/2020/08/22/%22Do%20the%20Right%20Thing,%20Then%20Wait%20to%20Get%20Fired%22/"/>
    <id>https://en.smallyu.net/2020/08/22/%22Do%20the%20Right%20Thing,%20Then%20Wait%20to%20Get%20Fired%22/</id>
    <published>2020-08-22T08:17:53.000Z</published>
    <updated>2025-08-06T10:38:27.587Z</updated>
    
    <content type="html"><![CDATA[<p>“Do the right thing, then wait to get fired.” This quote is from a blog post by Google engineer Tan Chade-Meng titled “<a href="http://chademeng.com/me/do-the-right-thing-wait-to-get-fired/">DO THE RIGHT THING, WAIT TO GET FIRED</a>.” The content of this blog was quoted in a book about programmer collaboration, “<a href="https://book.douban.com/subject/11154471/">Team Geek: A Software Developer’s Guide to Working Well with Others</a>“ (P126), which was then cited by CoolShell’s article “<a href="https://coolshell.cn/articles/17972.html">My View on Performance Assessment</a>.” I first saw this quote in CoolShell’s article. After seeing it, it stayed in my mind, and now I must copy it here:</p><blockquote><p>New Google employees (we call “Nooglers”) often ask me what makes me effective at what I do.  I tell them only half-jokingly that it’s very simple: I do the Right Thing for Google and the world, and then I sit back and wait to get fired.  If I don’t get fired, I’ve done the Right Thing for everyone.  If I do get fired, this is the wrong employer to work for in the first place.  So, either way, I win.  That is my career strategy.</p></blockquote><p>What tremendous confidence and strength it takes to say such words! Although the original author also mentioned that this is a half-joking statement, and despite having some influence and having done some “right” things—without status and position, it is indeed difficult to say such words. But the spirit behind this quote will always encourage and inspire us—you know who I’m talking about, enduring and everlasting. There are also many articles discussing the meaning of this quote, such as “<a href="https://brendansterne.com/2013/07/11/do-the-right-thing-wait-to-get-fired/">Do the Right Thing, Wait to Get Fired</a>.”</p><p>Of course, this quote cannot be reversed. It does not mean that waiting to be fired implies doing the right thing. This quote also does not apply to those who like to idle away, because effort does not necessarily yield results, but not trying is definitely comfortable :-P I need to seriously think about what the “right thing” is and how to do something “valuable.”</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;“Do the right thing, then wait to get fired.” This quote is from a blog post by Google engineer Tan Chade-Meng titled “&lt;a</summary>
        
      
    
    
    
    
    <category term="Work" scheme="https://en.smallyu.net/tags/Work/"/>
    
  </entry>
  
  <entry>
    <title>Giving Blockchain a Definition</title>
    <link href="https://en.smallyu.net/2020/08/09/Giving%20Blockchain%20a%20Definition/"/>
    <id>https://en.smallyu.net/2020/08/09/Giving%20Blockchain%20a%20Definition/</id>
    <published>2020-08-09T08:06:45.000Z</published>
    <updated>2025-08-06T10:38:27.655Z</updated>
    
    <content type="html"><![CDATA[<p>For a long time, blockchain seemed to lack a clear definition. The terms often associated with blockchain are decentralization, traceability, immutability, credit-based, and the next-generation value internet. These are all characteristics of blockchain, not its components. These terms describe what blockchain has, but not why it has those features or why it needs them.</p><p>It seems that many things don’t have clear definitions. For instance, what is a computer? Everyone knows it’s something you can play games on and browse the internet. A slightly more technical answer might describe it as a machine based on the Von Neumann architecture with five components. But a computer can simply be considered “a machine that performs computations.” What is a refrigerator? “A cabinet that stores items and has freezing functions” suffices. What is a design pattern? A software program design paradigm. What is a microservice? A software architecture pattern. So, what is blockchain? Interestingly, the term blockchain (blockchain) has no clear origin; even the Bitcoin white paper only mentions a “chain of blocks.”</p><p>I used to have some immature understandings of blockchain. Although not entirely incorrect, they were unclear, especially regarding the question of what blockchain is. Now, I believe the definition of blockchain should be:</p><blockquote><p>Blockchain is a type of data collaboration software, or in other words, blockchain is software used to synchronize data.</p></blockquote><p>Data collaboration software determines what data structure to use and what communication mechanism to synchronize specific data. Blockchain is not a database; it doesn’t store data. Storing data is left to actual databases. Blockchain doesn’t care how data is stored on the disk, whether the storage structure is reasonable, whether the utilization rate is high, or whether the processing speed is fast. Blockchain cares about how data is synchronized to other machines, how to synchronize it timely, and whether the data synchronized from other machines has issues. In a sense, blockchain is an implementation of data collaboration software.</p><p>Because it is data collaboration software, blockchain is multi-node and decentralized, which is self-evident.</p><p>Traceability means that transactions can be traced as long as there are relationships between the data, which is determined by the data model, such as UTXO.</p><p>The chain-like data structure is to facilitate the verification of data integrity by the data collaboration software, similar to using md5 to determine if a file is complete. This data structure is not necessary; comparing the entirety of data can achieve the same goal, although very inefficiently. Using encryption algorithms to summarize data and place it in the next segment essentially ensures that a large block of data is complete, nothing more.</p><p>As for immutability, it is a feature brought by data collaboration software. Blockchain immutability doesn’t mean data can’t be modified; it means that modifications are not recognized by other nodes. This is different. Data immutability is a technical issue. For example, not providing an interface to update data leaves users with no way to modify data, which can be controlled by technical means. Not accepting modifications from other nodes is a mechanism, and this issue is beyond the realm of technology.</p><p>Is blockchain development currently constrained by technology? The theory of computation includes two main parts: computability theory and complexity theory. Computability theory determines whether a problem can be solved algorithmically, and complexity theory aims to improve algorithm efficiency. Is this related to blockchain? Stepping back, does blockchain need computation? It doesn’t; it’s not related and not constrained. Here’s an interesting thought experiment: What would happen if everyone in the world joined a WeChat group? At least the messages on the screen would be overwhelming. What would happen if all the world’s data were on one blockchain? So, ultimately, blockchain is a mechanism issue, not a technical one.</p><p>Bitcoin and blockchain are two concepts. Bitcoin is a transaction system that uses blockchain for data synchronization. Bitcoin is primarily a transaction system, with data synchronization as a secondary need. This is the conceptual mistake I made earlier, equating blockchain with Bitcoin. Many people with a vague understanding of blockchain also associate blockchain with digital currencies like Bitcoin. I remember attending a sharing session last year where the speaker, a director from a well-known exchange, talked about blockchain and national policies, but the whole session was about Bitcoin anecdotes.</p><p>Blockchain is a component of Bitcoin. The author of Bitcoin recognized the value of Bitcoin and released the software and white paper. Why didn’t the author abstract the concept of blockchain and release a general-purpose software and manual? Was it because the author didn’t realize blockchain’s potential value? No. Blockchain was proposed because people saw the value of Bitcoin and wanted to replicate its success, so they extracted Bitcoin’s technical components and called it blockchain. Unfortunately, Bitcoin is a cleverly designed system, and extracting certain technical features alone cannot produce the expected value, which is also blockchain’s current situation. This is a modern version of imitating without understanding the essence.</p><p>Smart contracts were proposed as early as 1997 by a financial and legal practitioner. “Smart” refers to automatically executing certain actions when conditions are met, compared to paper contracts. Indeed, it was a bit smarter, especially in an era when digitalization wasn’t widespread, making the term “smart” not an exaggeration. Moreover, the author explicitly stated that smart contracts did not use artificial intelligence.</p><p>Abstracting smart contracts, they automatically execute actions when conditions are met, similar to conditional statements in programming languages. In fact, most modern smart contracts are implemented using Turing-complete programming languages. The fatal problem of describing contracts with programming languages is that their expressive power is much weaker than natural language. If you try to rewrite all the clauses in an insurance policy using a programming language—“If X happens, then compensate Y…”—the cost of rewriting is too high. Furthermore, legal clauses often require professional lawyers and judges to interpret and judge. The logic of the real world is far more complex than program logic, which programming languages cannot handle.</p><p>A data synchronization software should not be venerated. Blockchain has been deified and demonized. Therefore, one cannot say blockchain has no value because it is merely a tool software.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;For a long time, blockchain seemed to lack a clear definition. The terms often associated with blockchain are decentralization,</summary>
        
      
    
    
    
    
    <category term="Blockchain" scheme="https://en.smallyu.net/tags/Blockchain/"/>
    
  </entry>
  
  <entry>
    <title>Why Do Constructors Have No Return Value?</title>
    <link href="https://en.smallyu.net/2020/05/16/Why%20Do%20Constructors%20Have%20No%20Return%20Value_/"/>
    <id>https://en.smallyu.net/2020/05/16/Why%20Do%20Constructors%20Have%20No%20Return%20Value_/</id>
    <published>2020-05-16T04:19:44.000Z</published>
    <updated>2025-08-06T10:38:28.722Z</updated>
    
    <content type="html"><![CDATA[<p>Just now, a classmate asked me a question: What does it mean to <code>new</code> a member function in C++?</p><p>…I thought to myself, a <code>new</code> member function? Is there such an operation?</p><p>Later I asked, is the name of this member function the same as the class name?</p><p>He said yes, it’s the constructor.</p><p>…Isn’t that just <code>new</code>ing an object?</p><p>Then he asked a profound question: Why don’t constructors have return values?</p><p>I said that <code>new</code> is for the class, the part after <code>new</code> refers to the class name, not a member function.</p><p>But the class doesn’t have parameters?</p><p>The constructor has parameters.</p><p>But the constructor has no return value?</p><p>Huh?</p><img src="face.jpeg" width="30%" /><p>Here is a simple piece of code:</p><pre><code class="C++">#include &lt;iostream&gt;using namespace std;class Test&#123;    public:        Test(int num);&#125;;// Constructor, has parameters but no return valueTest::Test(int num)&#123;    cout &lt;&lt; num &lt;&lt; endl;&#125;int main()&#123;    // Object assigned to a variable    Test* test = new Test(1);    return 0;&#125;</code></pre><p>Actually, you can think of this scenario without looking at the code. When you <code>new</code> an object, is the variable after <code>new</code> referring to the class name or the method name?</p><p>If it refers to the class name, the class itself has no parameters, and no return value. Moreover, the behavior of the <code>new</code> keyword in the code would be different from other statements. Additionally, the class has a default no-argument constructor. If <code>new</code> is for the class, why do we need the default constructor?</p><p>If it refers to the function name, the constructor has no return value. As in the code above, it’s clear that <code>new Test(1)</code> is assigned to <code>Test* test</code>.</p><p>Why don’t constructors have return values? Because when a constructor executes, it tells the compiler how much space to allocate in memory, initializes member variables, determines the address of <code>this</code>, and after doing these things, it doesn’t allow the user to customize the return type? Because the return value of the constructor is always and must be itself, it’s not transparent to the user (why does the compiler “presumptuously” do this)?</p><p>Why don’t constructors have return values? I don’t know the answer to this question, nor am I very interested in knowing. But this question has given me great inspiration and a lot of shock. The phrase “new member function” is really a novel idea. We take too many things for granted, as a matter of course, thinking it should be that way, but rarely ask why it is that way, and rarely seriously think about and understand many things.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Just now, a classmate asked me a question: What does it mean to &lt;code&gt;new&lt;/code&gt; a member function in C++?&lt;/p&gt;
&lt;p&gt;…I thought to myself,</summary>
        
      
    
    
    
    
    <category term="design" scheme="https://en.smallyu.net/tags/design/"/>
    
  </entry>
  
  <entry>
    <title>About Human Abilities, Experiences, and...</title>
    <link href="https://en.smallyu.net/2020/05/03/About%20Human%20Abilities,%20Experiences,%20and.../"/>
    <id>https://en.smallyu.net/2020/05/03/About%20Human%20Abilities,%20Experiences,%20and.../</id>
    <published>2020-05-03T13:50:15.000Z</published>
    <updated>2025-08-06T10:38:27.632Z</updated>
    
    <content type="html"><![CDATA[<p>Lately, there doesn’t seem to be anything particularly special going on. The amount of work has increased compared to before, occupying a lot of my time. In the gaps outside of work, it seems I don’t have much energy to focus on learning.</p><p>The content on this blog roughly falls into two or three categories: one is technical stuff I’ve thought about or learned, another is work and life-related things that I’ve encountered or thought about which sparked some insights, and the third category might just be daily logs, fantasies, and pure records of what happened. Ideally, the frequency of blog updates would be about every two weeks to a month; too short a time frame leaves little to say, and too long feels a bit too long. If there’s nothing to write or I don’t feel like writing for a long stretch, it means something dangerous has happened—either I’ve become lax in thinking or there are abnormal psychological issues. So, the blog can also serve as a mirror for self-reflection.</p><p>Lately, I’ve been struggling with a point that is difficult to conclude.</p><p>(1)</p><p>A while back on a weekend, a grad school friend asked me a basic operational question. It was about a C++ project cloned from Github that threw errors when opened in VS2012, saying it couldn’t find files. I rarely touch C++, but I quickly looked into it. The project is called <a href="https://www.wxishiko.com/wxCharts/">wxCharts</a>, a chart UI library, and almost none of the header files could be found during compilation. His professor told him to add external dependency libraries in the settings, but even after doing so, the header files were still missing.</p><p>I suggested picking one of the missing files and searching for it on the disk, but no results…</p><p>Later, I checked wxCharts’ official website and found out it relies on <a href="https://www.wxwidgets.org/">wxWidgets</a>. wxWidgets is a GUI library, and wxCharts is just a component of this GUI library. After testing locally, I found that compiling and installing wxWidgets allowed wxCharts to compile successfully.</p><p>The cause was found, but he said he had already installed wxWidgets. I wasn’t sure if the <code>build</code> in Windows VS was the same as <code>make install</code> in Linux, so I suggested a few options: one, copy the wx folder under wxWidgets to wxCharts (the wx folder is the default dependency folder for the project, similar to the src directory in a Go project); two, try placing the wxCharts source code into the wxWidgets project and see if it compiles; three, reinstall wxWidgets, making sure to install it globally and configure it in the environment variables.</p><p>After some fuss, we finally managed to locate the header files. There was an issue with the path configuration for external dependencies, using the wrong environment variable as the path, and redundantly referencing incorrect paths. But compilation still failed, as certain files couldn’t be found. More tweaking revealed that besides the header files, dynamic dependency libraries also needed to be included, and the directories for the production and debug versions were different, with the debug version having a ‘d’ suffix…</p><p>The problem we faced was straightforward—missing project dependencies. If it had been a Java project, it would have been a piece of cake (although even some colleagues with years of experience sometimes struggle with such low-level issues). This friend is someone I get along well with; we used to play “Honor of Kings” together in college. I have a bit of an understanding of his abilities—he might be strong academically but is almost a complete novice in computer science. Yet, academically, his undergraduate performance wasn’t as good as mine. It was his sincere effort during the year or so of grad school prep that made the difference.</p><p>A minor realization I had was that he’s now a grad student at a fairly decent 211 university, while my degree is still from a non-prestigious undergrad institution. Our educational levels differ significantly. As for abilities, I can only say that once there was an opportunity to go to grad school in front of me, I didn’t cherish it. Even after losing it, I didn’t feel a tinge of regret. If I could go back, I’d still make the same decision. If I had to put a time frame on it, I’d hope it’s in my lifetime.</p><p>(2)</p><p>I once mentioned a colleague who constantly perplexes me with their practical skills and sense of responsibility. Yet, after encountering a few issues, I realized they indeed have rich development experience that’s hard to refute.</p><p>We faced a rather simple recursion problem. I hadn’t figured out whether an object passed into a function is passed by value or reference.</p><pre><code class="JavaScript">function a() &#123;    obj = &#123; &quot;a&quot;: 1 &#125;    b(obj)    console.log(obj)&#125;function b(obj) &#123;    // Method 1    obj = 1    // Method 2    obj = &#123; &quot;a&quot;: 2 &#125;    // Method 3    obj.a = 2&#125;</code></pre><p>I had to clarify this to use recursion correctly. Method 1 assigns a new value to the object, Method 2 assigns a new object to the parameter, and Method 3 changes the object’s property. At the time, I had no concept and wondered if it could be solved using the prototype chain. I knew she wasn’t clear on this either, but she tentatively mentioned whether it was related to the stack and heap, then dropped it uncertainly.</p><p>I thought it was unrelated; I thought she was just guessing. I was wrong.</p><p>Objects are passed by reference, no doubt about that. However, whether the object’s properties change depends on whether the change is in the stack space or heap space. Assigning a new value to an object, whether simple or complex, will point the object’s variable to a new stack address, so the object’s properties won’t change. Using Method 3 changes the contents of the heap the object points to, thus changing the original object’s properties.</p><p>So, in fact, experience is useful and difficult to surpass easily, as experience cannot be gained through shortcuts.</p><p>(3)</p><p>Abilities are acquired through experience. Strong abilities can help acquire more advanced experiences more quickly and efficiently, which in turn strengthens abilities.</p><p>Perhaps abilities and experience are complementary, similar to the so-called “experience and insight.” Here, “abilities” indeed have a hint of “insight.” Sometimes during recruitment, it feels like the recruiters emphasize years of experience, as if hiring more experienced people is a bargain compared to those with less experience. But, regarding abilities and experience…</p><p>Recently, I downloaded a music composition software and tried it out. Composing music is actually very challenging, with skill requirements vastly different from programming despite the similar term. Now, with various training courses and online classes, programming has virtually no entry barrier. As we enter an era of “programming for everyone,” how will we face this world? Future programming might not permeate life with MVC, ORM, etc., but an IoT device, automated equipment, or future versions of iOS Shortcuts might still need a bit of “programming” logic to better suit human personalized living habits.</p><p>PS:</p><img src="chortcut.png" width="30%" /><center>iOS 13's Shortcuts already support basic statement logic</center>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Lately, there doesn’t seem to be anything particularly special going on. The amount of work has increased compared to before, occupying</summary>
        
      
    
    
    
    
    <category term="Learning" scheme="https://en.smallyu.net/tags/Learning/"/>
    
  </entry>
  
  <entry>
    <title>Understanding the Actor Model Through Erlang</title>
    <link href="https://en.smallyu.net/2020/03/31/Understanding%20the%20Actor%20Model%20Through%20Erlang/"/>
    <id>https://en.smallyu.net/2020/03/31/Understanding%20the%20Actor%20Model%20Through%20Erlang/</id>
    <published>2020-03-31T04:47:59.000Z</published>
    <updated>2025-08-06T10:38:28.714Z</updated>
    
    <content type="html"><![CDATA[<p>The Actor Model is a broad concept that was proposed in the last century. It views an actor as a whole, which can be an atomic variable, an entity, or a thread. Actors communicate with each other, and each actor has its own state. Upon receiving messages from other actors, it can change its state or perform other actions. When discussing the Actor Model, examples such as Erlang, Elixir, or Akka are often cited as they all implement the Actor Model to some extent.</p><p>Front-end MVVM frameworks like React and Vue have their own data flow management frameworks, such as Redux and Vuex. These frameworks include concepts like Action, Reducer, and State, which can sometimes be confusing. As front-end development becomes more complex, some elements may be borrowed from the back-end, like TypeScript’s type system. I am curious if there is a conceptual similarity between actions in these front-end frameworks and the Actor Model in the back-end.</p><p>In essence, actions are simple, and the underlying code is also simple. In a reducer, different operation types are judged using switch, and different methods are called. The simplest form is a method action that changes the value of the global variable state. The Redux documentation states that its design is derived from the Flux architecture. The origin of the Flux architecture is unclear, but it is unlikely to be inspired by the Actor Model.</p><pre><code class="JavaScript">let state = nullfunction action(val) &#123;  state = val&#125;</code></pre><p>Erlang is an old programming language and is a typical language inspired by the Actor Model. Understanding concepts in isolation can be abstract, so starting with a specific, concrete language might help explore these theories. For example, learning FP through Haskell is much more effective than through Java. Elixir is a language based on the Erlang VM, and its relationship with Erlang is similar to that of Scala and Java, making Erlang’s syntax relatively simple and clean.</p><h3 id="Erlang"><a href="#Erlang" class="headerlink" title="Erlang"></a>Erlang</h3><p>Erlang code blocks end with <code>.</code>. A code block can be a single line or multiple lines, where <code>.</code> functions similarly to <code>&#125;</code>, as Erlang does not have <code>&#123;</code>. Statements within the code block end with <code>,</code>, indicating the end of a statement, akin to <code>;</code> in some languages.</p><p>Erlang defines a program file as a module, and the module can be loaded in the command line using <code>c(test).</code>. The module name must match the file name:</p><pre><code class="Erlang">-module(test).</code></pre><p>The header of the file needs to define the functions exported by the program, which are the module’s entry points:</p><pre><code class="Erlang">-export([start/0, ping/3, pong/0]).</code></pre><p>Here, three functions are exported. Brackets indicate an array, and the numbers <code>/0</code> and <code>/3</code> indicate the number of parameters for each function. The start function serves as the main entry point of the program, responsible for starting the entire program. The ping function sends messages, and the pong function receives messages and responds.</p><p>Erlang has a concept of <code>process</code>, which is neither a thread nor a computer-level process; it is just a <code>process</code>. We will start two processes: one for ping and one for pong, simulating message transmission and interaction. This can be likened to starting two threads, one for production and one for consumption.</p><pre><code class="Erlang">ping(0, Pong_PID, StartTime) -&gt;     Pong_PID ! &#123;finished, StartTime&#125;;</code></pre><p>This is the first part of the ping function, a branch that accepts three parameters. If the first parameter is 0, the statements within this function will be executed. The second parameter, <code>Pong_PID</code>, refers to the process containing pong, and the third parameter is the program’s start time, used to record the program’s runtime. The function body has a single statement: <code>!</code> sends a message, meaning the data <code>&#123;finished, StartTime&#125;</code> is sent to the process with ID <code>Pong_PID</code>, where finished is an <code>Atom</code> that acts as an identifier sent to pong. An Atom is one of Erlang’s data types, akin to an undeclared constant.</p><pre><code class="Erlang">ping(N, Pong_PID, StartTime) -&gt;     Pong_PID ! &#123;ping, self()&#125;,    receive        pong -&gt;             io:format(&quot;~w~n&quot;, [N])    end,    ping(N - 1, Pong_PID, StartTime).</code></pre><p>This is the second part of the ping function. If the first parameter received by the function is not 0, the statements within this function will be executed. This part of the function sends the data <code>&#123;ping, self()&#125;</code> to pong upon receiving the request, where the identifier is <code>ping</code> instead of <code>finished</code>. The second parameter, <code>self()</code>, returns the current process’s ID, which is passed to pong for pong to reply to the message. Pong will selectively use the second parameter.</p><p>After sending the data to pong, there is a <code>receive ... end</code> code block that blocks the current program’s execution until the current process receives data. This block performs a simple pattern matching, where <code>pong</code> is an Atom variable. If the pong identifier is received, the statement after <code>-&gt;</code> will be executed. <code>io:format</code> is a simple formatted output that prints the value of N to the screen.</p><p>After receive ends, ping calls itself recursively until N is 0, meaning the interaction between ping and pong continues N times, and the number of interactions is printed by <code>io:format</code>. These are the two branches of the ping function. The pong function is similar to the ping function:</p><pre><code class="Erlang">pong() -&gt;    receive        &#123;finished, StartTime&#125; -&gt;             io:format(&quot;The End&quot;);            io:format(&quot;~w~n&quot;, [erlang:timestamp()]);            io:format(&quot;~w~n&quot;, [StartTime]);        &#123;ping, Ping_PID&#125; -&gt;            Ping_PID ! pong,            pong()    end.</code></pre><p>The pong function does not have branches in terms of parameters, but there are two matches within the receive block. If the finished identifier is received, the start and end times are printed, and the program ends. If the ping identifier is received, a pong response is sent to Ping_PID, which is the ping process, and then pong calls itself. This means pong first sends a message and then waits for a reply. If no reply is received, it waits indefinitely.</p><pre><code class="Erlang">start() -&gt;    Pong_PID = spawn(test, pong, []),    spawn(test, ping, [10, Pong_PID, erlang:timestamp()]).</code></pre><p>Finally, the start function is the program’s entry function, spawning two processes that run independently. When the first parameter passed to ping is 10, the interaction between ping and pong continues 10 times.</p><h3 id="Interaction-Speed"><a href="#Interaction-Speed" class="headerlink" title="Interaction Speed"></a>Interaction Speed</h3><p>I once heard a so-called “expert” say that to improve computer speed, we should focus on CPU utilization because actors are fast. Why are they fast? Because an actor is a whole that runs on a single core, eliminating the need for inter-core communication. The accuracy of this statement may be debatable, but I am curious if actors are truly fast, which led me to test the speed of actors.</p><p>It must be noted that I am well aware this testing method is unreliable.</p><p>In the Erlang program, two processes communicate with each other, testing communication times of different magnitudes and recording the program’s execution time. For comparison, two threads are started in Java, using thread sleep and wake-up for inter-thread communication. Similarly, two goroutines communicate in Go. As for Akka, which also represents the Actor model, a test program was also written. The table below shows the test results, with the number of times ranging from 1 to 100 million, and the time unit is milliseconds.</p><table><thead><tr><th>Number of Times</th><th align="right">Erlang</th><th align="right">Java</th><th align="right">Go</th><th align="right">Akka</th></tr></thead><tbody><tr><td>1</td><td align="right">0</td><td align="right">0</td><td align="right">0</td><td align="right">3</td></tr><tr><td>10</td><td align="right">0</td><td align="right">1</td><td align="right">0</td><td align="right">7</td></tr><tr><td>100</td><td align="right">3</td><td align="right">4</td><td align="right">1</td><td align="right">17</td></tr><tr><td>1,000</td><td align="right">26</td><td align="right">30</td><td align="right">4</td><td align="right">83</td></tr><tr><td>10,000</td><td align="right">610</td><td align="right">168</td><td align="right">42</td><td align="right">225</td></tr><tr><td>100,000</td><td align="right">2,783</td><td align="right">1,295</td><td align="right">404</td><td align="right">674</td></tr><tr><td>1,000,000</td><td align="right">27,085</td><td align="right">11,300</td><td align="right">4489</td><td align="right">3515</td></tr><tr><td>10,000,000</td><td align="right">273,912</td><td align="right">107,673</td><td align="right">40335</td><td align="right">29368</td></tr><tr><td>100,000,000</td><td align="right">2,851,680</td><td align="right">1,092,879</td><td align="right">482196</td><td align="right">300228</td></tr></tbody></table><p>Initially, I tried rendering this data using Echarts for better comparison, but the resulting line chart was not user-friendly.</p><p>Overall, Erlang is the slowest, possibly due to its age and lack of optimization. Elixir might perform better. Comparatively, Java is faster than Erlang, and Go is faster than Java, which seems expected. Java’s time consumption is one-third of Erlang’s, and Go’s is half of Java’s.</p><p>The most surprising finding is that Akka’s actor speed is faster than Go’s goroutines. Before 1,000 interactions, Akka is slower than Erlang. At the 10K scale, it surpasses Erlang, at 100K, it surpasses Java, and at 1M, it surpasses</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;The Actor Model is a broad concept that was proposed in the last century. It views an actor as a whole, which can be an atomic variable,</summary>
        
      
    
    
    
    
    <category term="Programming Languages" scheme="https://en.smallyu.net/tags/Programming-Languages/"/>
    
  </entry>
  
  <entry>
    <title>An Interactive Method for Side Navigation Bar</title>
    <link href="https://en.smallyu.net/2020/03/21/An%20Interactive%20Method%20for%20Side%20Navigation%20Bar/"/>
    <id>https://en.smallyu.net/2020/03/21/An%20Interactive%20Method%20for%20Side%20Navigation%20Bar/</id>
    <published>2020-03-21T09:59:37.000Z</published>
    <updated>2025-08-06T10:38:27.634Z</updated>
    
    <content type="html"><![CDATA[<p>Recently, I’ve seen several demo projects of management systems. Combining this with some inconvenient aspects encountered during development, I noticed that most websites’ side navigation bars expand on click and collapse on click.</p><img src="classical.gif" width="20%"><p>This interaction feels a bit cumbersome:</p><ul><li>If the location of the submenu is unknown, you need to click each item to find the desired page.</li><li>If the location of the submenu is known, you still need to click the parent menu to see the desired submenu.</li><li>Without clicking each item, you can’t know what submenus are available.</li><li>After expanding the submenu, you need to click the parent menu each time to collapse it.</li></ul><p>Then I thought, could the click event be replaced with a hover event? As long as the mouse hovers over it, the menu will automatically expand without needing a click. However, simply using hover to expand requires considering the issue of inconsistent menu lengths. If the next menu is shorter than the current menu, the mouse leaving the current menu will cause the current menu to collapse, and the mouse will directly skip over the next shorter menu.</p><img src="problem.gif" width="20%"><p>As shown in the image, Column 2 has a length of 4, and Column 3 has a length of 2. When the mouse moves down from Column 2, the moment it leaves Column 2, Column 2 retracts, causing the mouse to hover directly over Column 4 without passing Column 3, which is illogical and contradicts user expectations. Logically, Column 3 should follow Column 2.</p><p>To address this issue, the interaction can be designed such that when the mouse leaves Column 2, Column 2 doesn’t retract until the mouse leaves the entire navigation bar. If a parent menu is clicked while a submenu is expanded, that parent menu won’t retract even if the mouse leaves the navigation bar.</p><img src="solution.gif" width="20%"><p>Below is a demo page embedded via iframe, allowing for a comparison of the two side navigation bar interaction methods (there are no hover events on mobile). I prefer more flexible interactions; in the second method, clicking the parent menu also expands and collapses the list, adding hover auto-expand functionality on top of the first method.</p><div align="center"><iframe src="/html/sider_bar_demo.html" width="400px" height="580px" frameborder="0" scrolling="yes" style="border: 5px double #e4e4e4;"> </iframe></div><p>Compared to the hover auto-expand without retraction method, a more advanced approach is that when the mouse moves from top to bottom, the submenu automatically expands but doesn’t retract. When the mouse moves from bottom to top, the submenu automatically expands and retracts. Whether the submenu should retract depends on whether it affects the user’s next operation. However, implementing such an effect is somewhat complex. For a navigation bar on a webpage, continuously monitoring the mouse coordinates entails a higher development and maintenance cost.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Recently, I’ve seen several demo projects of management systems. Combining this with some inconvenient aspects encountered during</summary>
        
      
    
    
    
    
    <category term="Design" scheme="https://en.smallyu.net/tags/Design/"/>
    
  </entry>
  
  <entry>
    <title>Three Minor Issues in Java Project Development</title>
    <link href="https://en.smallyu.net/2020/02/26/Three%20Minor%20Issues%20in%20Java%20Project%20Development/"/>
    <id>https://en.smallyu.net/2020/02/26/Three%20Minor%20Issues%20in%20Java%20Project%20Development/</id>
    <published>2020-02-26T09:37:42.000Z</published>
    <updated>2025-08-06T10:38:28.713Z</updated>
    
    <content type="html"><![CDATA[<p><strong>1. Is an Auto-Increment Primary Key Necessary in MySQL?</strong></p><p>Sometimes we use a meaningful field as the primary key, such as using the username instead of a meaningless auto-increment id. One of the benefits of this approach is leveraging the uniqueness of the primary key to ensure the uniqueness of the username. If duplicate data is attempted to be inserted, the database will throw a “Duplicate entry * for key PRIMARY” error.</p><p>The problem with relying on this “benefit” is whether we can and should rely on the default characteristics of the primary key (non-repetitive fields) to meet our business needs (non-repetitive fields). In fact, “non-repetitive” is a feature of unique indexes, not the primary key. The primary key field will automatically have a unique index.</p><p>One of the inconveniences of leveraging this “benefit” is that the data table lacks a field that represents the “data row sequence.” Oracle has something like rownum, but MySQL does not, so you have to use a script to implement it. If you need to traverse the table in segments, it’s difficult to operate without the concept of rows.</p><p>The “Alibaba Java Development Manual” clearly requires tables to have an id field. They may not necessarily be right, but I believe their reasons must be sufficiently convincing.</p><img src="id.png" width="90%" height="50%" /><p><strong>2. Map or Bean</strong></p><p>When querying data with MyBatis, the return type can be either List<Map> or List<Bean>. Here, Bean refers to a Data Object (DO).</p><p>The benefits of using a Bean are obvious. By entering the object name and pressing the next dot, IDEA will automatically pop up the Bean’s getter and setter methods, making the table’s properties clear at a glance. Whether getting or setting values, it is user-friendly.</p><p>One potential issue with using a Bean is if the table structure changes, such as deleting a field. Correspondingly, the Bean class would need to delete an attribute and its getter and setter methods. Any place in the program that uses this field will need to be modified. If not, the program will fail to compile.</p><p>We often encounter this situation during development. Debugging Class A, after changing a common COM class, BCDEF… all report errors during compilation. This is frustrating because I only want to confirm if the issue with Class A is caused by the COM class, but due to this dependency, I have to try other methods.</p><p>If facing system modifications, integration, or refactoring, Beans will also expose the same problems. In a recent project, to reuse as much of the original system as possible and make minimal changes, I had to use Bean.username to store the actual value of Bean.phoneNumber. All the various utility classes (encryption and decryption, local cache, etc.) of the original system depend on the Bean. Once involving Bean modifications, either a large-scale change is needed, or none at all.</p><p>Using a Map can slightly alleviate the issues brought by Beans, especially when handling value retrieval properly. For example, <code>String.valueOf(map.get(&quot;&quot;))</code> can avoid the dreaded null pointer exception, allowing the program to start normally even if the value is null. The places needing changes can get and set as desired without being restricted by Bean getter and setter methods.</p><p>In addition, both Map and Bean are essentially encapsulations of properties.</p><p><strong>3. Annotations or XML</strong></p><p>Spring’s IOC supports both annotations and XML, and MyBatis SQL similarly supports both.</p><p>In the past, Java projects were often packaged into WAR or JAR files and run in containers like Tomcat or Resin. The container would automatically extract the package into class files and resource files, including XML. One advantage of using XML configuration is that you can directly modify the XML in the production environment and restart the project to complete the operation without recompiling Java files into class files, packaging, extracting, replacing, and going through the deployment process—branching, development, testing, compilation, deployment, merging baselines, step-by-step emails.</p><p>I think times have changed. With continuous integration, automated operations, properties, and YML, XML doesn’t seem as important anymore.</p><p>For MyBatis SQL, there is an internal XML parser. XML serves as a DSL to achieve dynamic SQL statements through configuration. If using annotations, writing SQL in the provider, we lose the XML parser’s functionality. However, losing this capability also grants us freedom. Facing string-based SQL statements, we can completely encapsulate our own parser.</p><p>Interestingly, foreign developers seem to prefer annotations, while domestic developers tend to use XML. Many foreign authors use annotations in their books, while most domestic blog articles use XML configuration in tutorials. This is somewhat similar to the situation with front-end frameworks React and Vue. Enterprises and developers with stronger technical skills prefer React because JSX is more like a programming language with more room for creativity. Vue is favored by enterprises and developers with weaker technical skills because it’s easier to get started and simpler to develop. If you’ve used Vue, you’ll understand that developing with it doesn’t feel like programming; it’s more like a product of software industrialization.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;&lt;strong&gt;1. Is an Auto-Increment Primary Key Necessary in MySQL?&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Sometimes we use a meaningful field as the primary key,</summary>
        
      
    
    
    
    
    <category term="Programming Languages" scheme="https://en.smallyu.net/tags/Programming-Languages/"/>
    
  </entry>
  
  <entry>
    <title>Positioning of Programmers</title>
    <link href="https://en.smallyu.net/2020/01/11/Positioning%20of%20Programmers/"/>
    <id>https://en.smallyu.net/2020/01/11/Positioning%20of%20Programmers/</id>
    <published>2020-01-11T10:19:45.000Z</published>
    <updated>2025-08-06T10:38:27.727Z</updated>
    
    <content type="html"><![CDATA[<p>One terrifying thing is when programmers no longer focus on code, software, systems, and architecture, but rather on products, operations, and sales. Their outlook shifts from improving code quality, iterating better software, and making better engineering to enhancing documentation output and team morale.</p><h3 id="startup-and-996"><a href="#startup-and-996" class="headerlink" title="startup and 996"></a>startup and 996</h3><p>The company begins to advocate for an entrepreneurial mindset. In a startup, everyone must work hard together to achieve big things. The BOSS says, he returned to the company late one day and saw certain people still working past 10 PM. Everyone should be like that; we have to do it this way. If you can’t keep up with our pace due to health or other reasons, you might not fit well with our team. We all need to strive together; we need to do 10106. If we don’t do it this way, the company will die.</p><p>Hearing this, I couldn’t help but laugh silently. To say something that may not align with common values, I know this mentality is wrong. If the boss saw such thoughts, I’d have to talk to HR tomorrow, which would show a lack of responsibility and professional ethics. But frankly, if the company dies, what does it have to do with me?</p><p>It’s all about painting a rosy picture. Normally, you hear people complain about the boss making big promises that seem unattainable after joining, and then post online not to trust the boss’s words. Don’t believe in benefits and bonuses until they’re in your hands. Our situation seems different; if we don’t work hard, the company will die? I’ve heard a saying before: everyone tells us to work hard, but no one tells us what we’ll get after working hard. If the company dies, won’t we just go work elsewhere?</p><p>At the annual meeting’s Q&amp;A session, the big BOSS caught onto the term “enjoy the dividends,” suggesting that dividends are not given by the company but are earned by bringing corresponding value to the company. Often, the company’s idea is, you need to give me 20 units of work, and I’ll give you 10 units of profit. Employees think, you give me 10 units of money, I’ll do 10 units of work, and if you give me 5 more units, I’ll put in 5 more units of effort.</p><p>996 is a similar issue. Why are we 10106? Because we start work at 9:30 AM, and by the time we open our computers and have a morning meeting, it’s around 10 AM, so it’s 1010, not 99. Regarding 996, one saying is that some employees have a mentality of striving for performance, cultivated from a culture of being rewarded with small red flowers from childhood, leading to the belief that “effort will bring rewards.” Many bosses indeed buy into this.</p><p>Yesterday, I heard another perspective. Our BOSS mentioned 10106 but won’t issue an official policy notice because it violates labor laws. This confused me; should we do 10106 or not? I consulted slightly experienced employees and was told the boss likes “smart” employees. In other words, the boss brought up the matter, and it’s up to you to gauge how to handle it.</p><h3 id="Overtime"><a href="#Overtime" class="headerlink" title="Overtime"></a>Overtime</h3><p>Sometimes, when projects are tight, bugs occur suddenly, or there’s a launch or work error, occasional overtime is normal; there’s busy and idle times. Some companies require frequent overtime, with endless work, known as the 996 work system. Generally speaking, 965 and 996 correspond to different salary levels. The conflict arises when companies want to hire 996 people with 965 salaries, and employees want 996 salaries for 965 work.</p><p>There are instances where the boss doesn’t require overtime, but some people still work late. Each person’s division of labor and task volume differs, so does the speed of completion. It depends on the situation. If your efficiency is lower than others, overtime is understandable. The problem arises when others frequently work late due to inefficiency, and you, having finished your tasks, don’t work overtime. The boss might then focus on work hours, questioning if matching others’ work hours would yield more output. A wise leader should discern true work capability and judge output based on work volume, not hours. The worst scenario is the leader pretending to be ignorant of the real situation.</p><p>Another case is when the boss asks you to stay a bit longer. There might not be urgent tasks needing overtime, but why leave on time when others stay late? Everyone else is working late; why are you special? The boss might think you should put in more work since overtime should result in more output, possibly rooted in the mindset of taking advantage in Chinese labor culture.</p><p>In reality, 996 might not positively impact work output. If everyone leaves on time, I’d feel awkward staying late (seriously). If others can finish their work on time, needing overtime to complete tasks might reflect poorly on one’s ability. Therefore, I’d try to complete my work within office hours. If daily overtime is required, it might lead to a more relaxed work pace during regular hours, knowing that overtime will be needed anyway, thus leaving a good impression on the boss by working late.</p><h3 id="Technical-People"><a href="#Technical-People" class="headerlink" title="Technical People"></a>Technical People</h3><p>The company starts advocating for a “sales-oriented” approach because sales directly influence revenue, which the boss values. In a performance review, I first learned about the company’s overall picture from sales and operations. During the review, the BOSS said, “Knowing commonly used models and algorithms in machine learning is quite specific and ordinary. We need to…,” referring to content I had mentioned in my review materials a few days prior.</p><p>Actually, technology is not crucial, especially in a sales-oriented company. The specific technology used doesn’t matter as much as closing deals, convincing customers, and making money for the company. In the broader society, technology needs to be advanced and new enough to have a foothold. Machine learning, talked about for over a decade, is indeed quite ordinary and mediocre in its common usage, especially if it doesn’t bring substantial benefits.</p><p>Since implementing OKR, our performance plans have two features: they must have goals and results, and these goals and results focus more on self-improvement than work content. Self-improvement mainly refers to output, such as writing internal newsletters, patents, sharing technology, etc., especially things that can help with work. Ironically, we lack a strong technical atmosphere, with only a few key people writing actual code. Performance management shows that leaders don’t care much about work-related content like establishing project and development standards, requirements, development, reviews, testing, etc. They care more about personal achievements.</p><p>Often, the situation is the company cares about “what can you bring to the company?” while employees think, “what does the company need me to do?”</p><p>Performance reviews are the same; we have to write about work-related but also non-work content. Deep learning is a field worth learning and researching. Even common models and algorithms require at least a year to understand from principles to engineering. Currently, my work involves application layer development, such as CRUD operations, while the department’s technical theme is blockchain, so I put machine learning in the outlook section.</p><p>Personally, machine learning is a significant step. It has a certain threshold. I have tried multiple times before, abandoning after watching Andrew Ng’s course and Stanford’s image recognition class. There’s a view that machine learning is the development of calculus in modern computer technology, with its theoretical foundation in mathematics. Some also say blockchain is a small scam, while AI is a big scam… Regardless of the scam, it’s something that needs to be learned.</p><h3 id="Programmers"><a href="#Programmers" class="headerlink" title="Programmers"></a>Programmers</h3><p>Compared to sales or operations, one characteristic of programmers is less reliance on external resources, connections, market, regulation, and business. Technology changes in form but essentially involves operating a computer to perform calculations. Application layer developers should complete development tasks as required by the schedule, ensuring code quality is their professional responsibility. Improving system architecture skills is necessary. Skilled Coders can efficiently use toolchains, while excellent Coders can optimize algorithms, improving program efficiency and system performance.</p><p>Sorry, I am a Coder, and I don’t feel ashamed. (<a href="https://www.ruanyifeng.com/blog/2011/10/dont_call_yourself_a_programmer.html">@Don’t call yourself a programmer</a>)</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;One terrifying thing is when programmers no longer focus on code, software, systems, and architecture, but rather on products,</summary>
        
      
    
    
    
    
    <category term="Work" scheme="https://en.smallyu.net/tags/Work/"/>
    
    <category term="Programmer" scheme="https://en.smallyu.net/tags/Programmer/"/>
    
  </entry>
  
  <entry>
    <title>What is Rust&#39;s Ownership?</title>
    <link href="https://en.smallyu.net/2019/12/21/What%20is%20Rust&#39;s%20Ownership_/"/>
    <id>https://en.smallyu.net/2019/12/21/What%20is%20Rust&#39;s%20Ownership_/</id>
    <published>2019-12-21T15:06:28.000Z</published>
    <updated>2025-08-06T10:38:28.718Z</updated>
    
    <content type="html"><![CDATA[<p>Rust is memory safe. Facebook’s Libra uses Rust for development and has introduced a new programming language called Move. Move’s most significant feature is managing digital assets as resources, meaning they can only be moved, not copied, much like paper money, ensuring the safety of digital assets. This idea in Move is not unique; Rust has long used this approach to manage memory, making Rust memory safe. Memory in Rust is managed by the ownership system.</p><h3 id="Java’s-Reference-Counting"><a href="#Java’s-Reference-Counting" class="headerlink" title="Java’s Reference Counting"></a>Java’s Reference Counting</h3><p>Garbage collection comes in many forms, and ownership is one of them. Java uses reference counting, which has a well-known flaw: it cannot reclaim memory space involved in circular references. The basic rule of reference counting is that each time a memory reference is made, the count increases by one, such as instantiating an object or assigning the object to another variable. When a variable reference is canceled, the corresponding count decreases by one until the reference count is zero, at which point the space is freed.</p><pre><code class="Java">class Test &#123;    Test ref = null;&#125;Test a = new Test(); // a&#39;s count increases by oneTest b = new Test(); // b&#39;s count increases by one// At this point, a&#39;s count is 1, b&#39;s count is 1a.ref = b;           // a&#39;s count increases by one because ref is a&#39;s class variableb.ref = a;           // b&#39;s count increases by one because ref is b&#39;s class variable// At this point, a&#39;s count is 2, b&#39;s count is 2a = null;            // a&#39;s count decreases by one because a&#39;s reference is releasedb = null;            // b&#39;s count decreases by one because b&#39;s reference is released// At this point, a&#39;s count is 1, b&#39;s count is 1</code></pre><p>Therefore, when the references of a and b are released, their counts are still 1. To decrease a.ref’s count by one, a.ref needs to point to null. Does this need to be manually set to null? Of course not; Java has no concept of manually releasing memory space. Generally, a.ref’s object (b’s space) is released (count is 0), and a.ref’s count automatically decreases by one, becoming 0. However, because of the circular reference, b needs a’s count to become 0 for b’s count to become 0. But for a to become 0, b must first become 0. This is essentially a deadlock.</p><p>Does this have anything to do with Rust’s ownership? Of course not…</p><h3 id="Ownership"><a href="#Ownership" class="headerlink" title="Ownership"></a>Ownership</h3><p>Ownership has three basic rules:</p><ul><li>Each value has a variable <code>owner</code>.</li><li>Only one <code>owner</code> exists at a time.</li><li>When the <code>owner</code> leaves the scope, the value’s memory space is released.</li></ul><p>The scope is generally defined by <code>&#123;&#125;</code>, similar to conventional scope concepts.</p><pre><code class="Rust">&#123;                       // s is not yet declared    let s = &quot;hello&quot;;    // s is available&#125;                       // s has left the scope</code></pre><p>Rust’s variable types are divided into simple types and complex types, similar to ordinary variables and reference variables. Due to ownership, when simple types are assigned, the value is copied, but complex types have their references directly reset to new reference variables, rendering the original variable unusable.</p><pre><code class="Rust">let x = 5;let y = x;                        // y is 5, x is still 5let s1 = String::from(&quot;smallyu&quot;);let s2 = s1;                      // s2 is &quot;smallyu&quot;, s1 is no longer usable</code></pre><p>During assignment, s2’s pointer first points to the string, then s1’s pointer is set to null, embodying the concept of moving. To keep s1 usable, use <code>clone</code> to copy data to s2 instead of changing the pointer’s direction.</p><pre><code class="Rust">let s1 = String::from(&quot;smallyu&quot;);let s2 = s1.clone();              // s1 is still usable</code></pre><h3 id="Functions"><a href="#Functions" class="headerlink" title="Functions"></a>Functions</h3><p>Two concepts mentioned so far are: ownership releases memory space after leaving the scope, and complex type variables are passed in the program by moving. Combining these two features leads to situations like this:</p><pre><code class="Rust">fn main() &#123;    let s = String::from(&quot;smallyu&quot;);    takes(s);             // s is passed to the takes function                          // After takes execution ends, s is released    println!(&quot;&#123;&#125;&quot;, s);    // s is unusable, causing a program error&#125;fn takes(s: String) &#123;     // s enters the scope    println!(&quot;&#123;&#125;&quot;, s);    // s outputs normally&#125;                         // s leaves the scope, memory space is released</code></pre><p>If s is assigned a simple type, like 5, this won’t happen. For complex type variables, once they leave the scope, their memory space is forcibly released. Currently, we can use function return values to handle this situation:</p><pre><code class="Rust">fn main() &#123;    let s = String::from(&quot;smallyu&quot;);    let s2 = takes(s);     println!(&quot;&#123;&#125;&quot;, s2);&#125;fn takes(s: String) -&gt; String &#123;     println!(&quot;&#123;&#125;&quot;, s);     s&#125; </code></pre><p>takes returns the variable unchanged, but a new variable s2 is declared to receive the returned value because s is an immutable variable.</p><h3 id="Reference-Variables"><a href="#Reference-Variables" class="headerlink" title="Reference Variables"></a>Reference Variables</h3><p>Reference variables do not trigger the ownership drop method, meaning they do not reclaim memory space when they leave the scope:</p><pre><code class="Rust">fn main() &#123;    let s = String::from(&quot;smallyu&quot;);    takes(&amp;s);    println!(&quot;&#123;&#125;&quot;, s);&#125;fn takes(s: &amp;String) &#123;    println!(&quot;&#123;&#125;&quot;, s);&#125;</code></pre><h3 id="Mutable-Variables"><a href="#Mutable-Variables" class="headerlink" title="Mutable Variables"></a>Mutable Variables</h3><p>Reference variables are read-only, so in takes, s can be accessed but not modified, such as reassigned. Mutable variables can solve this problem:</p><pre><code class="Rust">fn main() &#123;    let mut s = String::from(&quot;smallyu&quot;);    takes(&amp;mut s);    println!(&quot;&#123;&#125;&quot;, s);&#125;fn takes(s: &amp;mut String) &#123;    s.push_str(&quot;, aha!&quot;);&#125;</code></pre><p>Mutable variables have limitations: only one other variable can reference a mutable variable at a time:</p><pre><code class="Rust">let mut s = String::from(&quot;smallyu&quot;);let r1 = &amp;mut s;let r2 = &amp;mut s;println!(&quot;&#123;&#125;, &#123;&#125;&quot;, r1, r2);</code></pre><p>This will cause an error because, to ensure memory safety, a variable can only have one mutable reference. If r1 and r2 could both modify s, it would cause chaos. Therefore, if <code>r1 = &amp;s</code> instead of <code>r1 = &amp;mut s</code>, there would be no problem, as only one mutable reference is allowed.</p><h3 id="Return-Values"><a href="#Return-Values" class="headerlink" title="Return Values"></a>Return Values</h3><p>Function return types cannot be reference types, also related to ownership rules. Returning ordinary variables is like throwing the function’s contents out. If returning a reference variable, it points to something within the function, but once the function ends, everything inside is destroyed, making the reference variable invalid.</p><pre><code class="Rust">fn dangle() -&gt; &amp;String &#123;    let s = String::from(&quot;smallyu&quot;);    &amp;s;&#125; // At this point, s&#39;s memory space is released, so the return value cannot reference it</code></pre><h3 id=""><a href="#" class="headerlink" title="?"></a>?</h3><p>There’s no more content.</p><p>Recently, I watched an exciting TV show “Silicon Valley.” The writers put the main characters in many difficult situations, making them seem like their misfortunes were self-inflicted. The writers also left many cliffhangers, making the plot so intense that I felt like sending them hate mail. Putting aside the plot, the geeks portrayed in the show are really cool! Of course, ordinary people can’t participate in such high-level battles.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Rust is memory safe. Facebook’s Libra uses Rust for development and has introduced a new programming language called Move. Move’s most</summary>
        
      
    
    
    
    
    <category term="Programming Languages" scheme="https://en.smallyu.net/tags/Programming-Languages/"/>
    
  </entry>
  
  <entry>
    <title>I Personally Wrote Unmaintainable Code</title>
    <link href="https://en.smallyu.net/2019/12/15/I%20Personally%20Wrote%20Unmaintainable%20Code/"/>
    <id>https://en.smallyu.net/2019/12/15/I%20Personally%20Wrote%20Unmaintainable%20Code/</id>
    <published>2019-12-15T12:03:32.000Z</published>
    <updated>2025-08-06T10:38:27.708Z</updated>
    
    <content type="html"><![CDATA[<p>Recently, I tried some offline activities and had a few days of severe pain. Now that things have calmed down a bit, it feels like a lifetime ago. There is a project that is undergoing final acceptance, so I pulled out the code from a month or two ago to manually update some data. Looking at the code I wrote not long ago, I felt like it was from a different era. If someone else had written it, I would have immediately thought it was garbage. Since I wrote it myself, objectively speaking, it is indeed garbage.</p><p>It was a memorable day when 2019 truly began for me. I used to work with the old system’s code, where I had to start the project in resin, which took at least two minutes to compile, making it hard to debug. I used to develop and debug programs on the test server instead of releasing code, and I even encountered pitfalls while writing small tasks like batch-executing SQL. I once looked down on garbage code and developers still using Eclipse in 2019.</p><p>To this day, I have become a developer who writes garbage code.</p><h3 id="Minor-Requirements"><a href="#Minor-Requirements" class="headerlink" title="Minor Requirements"></a>Minor Requirements</h3><p>The first time I wrote garbage code, I vividly remember printing logs twice:</p><pre><code class="java">catch (e) &#123;    System.out.println(&quot;Exception caught&quot;);    logger.error(&quot;Exception caught&quot;);&#125;</code></pre><p>The number of times logger appears is the number of times println appears. This is clearly an ugly practice. At the time, the nohup.out and log folders were not in the same directory. The log folder was configured to be in a unified directory, and I wanted nohup.out to also output logs… The specific reason is a bit fuzzy now, but this was the first time my own code disgusted me. It seems I removed it in a later version, vaguely remembering it.</p><p>In the same requirement, there was a commendable and praiseworthy approach in the old boss’s code. At the time, I thought it was redundant and a bit of a challenge to authority. It turns out I was still young.</p><pre><code class="java">Can&#39;t remember the code T_T</code></pre><p>In the same requirement, I needed to implement customizable SQL statements, similar to <code>?</code> in jdbcTemplate or <code>#&#123;&#125;</code> in mybatis. I used a very crude approach:</p><pre><code class="java">// Requirementsql = update set a=&#123;a&#125;, b=&#123;b&#125;, ...// Solutionfor (i = 0; i &lt; param.num; i++) &#123;    switch(match.group()) &#123;        case &#123;a&#125;: break;        case &#123;b&#125;: break;        ...    &#125;&#125;</code></pre><p>When asked if the parameter positions could be swapped, I was still confident. Could there be more or fewer parameters?…</p><h3 id="Changing-Requirements"><a href="#Changing-Requirements" class="headerlink" title="Changing Requirements"></a>Changing Requirements</h3><p>I once saw a program with a single class in one file, which is natural. This class had only one method, which was written by a female programmer and had over a thousand lines.</p><p>My task was to add a few fields to the originally output report. Initially, it output <code>a,b</code>, and now it needs <code>a,b,c,d</code>. <code>c,d</code> was my part to implement, with logic similar to <code>a,b</code>, but from different sources and executed with different SQL queries. Ideally, modifying the SQL should suffice, but the problem was that the method of over a thousand lines had three or four nested loops, involving business operations from different banks, with variables named <code>list1, list2</code> inside and outside the loops. The final result involved accumulating <code>a,b</code>.</p><p>I chose not to touch the original program, copied it, executed it separately, and integrated the data afterward. Arrogant and proud, I didn’t want to read the garbage code. So later, one class had two methods with a thousand lines each. The issue was the constant bugs. The copied code still needed to be understood from beginning to end, and integrating the two data parts brought many unexpected problems and vulnerabilities…</p><h3 id="Perfecting-Requirements"><a href="#Perfecting-Requirements" class="headerlink" title="Perfecting Requirements"></a>Perfecting Requirements</h3><p>Another requirement was to take over a project someone else had half-finished. In 2019, someone used a template engine in Spring Boot to write pages, and I had to use jQuery and a jQuery-based mobile style library to complete the development. The interface was ugly, but more importantly, the documentation! The documentation was inconsistent! My mistake was underestimating the requirement. I should have asked when in doubt and understood each aspect before starting. The result was naturally bad, with constant revisions. No one would want to maintain that code.</p><h3 id="Constantly-Changing-Requirements"><a href="#Constantly-Changing-Requirements" class="headerlink" title="Constantly Changing Requirements"></a>Constantly Changing Requirements</h3><p>Failing to finalize requirements at the start inevitably leads to bad code. Ideally, with proper planning, ample time, and high-quality developers, various designs and patterns are naturally good. Reality is never like that.</p><p>In Vue frontend projects, there is a common practice of encapsulating axios, writing various exports in a separate api.js, and importing them in modules. Supposedly for unified API URL management or something, but in practice, it turned out to be cumbersome, causing many development inconveniences. Did it make maintenance easier? Not at all. One reason is the constantly changing requirements. If the comments in the API are not clear or accurate, extracting them separately is meaningless.</p><pre><code>// api.jsexport a = () =&gt; &#123; get(&#39;a&#39;) &#125;// model.jsimport &#123;a&#125; from api.jsa().then(res =&gt; &#123;&#125;)</code></pre><p>If the <code>a</code> function in the API doesn’t correspond exactly to route <code>a</code>, modifying api.js requires finding the corresponding function on the respective page. This is no different from writing the route directly on the page. Maybe we could try encapsulating the routing functions at the top of each module or page, making the API in the module or page autonomous.</p><p>In frontend projects, CSS is more frustrating than APIs! Even more frustrating is when the project is already mature! The same background color configuration might be written in index, common, model, and even inline styles… And the configuration content differs in each place. Background color styles are fine, but document flow, positioning, floating, and margins are troublesome. True CSS mastery lies in document flow, and if someone who doesn’t fully understand it holds up an entire project, who dares to touch that code?</p><h3 id="Requirements-Too-Lazy-to-Rewrite"><a href="#Requirements-Too-Lazy-to-Rewrite" class="headerlink" title="Requirements Too Lazy to Rewrite"></a>Requirements Too Lazy to Rewrite</h3><p>With constantly changing requirements, another phenomenon is reusing old code whenever possible to complete current requirements as quickly as possible. Since future requirements are uncertain, refactoring clean code every time would be labor-intensive and inefficient… This is definitely a path to bad code.</p><p>In backend development, there’s something I dislike: beans, also known as entities. It’s an old practice, including templated DAOs and services. What’s the point of writing IClass and then ClassImpl? Beans are not conducive to changing requirements; sometimes, using a map is better. Referring back to the project for acceptance, my garbage code was related to beans. The bean design included many fields. When requirements changed, fields changed too. Modifying it meant changing many places. Who knows if requirements will change again? So, I forcibly reused it, resulting in fields with unclear meanings and some fields completely mismatched, merely occupying space to store data.</p><p>Of course, wrong framework choices also contribute to bad code, which is due to my lack of experience. It has to be admitted that architects play a crucial role in project management.</p><h3 id="Development-Dilemmas"><a href="#Development-Dilemmas" class="headerlink" title="Development Dilemmas"></a>Development Dilemmas</h3><p>One dilemma is naming. Occasionally, I wrote the wrong interface name or copied and pasted similar logic, too lazy to change variable names, resulting in unmaintainable code. This shows that code reviews are essential in corporate development, although small companies may not have high code quality requirements. Except for code that goes live and involves online business, reviews are mandatory to avoid disasters. For ordinary development, reviews might not be as strict.</p><p>Another dilemma is module division. For instance, if page A has file upload and page B has file download, should file upload and download be in the same API path? It seems logical since they are file operations. But if other APIs are divided by page, with all interfaces of the same page under the same path, is it awkward to single out file operations? Sometimes, modules are divided by data tables, but joint table operations can complicate conventions. Mixing various rules often leads to confusion and unmaintainable code.</p><h3 id=""><a href="#" class="headerlink" title="?"></a>?</h3><p>As the year ends, I have to put a question mark on my 2019.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Recently, I tried some offline activities and had a few days of severe pain. Now that things have calmed down a bit, it feels like a</summary>
        
      
    
    
    
    
    <category term="Work" scheme="https://en.smallyu.net/tags/Work/"/>
    
  </entry>
  
  <entry>
    <title>What is a Monad in Haskell?</title>
    <link href="https://en.smallyu.net/2019/11/26/What%20is%20a%20Monad%20in%20Haskell_/"/>
    <id>https://en.smallyu.net/2019/11/26/What%20is%20a%20Monad%20in%20Haskell_/</id>
    <published>2019-11-26T05:34:02.000Z</published>
    <updated>2025-08-06T10:38:28.718Z</updated>
    
    <content type="html"><![CDATA[<p>The first time I heard about Monad was at a Scala Meetup. Later, I tried to understand the concept of Monad but was overwhelmed by various voluminous books and tutorials on Haskell. Then I came across Ruan Yifeng’s article “<a href="http://www.ruanyifeng.com/blog/2015/07/monad.html">Illustrated Monad</a>“ published in 2015. Although it was clear and easy to understand, it was detached from Haskell, and the illustrations didn’t match the concepts in the language. Ruan Yifeng’s article was translated from “<a href="http://adit.io/posts/2013-04-17-functors,_applicatives,_and_monads_in_pictures.html">Functors, Applicatives, And Monads In Pictures</a>,” which I read through.</p><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><p>Computer programs are used to control a computer to perform calculations. The objects operated on by programs are various types of values, such as numerical values. Here’s a simple value <code>2</code>:</p><img src="1.png" style="box-shadow: 0 0 0 #fff; margin-left: 0;" /><p>Using a function to process the value can return the result of the function execution, such as:</p><img src="2.png" style="box-shadow: 0 0 0 #fff; margin-left: 0;" /><p>Apart from simple numerical types, values can also be contained within some contextual environment, forming more complex value types. You can think of the contextual environment as a box, with the numerical value placed inside the box. This box as a whole is described as <code>Just 2</code>, which is a boxed <code>2</code>:</p><img src="3.png" style="box-shadow: 0 0 0 #fff; margin-left: 0;" /><p>If you are familiar with Java, you can think of this box as a wrapper class, like Integer and int, corresponding to boxed and unboxed 2.</p><h3 id="Functors"><a href="#Functors" class="headerlink" title="Functors"></a>Functors</h3><p>Facing a boxed <code>2</code>, we can’t directly apply the <code>+3</code> function to it:</p><img src="4.png" style="box-shadow: 0 0 0 #fff; margin-left: 0;" /><p>At this point, we need a function <code>fmap</code> to operate on it. <code>fmap</code> will first extract the value 2 from <code>Just 2</code>, then add 3 to it, put the result 5 back into the box, and return <code>Just 5</code>:</p><img src="5.png" style="box-shadow: 0 0 0 #fff; margin-left: 0;" /><p>How does <code>fmap</code> know how to parse <code>Just</code>? What if it was another type like <code>Only</code>, could it still parse it? That’s why Functor is needed to complete the definition of this operation.</p><p>A Functor is a type of data type:</p><img src="6.png" style="box-shadow: 0 0 0 #fff; margin-left: 0;" /><p>Functor defines the behavior of <code>fmap</code>:</p><img src="7.png" style="box-shadow: 0 0 0 #fff; margin-left: 0;" /><p><code>fmap</code> has two input parameters and one output parameter. The input parameters are a function and a boxed value, and the output parameter is a boxed value. It can be used like this:</p><pre><code class="Haskell">fmap (+3) (Just 2)-- Just 5</code></pre><p>Returning to Haskell, the Haskell “system library” has an instance of <code>Functor</code> called <code>Maybe</code>, which defines the behavior of <code>fmap</code>, specifying how to operate on values when the input parameter is of type <code>Just</code>:</p><pre><code class="Haskell">instance Functor Maybe where  fmap func (Just val) = Just (func val)  fmap func Nothing = Nothing</code></pre><p>The entire process of the expression <code>fmap (+3) (Just 2)</code> is similar to this:</p><img src="8.png" style="box-shadow: 0 0 0 #fff; margin-left: 0;" /><p>Similarly, from the definition of <code>Maybe</code>, it can be seen that if the second parameter passed to <code>fmap</code> is <code>Nothing</code>, the function will return <code>Nothing</code>. This is indeed the case:</p><img src="9.png" style="box-shadow: 0 0 0 #fff; margin-left: 0;" /><pre><code class="Haskell">fmap (+3) Nothing-- Nothing</code></pre><p>Now suppose a scenario in Java where a user uses a utility class Request to make a request to a server, and the request returns a type Response. Response is an entity class that may or may not contain the required data:</p><pre><code class="Java">Response res = Request.get(url);if (res.get(&quot;data&quot;) != null) &#123;  return res.data;&#125; else &#123;  return null;&#125;</code></pre><p>In Haskell, using <code>fmap</code> would become:</p><pre><code class="Haskell">fmap (get(&quot;data&quot;)) (Response res)</code></pre><p>Of course, Haskell doesn’t have a <code>get(&quot;data&quot;)</code> syntax. You can encapsulate the operation of getting <code>Response.data</code> as a function <code>getData</code>, then pass it into <code>fmap</code> as the first parameter.</p><p>Haskell provides a syntax sugar <code>&lt;$&gt;</code> for <code>fmap</code> to simplify its usage:</p><pre><code class="Haskell">getData &lt;$&gt; (Response res)</code></pre><p>Next, think about how Haskell functions operate on lists. The function performs calculations on each element of the list and then returns a list:</p><img src="10.png" style="box-shadow: 0 0 0 #fff; margin-left: 0;" /><p>In fact, lists are also Functors. Here is the definition of lists:</p><pre><code class="Haskell">instance Functor [] where  fmap = map</code></pre><h3 id="Applicatives"><a href="#Applicatives" class="headerlink" title="Applicatives"></a>Applicatives</h3><p><code>Applicatives</code> is another concept. We previously said that values are placed in boxes. What if functions are also placed in boxes?</p><img src="11.png" style="box-shadow: 0 0 0 #fff; margin-left: 0;" /><p>Haskell provides the operator <code>&lt;*&gt;</code> to handle functions inside boxes:</p><img src="12.png" style="box-shadow: 0 0 0 #fff; margin-left: 0;" /><p>For example:</p><pre><code class="Haskell">Just (+3) &lt;*&gt; Just 2 == Just 5</code></pre><p>Using <code>&lt;*&gt;</code> can also accomplish some interesting operations, such as multiplying and adding each element in a list:</p><pre><code class="Haskell">[(*2), (+3)] &lt;*&gt; [1, 2, 3]-- [2, 4, 6, 4, 5, 6]</code></pre><img src="13.png" style="box-shadow: 0 0 0 #fff; margin-left: 0;" /><h3 id="Monads"><a href="#Monads" class="headerlink" title="Monads"></a>Monads</h3><p>Function execution involves processing values using functions with arguments, involving three roles. <code>Functors</code> place the processed value in a box, <code>Applicatives</code> place the function in a box, and <code>Monads</code> place the function’s argument in a box. Monads have an operator <code>&gt;&gt;=</code> to achieve Monad functionality. Suppose there is a function <code>half</code> that takes a numerical value as an argument. If the value is even, it divides by 2; otherwise, it returns Nothing:</p><pre><code class="Haskell">half x = if even x  then Just (x `div` 2)  else Nothing</code></pre><img src="14.png" style="box-shadow: 0 0 0 #fff; margin-left: 0;" /><p>How do you pass a <code>Just</code> type value to <code>half</code>?</p><img src="15.png" style="box-shadow: 0 0 0 #fff; margin-left: 0;" /><p><code>&gt;&gt;=</code> can solve this problem:</p><pre><code class="Haskell">Just 3 &gt;&gt;= half-- Nothing</code></pre><p>The <code>&gt;&gt;=</code> operator takes <code>Just 3</code>, transforms it into <code>3</code>, and processes it in <code>half</code>. A <code>Monad</code> is a data type that defines the behavior of <code>&gt;&gt;=</code>:</p><pre><code class="Haskell">class Monad m where  (&gt;&gt;=) :: m a -&gt; (a -&gt; m b) -&gt; m b</code></pre><img src="16.png" style="box-shadow: 0 0 0 #fff; margin-left: 0;" /><p>Here, <code>Maybe</code> is a <code>Monad</code> (existing alongside the <code>Maybe</code> mentioned above):</p><pre><code class="Haskell">instance Monad Maybe where  Nothing &gt;&gt;= func = Nothing  Just val &gt;&gt;= func = func val</code></pre><p><code>&gt;&gt;=</code> also supports chain operations:</p><pre><code class="Haskell">Just 20 &gt;&gt;= half &gt;&gt;= half &gt;&gt;= half-- Nothing</code></pre><img src="17.png" style="box-shadow: 0 0 0 #fff; margin-left: 0;" /><h3 id="Summary"><a href="#Summary" class="headerlink" title="Summary"></a>Summary</h3><p>Although Haskell’s Monad is quite famous, it actually involves three concepts: <code>Functors</code>, <code>Applicatives</code>, and <code>Monads</code>. Perhaps Monad has more extensive applications. In data processing, FP is not superior to OOP; the logic is similar, only the writing style differs. Facing the same problem with different thinking and expressions corresponds to different programming ideas and paradigms. There are many intricate theories in the world waiting for us to explore.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;The first time I heard about Monad was at a Scala Meetup. Later, I tried to understand the concept of Monad but was overwhelmed by</summary>
        
      
    
    
    
    
    <category term="Programming Languages" scheme="https://en.smallyu.net/tags/Programming-Languages/"/>
    
  </entry>
  
  <entry>
    <title>A Brief Analysis of the Blockchain Technology Behind Libra</title>
    <link href="https://en.smallyu.net/2019/11/20/A%20Brief%20Analysis%20of%20the%20Blockchain%20Technology%20Behind%20Libra/"/>
    <id>https://en.smallyu.net/2019/11/20/A%20Brief%20Analysis%20of%20the%20Blockchain%20Technology%20Behind%20Libra/</id>
    <published>2019-11-20T09:21:18.000Z</published>
    <updated>2025-08-06T10:38:27.588Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>Recently, national leaders have publicly encouraged the research of blockchain technology, stating that blockchain should be used as a breakthrough for independent innovation of core technologies. The issuance plan of Libra is an important milestone in the history of blockchain development. This article briefly introduces Libra’s technical solutions from aspects such as contract language, database protocol, logical data model, data structure, and consensus protocol.</p></blockquote><p>In May 2019, Facebook first confirmed its intention to launch a cryptocurrency, and news of the “global coin” and “Facebook coin” spread rapidly. On June 18, Facebook officially announced that it would launch a cryptocurrency called Libra, with a targeted release in the first half of 2020. Facebook claims that Libra is built on a secure, reliable, and scalable blockchain, adopts an off-chain asset collateral model, is anchored to a basket of fiat currencies as asset collateral, and is governed by the independent Libra Association. With 2.7 billion users worldwide, Libra’s vision is to create a simple, borderless currency that provides financial services to billions of people.</p><p>After Facebook officially announced Libra, it simultaneously launched Libra’s official website, white paper, and test network. The white paper mentioned that the Libra network hopes to operate as a public chain in the future, but due to the lack of mature technology to support large-scale transactions on public chains, Libra will start as a consortium chain, with plans to transition from a consortium chain to a public chain in three to five years.</p><p>The Libra official website published three papers detailing the technical solutions used by Libra: “The Libra Blockchain,” “Move: A Language with Programmable Resources,” and “State Machine Replication in the Libra Blockchain.” To meet the requirements of high security, sufficient flexibility, and high throughput, Libra designed a new programming language, Move, chose the BFT consensus mechanism, and adopted the widely used Merkle Tree as the data structure. This article briefly introduces the relevant technologies of the Libra blockchain.</p><h3 id="Move"><a href="#Move" class="headerlink" title="Move"></a>Move</h3><p>When real-world assets enter the Libra reserve, the system creates corresponding digital assets in Libra currency. These digital assets circulate between different accounts, and when real-world assets leave the Libra reserve, the corresponding digital assets are destroyed. Facebook designed a new programming language, Move, for managing digital assets in Libra, representing digital assets as resources in Move.</p><p>Move is a typed bytecode language, with resources being one of the types. Programs are first checked by a bytecode verifier before being executed by an interpreter. In Move, resources only support two operations: copy and move. Copying means moving out the resource, and moving means moving in the resource. Unlike ordinary variable types, resources can be assigned to ordinary variables, but resources themselves can only be moved between addresses and cannot be copied or discarded. If the program violates these rules, such as copying once and moving twice, it will not pass the bytecode verifier because the resource is no longer accessible after the first move.</p><p>Using Move, custom transaction logic and smart contracts can be written, which are more powerful than existing contract languages. Bitcoin Script provides a simple and elegant design for expressing strategies to spend bitcoins but does not support custom data types and programs and is not Turing complete. The Ethereum Virtual Machine supports control flow and custom data structures, but the excessive freedom of contracts leads to more vulnerabilities, resulting in many security incidents. Move’s static type system ensures the security of digital assets.</p><p>To facilitate verification by static analysis tools, Move takes several design measures: no dynamic dispatch, making it easier for verification tools to analyze programs; limited mutability, requiring references for each value change, with temporary variables created and destroyed within a single script, and the bytecode verifier using a “borrow checking” mechanism similar to Rust to ensure that a variable has only one mutable reference at a time; modularity, allowing verification tools to verify programs at the module level without needing to care about implementation details. These features make static verification tools more efficient and reliable.</p><pre><code>public main(payee: address, amount: u64) &#123;  let coin: 0x0.Currency.Coin = 0x0.Currency.withdraw_from_sender(copy(amount));  0x0.Currency.deposit(copy(payee), move(coin));&#125;</code></pre><p>This is an example program of a transaction script, an intermediate representation (IR) of the Move language, which is more readable and writable for programmers. The program implements a function to transfer resources. The main method is the entry point of the script, containing two parameters: the target address and the amount. The program first withdraws the amount of resources from the 0x0 address Currency module and temporarily stores it in the coin variable, then moves the coin resources to the payee’s address.</p><p>Transaction scripts provide flexibility in one aspect of Move, while modular design ensures the diversity of script programs. The module type is <code>module</code>, mainly containing Move programs. A module can include any number of resources, that is, declare one or more resource-type variables. Modules&#x2F;resources&#x2F;procedures are equivalent to classes&#x2F;objects&#x2F;methods in object-oriented languages, except there is no concept of self or this in Move.</p><h3 id="Libra-Protocol"><a href="#Libra-Protocol" class="headerlink" title="Libra Protocol"></a>Libra Protocol</h3><p>The Libra blockchain is a distributed database that needs cryptographic authentication to store programmable resources, such as Libra currency, represented as resources in Move. The Libra protocol has two types of entities: validators that collectively maintain the database and clients that typically initiate requests to the database. During execution, the Libra protocol elects a leader to receive client requests, synchronizes the requests to other validators for execution, and then returns the results to the leader, who then returns the final result to the client.</p><p>Libra transactions go through many steps, including signature verification, running pre-execution programs, verifying transaction scripts and module programs, publishing modules, executing transaction scripts, running post-execution programs, etc. To measure the computational power of contract transactions, Libra adopts the Gas concept from Ethereum, consuming Gas as transaction fees.</p><img src="a.png" width="100%" style="box-shadow: 0 0 0px #fff;"><p>This diagram shows the detailed flow of transaction requests within the Libra network components. The client initiates a request to the permission control layer. After permission verification, the request data is passed to the virtual machine for preprocessing, and the data also enters the memory pool, responsible for synchronizing the request to other nodes. The consensus protocol plays a role during request synchronization. After node synchronization, the virtual machine executes the actual transaction program, the program execution is completed, and the result is persisted, completing the basic process.</p><h3 id="Logical-Data-Model"><a href="#Logical-Data-Model" class="headerlink" title="Logical Data Model"></a>Logical Data Model</h3><p>All data on the Libra blockchain is stored in a database identified by version numbers, which are 64-bit unsigned integers. Each version of the database contains a tuple (T, O, S), where T represents the transaction, O represents the transaction output, and S represents the ledger state. When we say an Apply operation is executed, it is represented as Apply(S, T) -&gt; (O, S), meaning that the T transaction is executed in the S state, producing O output and changing the ledger state to S.</p><p>Accounts are owners of resources and can use the resources in their accounts for transactions. An account address is a 256-bit value. Creating a new account requires a verification&#x2F;signature key pair (vk, sk). The new account address a is computed by public key encryption of vk, a &#x3D; H(vk). Specifically, Libra uses the SHA3-256 hash function and the EdDSA public key of the Ed25519 elliptic curve for digital signatures. During transactions, an existing account can generate a new account by invoking the create_account(a) command.</p><img src="b.png" width="80%" style="box-shadow: 0 0 0px #fff;"><p>The diagram shows four account addresses prefixed with 0x. Rectangles represent modules, ellipses represent resources, and arrows represent dependencies. The Currency.T in the 0x12 account is declared in the Currency module, and the Currency module code is stored at address 0x56. Similarly, the StatChannel.T of 0x34 is declared in the StateChannel module at address 0x78. When a client wants to access the Currency.T under 0x12, the request resource path should be written as 0x12&#x2F;resources&#x2F;0x56.Currency.T.</p><h3 id="Data-Structure"><a href="#Data-Structure" class="headerlink" title="Data Structure"></a>Data Structure</h3><p>Libra transaction blocks contain data signed by nodes, and the signature data is verified before the transaction. The collective signature allows clients to trust that the requested database version is complete and valid, enabling clients to query any node or third-party database replica. The data structure in the Libra protocol is primarily based on Merkle trees.</p><img src="c.png" width="100%" style="box-shadow: 0 0 0px #fff;"><p>As shown, the root hash of ledger historical data verifies the system’s complete state, with ledger data accumulated by a Merkle tree, represented by dashed lines. Each node in the ledger’s historical data contains transaction signatures, event trees, and ledger states. The event tree is also based on Merkle trees, while the ledger state is based on sparse Merkle trees, with each leaf node containing account data.</p><p>In the Libra protocol, validator nodes V verify the root hash a of data D. For example, when an untrusted node obtains data D and uses function f to compute the result r, it also needs data π to verify the result’s correctness. The protocol requires the node to transmit (a, f, r, π) to the validator V for verification. If f(D) &#x3D; r, the result is verified.</p><img src="d.png" width="70%" style="box-shadow: 0 0 0px #fff;"><p>In the diagram, data D &#x3D; {0:s0, 1:s1, 2:s2, 3:s3}. Suppose f is a</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;Recently, national leaders have publicly encouraged the research of blockchain technology, stating that blockchain should</summary>
        
      
    
    
    
    
    <category term="Blockchain" scheme="https://en.smallyu.net/tags/Blockchain/"/>
    
  </entry>
  
  <entry>
    <title>Rational Understanding of Blockchain</title>
    <link href="https://en.smallyu.net/2019/11/05/Rational%20Understanding%20of%20Blockchain/"/>
    <id>https://en.smallyu.net/2019/11/05/Rational%20Understanding%20of%20Blockchain/</id>
    <published>2019-11-05T05:53:58.000Z</published>
    <updated>2025-08-06T10:38:27.728Z</updated>
    
    <content type="html"><![CDATA[<p>I once thought blockchain was a revolutionary and disruptive technology, alongside artificial intelligence and big data as the forefront of internet technology. However, true intelligence in AI is still a dream, and big data cannot achieve precise analysis like in the Avengers. Recently, the leader’s speech about blockchain was inspiring, but haven’t the past trends like IoT and Internet+ also ended without much impact?</p><h3 id="Public-Blockchains-Cannot-Escape-Currency"><a href="#Public-Blockchains-Cannot-Escape-Currency" class="headerlink" title="Public Blockchains Cannot Escape Currency"></a>Public Blockchains Cannot Escape Currency</h3><p>Some believe that just as nuclear reactions initially aimed to build nuclear bombs but now serve as a source of power, blockchain initially supported Bitcoin but can now be applied in other fields. In other words, they see nuclear reactions and blockchain as equivalent.</p><pre><code>Nuclear Reaction -&gt; Nuclear BombBlockchain -&gt; Bitcoin</code></pre><p>However, upon closer examination, how can we compare these almost completely different things? If you’ve read a few books on blockchain, you’ll find that the content isn’t particularly new, and the ideas don’t quite qualify as revolutionary or innovative. Bitcoin has been around for about 10 years and hasn’t overcome technical challenges, just different mechanisms combined. It should be considered on the same level as P2P or some video game. The value of Bitcoin lies in electronic transactions, not the currency itself.</p><pre><code>Nuclear Reaction -&gt; Nuclear Energy -&gt; Big ExplosionBlockchain -&gt; Bitcoin -&gt; Electronic Transactions</code></pre><p>Because of nuclear reactions, we get nuclear energy, which can cause big explosions. Because of blockchain, we get Bitcoin, which enables electronic transactions. So, in this sense, nuclear energy is inseparable from nuclear reactions, and Bitcoin is inseparable from blockchain.</p><p>So, can blockchain be applied independently of Bitcoin? Or are blockchain and Bitcoin essentially one entity? Just like nuclear reactions produce nuclear energy, it’s the energy that’s valuable, not the reaction. Blockchain produces Bitcoin, which operates on blockchain to offer anonymity, immutability, and traceability. It’s Bitcoin that’s valuable, not blockchain.</p><p>A few days ago, the Guangzhou government issued detailed guidelines (<a href="http://www.gz.gov.cn/gzswjk/2.3.6.3/201910/7beb40281dde4fa2beee0da2b16aa6dc.shtml">Implementation Details</a>) for subsidizing blockchain enterprises, clearly stating “non-currency” public chain projects. This policy indicates that while the state does not allow issuing currency, a non-currency public chain is the ideal scenario for blockchain, though generally, ideals are hard to achieve.</p><p>Bitcoin addresses trust issues in transactions, fundamentally concerned with data storage. In a transaction, if either the sender or receiver keeps the record, disputes can arise if either party lies or makes a mistake. Traditionally, a third party like a bank or legal firm resolves such issues. But if one doesn’t trust these centralized institutions, Bitcoin’s solution is to let everyone in the world keep the record, making it nearly impossible to alter without global consensus.</p><p>Without rewards, people won’t voluntarily keep records. So, how does a distributed ledger system maintain itself?</p><h3 id="Bitcoin-is-Not-Truly-Decentralized"><a href="#Bitcoin-is-Not-Truly-Decentralized" class="headerlink" title="Bitcoin is Not Truly Decentralized"></a>Bitcoin is Not Truly Decentralized</h3><p>Some think that distributed ledgers and databases are already decentralized, but this is not the final form of decentralization. For instance, Bitcoin’s program development, maintenance, and upgrades are still centralized. The data is globally shared, but the program’s rules, development, and releases are controlled by a centralized body. To trust the program, it’s open-sourced, but upgrading it presents challenges like ensuring backward compatibility or ensuring everyone updates.</p><p>Furthermore, Bitcoin’s data redundancy is a significant issue. Every node needs to backup all data, including unrelated historical data. If a single node doesn’t retain all data, the reliability of distributed data can’t be ensured. But if all data is kept, it’s a massive waste of resources. A centralized system can solve this with just one data copy, so why multiply it billions of times?</p><p>We can envision scenarios sacrificing the concept of decentralization:</p><ol><li><p><strong>Global Shared Database</strong>: A single global database that only stores data, with distributed programs solving consensus. It’s highly secure with strict write rules requiring global consensus or other mechanisms for data entry. Anyone can query data, and historical data can’t be modified. Consensus programs determine which data to write, ensuring minimal data redundancy.</p></li><li><p><strong>Split Data Storage</strong>: Each node keeps only half the data, split into historical and current. One person stores new data, another stores old data. New data nodes handle broadcasts and write data, while old data nodes store data, updating when new data overflows. The system randomly pairs new and old nodes, balancing distribution. Security remains high with random node pairing.</p></li><li><p><strong>Data Splitting and Redundancy</strong>: Nodes keep only parts of data, split according to certain rules and stored in different nodes. This reduces redundancy while saving space. Further, data could self-verify, with nodes storing varying data sizes. Users query data across the network, assembling it from nodes. This mixes node data, necessitating a self-verification mechanism.</p></li></ol><h3 id="Digital-Currency-and-Blockchain-are-Unrelated"><a href="#Digital-Currency-and-Blockchain-are-Unrelated" class="headerlink" title="Digital Currency and Blockchain are Unrelated"></a>Digital Currency and Blockchain are Unrelated</h3><p>Some discussions on blockchain applications link to central bank digital currency research, even notable exchange directors giving blockchain-themed talks mixing Bitcoin and Libra stories. Many ignore the conceptual differences, which are trivial yet crucial. The central bank’s digital currency plans may use blockchain, but it’s not essential. For the state, blockchain’s significance lies in “centralization in the name of decentralization,” aiming to unify and regulate the internet. Without blockchain, the state can still achieve its goals, using blockchain as a tool for convenience.</p><p>In the past, blockchain referred to the technology supporting Bitcoin. In the future, blockchain will be almost synonymous with consortium chains.</p><p>Huawei’s blockchain whitepaper objectively views blockchain as a supplement to the internet, inseparable from traditional databases and TCP, playing a unique role in specific scenarios. For the state, blockchain offers transparent data, preventing manipulation. For businesses, it facilitates checks and balances, with multiple companies sharing data, and blockchain as the key. Without blockchain, data sharing might be unclear, but with Bitcoin’s decade-long stability, it’s a promising technology driving innovation and application.</p><p>In the future, blockchain development will split into foundational and application layers. Foundational development requires higher technical skills, while application development will be akin to current web development. Blockchain application providers and SDKs will emerge, enabling developers to store data and conduct transactions on the blockchain, similar to current database APIs and payment interfaces.</p><h3 id="In-Conclusion"><a href="#In-Conclusion" class="headerlink" title="In Conclusion"></a>In Conclusion</h3><p>Blockchain will be widely integrated into our networks but is not enough to change the world. (Don’t laugh)</p><h3 id="Update"><a href="#Update" class="headerlink" title="Update"></a>Update</h3><p>I stumbled upon the distributed network <a href="https://github.com/HelloZeroNet/ZeroNet">ZeroNet</a>, a project released in 2015 that meets almost all my expectations for a blockchain storage system, with complete functionalities for blogs, forums, emails, and file sharing. However, it hasn’t solved any of the issues I anticipated, validating some of my thoughts. The difference is that I hoped to connect a distributed network to the public internet, while ZeroNet created an autonomous network system, with .bit domains only as URI suffixes, limiting wider adoption. Additionally, P2P file systems are hard to regulate, leading to GWF’s blacklist. Although specific, ZeroNet and IPFS indicate that blockchain is best suited for financial fields or restricted internet domains.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;I once thought blockchain was a revolutionary and disruptive technology, alongside artificial intelligence and big data as the forefront</summary>
        
      
    
    
    
    
    <category term="Blockchain" scheme="https://en.smallyu.net/tags/Blockchain/"/>
    
  </entry>
  
  <entry>
    <title>Overview of Basic Rust Syntax</title>
    <link href="https://en.smallyu.net/2019/08/19/Overview%20of%20Basic%20Rust%20Syntax/"/>
    <id>https://en.smallyu.net/2019/08/19/Overview%20of%20Basic%20Rust%20Syntax/</id>
    <published>2019-08-19T14:12:25.000Z</published>
    <updated>2025-08-06T10:38:27.722Z</updated>
    
    <content type="html"><![CDATA[<p>Rust is a language with complexity and application scenarios comparable to C++. Let’s learn it together!</p><p>Recently, I’ve been pondering what kind of content this type of article represents. A programming language tutorial? The content is not comprehensive enough; an evaluation of the language? Not quite; study notes? If so, that’s definitely not my intention. I tend to think this is an exploratory process, whether for myself or for others. I hope to show that, look, there’s nothing mysterious about a new programming language, it’s so simple! Some programmers spend their entire lives using a particular language as a prefix to their job title, “Java Programmer” or “Backend Developer.” We should break out of this loop.</p><h3 id="Statements"><a href="#Statements" class="headerlink" title="Statements"></a>Statements</h3><p>Rust statements must end with a <code>;</code>.</p><h3 id="Constants-and-Variables"><a href="#Constants-and-Variables" class="headerlink" title="Constants and Variables"></a>Constants and Variables</h3><p>Rust uses <code>let</code> to define constants and <code>let mut</code> to define variables. This way of writing may seem a bit strange:</p><pre><code class="Rust">fn main() &#123;  let x = 1;  println!(&quot;&#123;&#125;&quot;, x);  let mut y = 2;  println!(&quot;&#123;&#125;&quot;, y);  y = 3;  println!(&quot;&#123;&#125;&quot;, y);&#125;</code></pre><p>Unlike other languages, Rust allows multiple declarations of the same constant within the same scope. This means that although constants in Rust cannot be reassigned, the same constant name can be defined multiple times. We can understand the difference between constants and variables at the system level, but the writing style can be a bit confusing. If I assign a value to the same symbol multiple times, isn’t that symbol a variable?</p><pre><code class="Rust">fn main() &#123;  let x = 1;  println!(&quot;&#123;&#125;&quot;, x);  let x = 2;  println!(&quot;&#123;&#125;&quot;, x);&#125;</code></pre><p>Another somewhat strange aspect is that Rust variables cannot be redeclared. We cannot speculate on the intentions of the language designers; this is clearly not allowed to enable redefinition. Perhaps, there are only constants in Rust, and the <code>mut</code> keyword provides an interface for constants to be assigned multiple times. Without <code>mut</code>, a constant is just a constant; with <code>mut</code>, the constant gets an “entry” to acquire new values. As for the issue of variable redeclaration, why need a bicycle?</p><pre><code class="Rust">fn main() &#123;  let mut x = 1;  let mut x = 2;&#125;// warning: variable does not need to be mutable</code></pre><h3 id="Control-Flow"><a href="#Control-Flow" class="headerlink" title="Control Flow"></a>Control Flow</h3><p>The conditional part of Rust does not require parentheses, similar to the Go language. Who came first?</p><pre><code class="Rust">fn main() &#123;  let number = 2;  if number == 1 &#123;    println!(&quot;1&quot;)  &#125; else if number == 2 &#123;    println!(&quot;2&quot;)  &#125; else &#123;    println!(&quot;3&quot;)  &#125;&#125;</code></pre><p>Since the <code>if</code> statement itself is an expression, it can also be nested into assignment statements to achieve a function similar to the ternary operator in other languages. (Rust is a strongly typed language, so assignment types must be consistent.)</p><pre><code class="Rust">fn main() &#123;  let number = if true &#123;    3  &#125; else &#123;    4  &#125;;  println!(&quot;&#123;&#125;&quot;, number);&#125;</code></pre><p>Compared to the concise and multifunctional <code>for</code> loop of the Go language, Rust supports multiple types of loops:</p><pre><code class="Rust">fn main() &#123;  loop &#123;    // ...  &#125;  while true &#123;    // ...  &#125;  let a = [1, 2, 3];  for item in a.iter() &#123;    println!(&quot;&#123;&#125;&quot;, item);  &#125;&#125;</code></pre><h3 id="Functions-and-Value-Passing"><a href="#Functions-and-Value-Passing" class="headerlink" title="Functions and Value Passing"></a>Functions and Value Passing</h3><p>Rust seems to have no distinction between pass by value and pass by reference, because everything in Rust is passed by reference, or categorized as constant passing and variable passing. Comparing the creation of strings in Java, strings in Rust can also be created using the “object declaration” method:</p><pre><code class="Rust">fn main() &#123;  // Constant passing  let a = String::from(&quot;a&quot;);  testa(&amp;a);  // Variable passing  let mut b = String::from(&quot;b&quot;);  testb(&amp;mut b);  println!(&quot;&#123;&#125;&quot;, b);&#125;fn testa(a: &amp;String) &#123;  println!(&quot;&#123;&#125;&quot;, a);&#125;fn testb(b: &amp;mut String) &#123;  b.push_str(&quot; b&quot;);&#125;</code></pre><p>Functions can also have return values, and in Rust, the return type is defined with <code>-&gt;</code>. By default, the value of the last line of the function is used as the return value, or you can use <code>return</code> to end the function early. Note that the expression used as the return value on the last line should not end with a semicolon…</p><pre><code class="Rust">fn main() &#123;  let mut a = test();  println!(&quot;&#123;&#125;&quot;, a);  a = test2();  println!(&quot;&#123;&#125;&quot;, a);&#125;fn test() -&gt; u32 &#123;  1&#125;fn test2() -&gt; u32 &#123;  return 2;&#125;</code></pre><h3 id="Structures"><a href="#Structures" class="headerlink" title="Structures"></a>Structures</h3><p>The basic usage of structures is quite conventional, without the <code>new</code> keyword; you can use it directly by “instantiating” it:</p><pre><code class="Rust">struct Foo &#123;  a: String,  b: i32&#125;fn main() &#123;  let t = Foo &#123;    a: String::from(&quot;a&quot;),    b: 1,  &#125;;  println!(&quot;&#123;&#125;, &#123;&#125;&quot;, t.a, t.b);&#125;</code></pre><p>You can also add methods to structures:</p><pre><code class="Rust">struct Foo &#123;  a: String,  b: i32&#125;impl Foo &#123;  fn test(&amp;self) -&gt; i32 &#123;    self.b + 1  &#125;&#125;fn main() &#123;  let t = Foo &#123;    a: String::from(&quot;a&quot;),    b: 1,  &#125;;  println!(&quot;&#123;&#125;, &#123;&#125;, &#123;&#125;&quot;, t.a, t.b, t.test());&#125;// a, 1, 2</code></pre><h3 id="Lists-and-Pattern-Matching"><a href="#Lists-and-Pattern-Matching" class="headerlink" title="Lists and Pattern Matching"></a>Lists and Pattern Matching</h3><p>The following example creates a vector containing three elements, then assigns the 0th element to the constant <code>one</code>. It then uses pattern matching to check if the 0th element of the list equals the value of <code>one</code>. If they are equal, it outputs the string “one”; otherwise, it outputs “none.” In Rust’s pattern matching, <code>Some()</code> and <code>None</code> are built-in keywords:</p><pre><code class="Rust">fn main() &#123;  let v = vec![1, 2, 3];  let one = &amp;v[0];  println!(&quot;&#123;&#125;&quot;, one);  match v.get(0) &#123;    Some(one) =&gt; println!(&quot;one&quot;),    Some(2) =&gt; println!(&quot;two&quot;),    None =&gt; println!(&quot;none&quot;),  &#125;&#125;</code></pre><h3 id="Error-Handling"><a href="#Error-Handling" class="headerlink" title="Error Handling"></a>Error Handling</h3><p>The <code>panic</code> function is used to throw exceptions:</p><pre><code class="Rust">fn main() &#123;  panic!(&quot;new Exception&quot;);&#125;// thread &#39;main&#39; panicked at &#39;new Exception&#39;, test.rs:4:3// note: Run with `RUST_BACKTRACE=1` environment variable to display a backtrace.</code></pre><p>For error handling, Rust provides two shorthand methods for conveniently handling error information. The <code>unwrap()</code> function automatically throws a <code>panic</code>. If <code>unwrap()</code> is not used, the program skips the code where <code>panic</code> occurred. This is somewhat opposite to Java’s exception handling logic because if an exception is not handled in Java, the program cannot continue running. In Rust, if <code>unwrap()</code> is used to handle a <code>panic</code>, the program will stop executing and print the error message.</p><pre><code class="Rust">use std::fs::File;fn main() &#123;  let f = File::open(&quot;hello.txt&quot;);  println!(&quot;a&quot;);  let f2 = File::open(&quot;hello.txt&quot;).unwrap();  println!(&quot;b&quot;);&#125;// a// thread &#39;main&#39; panicked at &#39;called `Result::unwrap()` on an `Err` value: Os &#123; code: 2, kind: NotFound, message: &quot;The system cannot find the file specified.&quot; &#125;&#39;, src\libcore\result.rs:999:5// ...</code></pre><p>Another shorthand method is <code>expect()</code>, which can be used to replace <code>unwrap()</code>. The difference between <code>expect()</code> and <code>unwrap()</code> is that <code>unwrap()</code> uses the system’s built-in <code>panic</code> information, while <code>expect()</code> can pass a parameter as the <code>panic</code> error message. That’s all.</p><pre><code class="Rust">use std::fs::File;fn main() &#123;    let f = File::open(&quot;hello.txt&quot;).expect(&quot;Failed to open hello.txt&quot;);&#125;// thread &#39;main&#39; panicked at &#39;Failed to open hello.txt: ...// ...</code></pre><h3 id="Lambda-Expressions"><a href="#Lambda-Expressions" class="headerlink" title="Lambda Expressions"></a>Lambda Expressions</h3><p>Lambda expressions in Rust use <code>|</code> as parameter delimiters, replacing <code>()</code>. Besides that, Lambdas function the same as in other languages:</p><pre><code class="Rust">fn main() &#123;  let test = |num| &#123;    num == 1  &#125;;  println!(&quot;&#123;&#125;, &#123;&#125;&quot;, test(1), test(2));&#125;// true, false</code></pre><h3 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h3><p>Rust’s language features go far beyond this, especially Rust’s unique memory management mechanism, and the concept of “ownership,” which makes it hard for Rust beginners to get started, require us to keep moving forward.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Rust is a language with complexity and application scenarios comparable to C++. Let’s learn it together!&lt;/p&gt;
&lt;p&gt;Recently, I’ve been</summary>
        
      
    
    
    
    
    <category term="Programming Language" scheme="https://en.smallyu.net/tags/Programming-Language/"/>
    
  </entry>
  
  <entry>
    <title>Java-Based Web Scraping Framework WebCollector</title>
    <link href="https://en.smallyu.net/2019/08/10/Java-Based%20Web%20Scraping%20Framework%20WebCollector/"/>
    <id>https://en.smallyu.net/2019/08/10/Java-Based%20Web%20Scraping%20Framework%20WebCollector/</id>
    <published>2019-08-10T13:03:41.000Z</published>
    <updated>2025-08-06T10:38:27.717Z</updated>
    
    <content type="html"><![CDATA[<p>Long, Long Ago, there were numerous Python web scraping tutorials available online, and various training courses leveraged the trend to promote Python. In recent years, the hype has shifted towards artificial intelligence. Web scraping can be a simple or complex concept, much like building a doghouse versus constructing a skyscraper - both are engineering projects.</p><p>Due to work requirements, I needed to use WebCollector to scrape some data from web pages. In a broad sense, web scraping involves nothing more than accessing page files, extracting the necessary data, and then storing the data in a database. The challenges often lie in two main areas: one, the anti-scraping strategies of the target website, which can be a frustrating battle of wits; and two, the large number and variety of target web pages, making it difficult to formulate effective data scraping and analysis plans.</p><h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p>This is a brief conceptual diagram. Due to screen width limitations, the content may not be clear. Please open the image in a new tab or click <a href="/2019/08/10/%E5%9F%BA%E4%BA%8EJava%E7%9A%84%E7%88%AC%E8%99%AB%E6%A1%86%E6%9E%B6WebCollector/WebCollector.png">here</a>. The image is not perfect and even contains some incorrect implementations, which will be explained in detail later.</p><img src="WebCollector.png" width="95%" height="100%"><p>I divided the target web pages into four types:</p><ol><li>Static web documents that can be loaded with curl</li><li>Pages that require custom HTTP requests, such as search result pages obtained via POST requests or pages that require authentication using cookies</li><li>Pages containing data generated by JavaScript, which is the data we need. Since JavaScript executes after loading, similar to how CSS is rendered by the browser after loading, this data cannot be directly obtained</li><li>Pages containing data generated by JavaScript, which also require custom HTTP requests</li></ol><h3 id="Test-Environment"><a href="#Test-Environment" class="headerlink" title="Test Environment"></a>Test Environment</h3><p>To facilitate testing, a simple server is started locally using Node.js to receive requests and return a page as a response. The content of server.js is as follows:</p><p><code>JavaScript</code>var http &#x3D; require(‘http’)var fs &#x3D; require(‘fs’)var server &#x3D; http.createServer((req,res) &#x3D;&gt; {  &#x2F;&#x2F; Return page content  fs.readFile(‘.&#x2F;index.html’, ‘utf-8’, (err,data) &#x3D;&gt; {    res.end(data);  });  &#x2F;&#x2F; Print cookie information in the request  console.log(req.headers.cookie)})server.listen(9000) </p><pre><code>The content of index.html is simpler, containing only a title and a p tag:```HTML```&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;    &lt;title&gt;This is a title&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt;</code></pre><h3 id="Static-Page"><a href="#Static-Page" class="headerlink" title="Static Page"></a>Static Page</h3><p>This is the simplest version of a web scraper. The constructor calls the parent class’s parameterized constructor and adds a URL to the queue of URLs to be scraped. The visit method is the consumer, processing each URL request.</p><p><code>Java</code>public class StaticDocs extends BreadthCrawler {</p><pre><code>public StaticDocs(String crawlPath, boolean autoParse) &#123;    super(crawlPath, autoParse);    this.addSeed(&quot;http://127.0.0.1:9000/&quot;);&#125;@Overridepublic void visit(Page page, CrawlDatums next) &#123;    System.out.println(page.doc().title());    // This is a title&#125;public static void main(String[] args) throws Exception &#123;    StaticDocs crawler = new StaticDocs(&quot;crawl&quot;, true);    crawler.start(1);&#125;</code></pre><p>}</p><pre><code>### Cookie AuthenticationRequesting with a cookie in the header is equally simple. Just add the appropriate configuration in the constructor, and the Node.js command line will print the cookie content:```Java```public CookieDocs(String crawlPath) &#123;    super(crawlPath, true);    // Set request plugin    setRequester(new OkHttpRequester() &#123;        @Override        public Request.Builder createRequestBuilder(CrawlDatum crawlDatum) &#123;            return super.createRequestBuilder(crawlDatum)                    .header(&quot;Cookie&quot;, &quot;name=smallyu&quot;);        &#125;    &#125;);    this.addSeed(&quot;http://127.0.0.1:9000/&quot;);&#125;// name=smallyu</code></pre><h3 id="JavaScript-Generated-Data"><a href="#JavaScript-Generated-Data" class="headerlink" title="JavaScript-Generated Data"></a>JavaScript-Generated Data</h3><p>Testing the case of JavaScript-generated data requires some preparation. Modify index.html and add the following lines of code in the body tag:</p><p><code>JavaScript</code></p><div id="content">1</div><script>  document.getElementById('content').innerHTML = '2'</script>```<p>As expected, the content of the div returned directly by the request is 1, and the JavaScript, executed by the browser, changes the content of the div to 2. A web scraper accessing a static page can only reach the first step, which is to directly obtain the content returned by the request. Modify the visit method of StaticDocs.java to print the content of the div and confirm it is 1:</p><p><code>Java</code>System.out.println(page.select(“div”).text());&#x2F;&#x2F; 1</p><pre><code>Here is an official demo for obtaining JavaScript-generated data. WebCollector relies on Selenium and uses HtmlUnitDriver to run JavaScript:```Java```public class JsDocs &#123;    public static void main(String[] args) throws Exception &#123;        Executor executor = (CrawlDatum datum, CrawlDatums next) -&gt; &#123;            HtmlUnitDriver driver = new HtmlUnitDriver();            driver.setJavascriptEnabled(true);            driver.get(datum.url());            WebElement divEle = driver.findElement(By.id(&quot;content&quot;));            System.out.println(divEle.getText());            // 2        &#125;;        // Create a DBManager based on Berkeley DB        DBManager manager = new RocksDBManager(&quot;crawl&quot;);        // Create a Crawler with DBManager and Executor        Crawler crawler = new Crawler(manager, executor);        crawler.addSeed(&quot;http://127.0.0.1:9000/&quot;);        crawler.start(1);    &#125;&#125;</code></pre><p>If you have seen the homepage of WebCollector, you will notice a significant difference between this demo and other demos. When not requiring JavaScript-generated data, the new class extends BreadthCrawler, which extends AutoParseCrawler, which in turn extends Crawler. However, for obtaining JavaScript data, the demo directly instantiates Crawler, skipping BreadthCrawler and AutoParseCrawler.</p><img src="uml.png" width="50%" height="100%"><p>Why is this done? To reiterate, this is an official demo.</p><h3 id="JavaScript-Generated-Data-After-Cookie-Authentication"><a href="#JavaScript-Generated-Data-After-Cookie-Authentication" class="headerlink" title="JavaScript-Generated Data After Cookie Authentication"></a>JavaScript-Generated Data After Cookie Authentication</h3><p>According to the official example, it is clear that cookies cannot be set because the Crawler class does not provide a method for customizing headers. This header customization method is inherited from the AutoParseCrawler class. So how do you achieve both setting cookies and using HtmlUnitDriver?</p><p>The result is simple. After reviewing the WebCollector code, I discovered that AutoParseCrawler implements the Executor interface and assigns this to the parent class’s executor in its constructor. In other words, AutoParseCrawler itself is an Executor. The following code illustrates their relationship:</p><p><code>Java</code>public class Crawler {    protected Executor executor;</p><pre><code>public Crawler(DBManager dbManager, Executor executor) &#123;    // ...&#125;</code></pre><p>}</p><p>public class AutoParseCrawler extends Crawler implements Executor {    public AutoParseCrawler(boolean autoParse) {        &#x2F;&#x2F; Here, executor refers to the parent class        this.executor &#x3D; this;    }}</p><pre><code>Creating a new Crawler and passing in an executor is equivalent to directly creating an AutoParseCrawler. BreadthCrawler extends AutoParseCrawler, so BreadthCrawler itself is also an Executor. Looking again at the official demo for custom cookies, how can HtmlUnitDriver be used in it? By overriding the execute method of Executor.Therefore, to obtain JavaScript-generated data after defining a cookie, use a class that extends BreadthCrawler and override the execute method. Here is a complete demo:```Java```/** * @author smallyu * @date 2019.08.11 12:18 */public class JsWithCookieDocs extends BreadthCrawler &#123;    public JsWithCookieDocs(String crawlPath) &#123;        super(crawlPath, true);        // Set request plugin        setRequester(new OkHttpRequester() &#123;            @Override            public Request.Builder createRequestBuilder(CrawlDatum crawlDatum) &#123;                return super.createRequestBuilder(crawlDatum)                        .header(&quot;Cookie&quot;, &quot;name=smallyu&quot;);            &#125;        &#125;);        this.addSeed(&quot;http://127.0.0.1:9000/&quot;);    &#125;    // Directly override execute    @Override    public void execute(CrawlDatum datum, CrawlDatums next) throws Exception &#123;        super.execute(datum, next);        HtmlUnitDriver driver = new HtmlUnitDriver();        driver.setJavascriptEnabled(true);        driver.get(datum.url());        WebElement divEle = driver.findElement(By.id(&quot;content&quot;));        System.out.println(divEle.getText());        // 2        // Meanwhile, the Node.js command line prints the cookie content    &#125;    // No need for visit when execute is overridden    public void visit(Page page, CrawlDatums crawlDatums) &#123;&#125;    public static void main(String[] args) throws Exception &#123;        JsWithCookieDocs crawler = new JsWithCookieDocs(&quot;crawl&quot;);        crawler.start(1);    &#125;&#125;</code></pre><h3 id="External-Proxy"><a href="#External-Proxy" class="headerlink" title="External Proxy"></a>External Proxy</h3><p>Perhaps it is not over yet. In the initial conceptual image, both setting cookies and obtaining JavaScript-generated data were defined using internal Selenium and</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Long, Long Ago, there were numerous Python web scraping tutorials available online, and various training courses leveraged the trend to</summary>
        
      
    
    
    
    
    <category term="Programming Languages" scheme="https://en.smallyu.net/tags/Programming-Languages/"/>
    
  </entry>
  
  <entry>
    <title>Kotlin: A Simplified Version of Scala</title>
    <link href="https://en.smallyu.net/2019/07/06/A%20Simplified%20Version%20of%20Scala/"/>
    <id>https://en.smallyu.net/2019/07/06/A%20Simplified%20Version%20of%20Scala/</id>
    <published>2019-07-06T02:18:22.000Z</published>
    <updated>2025-08-06T10:38:27.632Z</updated>
    
    <content type="html"><![CDATA[<p>A swordsman in the martial world must have a handy sword. A good programming language is like a good sword: the weight is appropriate, it feels comfortable, it’s elegant to wield, and its lethality is adequate. The official stance on Kotlin’s relationship with Scala is, “If you’re happy with Scala, you don’t need Kotlin.”</p><h3 id="Scripting"><a href="#Scripting" class="headerlink" title="Scripting"></a>Scripting</h3><p>Like Java, Scala’s basic unit of execution is a class, while Kotlin allows the main method in a file to run directly without requiring a class. Java’s entry function is defined within a class:</p><pre><code class="Java">public class Java &#123;    public static void main(String[] args) &#123;&#125;&#125;</code></pre><p>Scala’s entry function is defined within an object rather than a regular class:</p><pre><code class="Scala">object Scala &#123;  def main(args: Array[String]): Unit = &#123;&#125;&#125;</code></pre><p>Kotlin’s entry function is defined directly in a .kt file; thus, a class in Kotlin is merely a data structure where an entry function cannot be defined:</p><pre><code class="Kotlin">fun main(args: Array&lt;String&gt;) &#123;&#125;</code></pre><h3 id="Constructors-and-Singleton-Pattern"><a href="#Constructors-and-Singleton-Pattern" class="headerlink" title="Constructors and Singleton Pattern"></a>Constructors and Singleton Pattern</h3><p>Kotlin’s constructor, like Scala’s, is written in the class definition, and thus cannot include initialization code directly as Java’s constructors can. In Kotlin, the init block is used to execute initialization code:</p><pre><code class="Kotlin">class Test(arg: String) &#123;    init &#123;        println(&quot;This string is $&#123;arg&#125;&quot;)    &#125;&#125;fun main(args: Array&lt;String&gt;) &#123;    val test = Test(&quot;smallyu&quot;)&#125;// This string is smallyu</code></pre><p>If a second constructor is needed, you have to use a constructor function similar to ES6, or a secondary constructor like in Scala. This is indeed an awkward way of writing, making Java seem more user-friendly in comparison.</p><pre><code class="Kotlin">class Test(arg1: String) &#123;    init &#123;        println(&quot;This string is $&#123;arg1&#125;&quot;)    &#125;    constructor(arg2: Int): this(&quot;smallyu2&quot;) &#123;        println(&quot;This int is $&#123;arg2&#125;&quot;)    &#125;&#125;fun main(args: Array&lt;String&gt;) &#123;    val test = Test(1)&#125;// This string is smallyu2// This int is 1</code></pre><p>Kotlin’s constructor needs to be defined with the constructor keyword, which can be omitted by default, but if you want to add access modifiers, you naturally can’t omit it. Implementing the singleton pattern in Kotlin is similar to Java: make the constructor private, and expose the instance through a static method:</p><pre><code class="Kotlin">class Test private constructor() &#123;    companion object Factory &#123;        fun create(): Test = Test()    &#125;&#125;fun main(args: Array&lt;String&gt;) &#123;    val test = Test.Factory.create()&#125;</code></pre><p>In Kotlin, the object keyword defines a static block, and companion allows defining static blocks within the class, hence the companion object defines a method create() that can be accessed externally.</p><h3 id="Getter-and-Setter"><a href="#Getter-and-Setter" class="headerlink" title="Getter and Setter"></a>Getter and Setter</h3><p>Another interesting feature in Kotlin is the getter and setter. The principle behind data binding in frontend frameworks like React or Vue is using Object.defineProperty() to define an object’s getter and setter, allowing changes to the object to be synchronized with the page in real-time. Kotlin provides support for property getters and setters:</p><pre><code class="Kotlin">var test: Int    get() &#123;        println(&quot;There is test getter&quot;)        return 2    &#125;    set(arg) &#123;        println(&quot;The setter arg is $&#123;arg&#125;&quot;)    &#125;fun main(args: Array&lt;String&gt;) &#123;    println(test)    test = 3&#125;// There is test getter// 2// The setter arg is 3</code></pre><h3 id="Others"><a href="#Others" class="headerlink" title="Others"></a>Others</h3><p>I became interested in Kotlin because I found that Kotlin supports coroutines. If Kotlin truly has language-level coroutine support, combined with its ability to run on the JVM and develop multi-platform applications including server-side, Android, JavaScript, and Native, Kotlin would undoubtedly be an extremely powerful programming language. However, Kotlin’s coroutines are just an extension package and still require a compiler tool to introduce, so Go language remains dominant in coroutine support. For the JavaScript platform, Kotlin is not as easy to use as TypeScript. As for Android and Native, they are already Java’s application scenarios…</p><p>Kotlin provides a lot of syntactic sugar, seemingly reducing the amount of code a programmer has to write, but to proficiently apply Kotlin’s features, users must understand concepts similar to data classes, just like Scala’s case classes. Kotlin is less academic than Scala and does not have a significant advantage over Java in terms of engineering capabilities. Although Go language takes a different path and has widely criticized language features, it is satisfying to read and write. Therefore, like Scala, Kotlin will not have a broad application prospect. In other words, it will not be the next popular programming language.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;A swordsman in the martial world must have a handy sword. A good programming language is like a good sword: the weight is appropriate,</summary>
        
      
    
    
    
    
    <category term="Programming Languages" scheme="https://en.smallyu.net/tags/Programming-Languages/"/>
    
  </entry>
  
  <entry>
    <title>Does JavaScript Have Associative Arrays?</title>
    <link href="https://en.smallyu.net/2019/05/18/Does%20JavaScript%20Have%20Associative%20Arrays_/"/>
    <id>https://en.smallyu.net/2019/05/18/Does%20JavaScript%20Have%20Associative%20Arrays_/</id>
    <published>2019-05-18T10:50:32.000Z</published>
    <updated>2025-08-06T10:38:27.646Z</updated>
    
    <content type="html"><![CDATA[<p>If you have worked with PHP, you are certainly familiar with associative arrays. In C or Java, array indices start from 0, whereas in PHP, you can use strings as array indices in addition to numbers. Arrays with numeric indices are called indexed arrays, and arrays with string indices are called associative arrays. Both are valid arrays.</p><pre><code class="PHP">&lt;?php$arr[0] = 1;        // Indexed array$arr[&quot;a&quot;] = &quot;b&quot;;    // Associative arrayecho $arr[0];       // 1echo $arr[&quot;a&quot;];     // b</code></pre><p>In JavaScript, you can also use strings as array indices:</p><pre><code class="JavaScript">let arr = []arr[0] = 1arr[&#39;a&#39;] = &#39;b&#39;</code></pre><p>Yesterday, my pretty colleague and I encountered a puzzling issue when using arrays with string indices in JavaScript.</p><h3 id="The-Origin"><a href="#The-Origin" class="headerlink" title="The Origin"></a>The Origin</h3><p>In Express.js framework’s route handling, using <code>res.json()</code> to return an array, arrays with numeric indices are returned normally, but arrays with string indices always return empty. Here is a minimal code to describe the process:</p><pre><code class="JavaScript">app.get(&#39;/&#39;, (req, res) =&gt; &#123;  let arr = []  arr[&#39;a&#39;] = &#39;b&#39;  console.log(arr)  // [a: &#39;b&#39;]  res.json(arr)     // []&#125;)</code></pre><p>The expected returned array <code>arr</code> contains one element. The text content printed directly to the console with <code>console.log()</code> is <code>[a: &#39;b&#39;]</code>, which matches the expectation. However, if you make a page request to the route, the returned content is <code>[]</code>, which is puzzling. In other words, <code>res.json()</code> swallows the array content.</p><h3 id="Exploration"><a href="#Exploration" class="headerlink" title="Exploration"></a>Exploration</h3><p>To find the true cause of the problem, I looked into the definition of <code>res.json()</code> in the framework:</p><pre><code class="JavaScript">res.json = function json(obj) &#123;  var val = obj;  // ...  var body = stringify(val, replacer, spaces, escape)  // ...  return this.send(body);&#125;;</code></pre><p>The returned content <code>body</code> is processed by the <code>stringify()</code> method, which calls the <code>JSON.stringify()</code> method from JavaScript’s standard JSON library:</p><pre><code class="JavaScript">function stringify (value, replacer, spaces, escape) &#123;  var json = replacer || spaces    ? JSON.stringify(value, replacer, spaces)    : JSON.stringify(value);  // ...&#125;</code></pre><p>This means that the return value of <code>JSON.stringify()</code> will ignore array elements with string indices. To verify this phenomenon, a simple demo was tested:</p><pre><code class="JavaScript">let arr1 = [], arr2 = []arr1[0] = 1arr2[&#39;a&#39;] = &#39;b&#39;JSON.stringify(arr1)    // &quot;[1]&quot;JSON.stringify(arr2)    // &quot;[]&quot;</code></pre><p>So the question arises: why does JavaScript’s standard library method <code>JSON.stringify()</code> ignore elements with string indices in arrays? Is it intentional, because the official stance is against using strings as indices, or is it due to unavoidable reasons that prevent implementation? To find the root cause, I tried to locate the definition of <code>JSON.stringify()</code> in Chrome’s JavaScript engine, <a href="https://github.com/v8/v8">V8</a>.</p><p>V8 engine is written in C++, and the definition of <code>JSON.stringify()</code> should be this segment of code:</p><pre><code class="JavaScript">// ES6 section 24.3.2 JSON.stringify.BUILTIN(JsonStringify) &#123;  HandleScope scope(isolate);  JsonStringifier stringifier(isolate);  Handle&lt;Object&gt; object = args.atOrUndefined(isolate, 1);  Handle&lt;Object&gt; replacer = args.atOrUndefined(isolate, 2);  Handle&lt;Object&gt; indent = args.atOrUndefined(isolate, 3);  RETURN_RESULT_OR_FAILURE(isolate,                           stringifier.Stringify(object, replacer, indent));&#125;</code></pre><p>It can be inferred that <code>object</code> is the content processed and returned by <code>JSON.stringify()</code>, which is wrapped by the <code>args.atOrUndefined()</code> method before returning. Here, <code>atOrUndefined()</code> is called repeatedly with two parameters. It can be understood that the first parameter <code>isolate</code> holds complete parameter information, and the second parameter is the data index. Combined, the <code>atOrUndefined()</code> method processes the complete data.</p><p>Then, looking at the definition of <code>atOrUndefined()</code>, it calls the <code>at()</code> method, which in turn calls the <code>Arguments</code> class’s <code>at</code> method:</p><pre><code class="C++">Handle&lt;Object&gt; atOrUndefined(Isolate* isolate, int index) &#123;  if (index &gt;= length()) &#123;    return isolate-&gt;factory()-&gt;undefined_value();  &#125;  return at&lt;Object&gt;(index);&#125;Handle&lt;S&gt; at(int index) &#123;  DCHECK_LT(index, length());  return Arguments::at&lt;S&gt;(index);&#125;</code></pre><p>In the <code>Arguments::at()</code> method, the pointer <code>value</code> gets the memory address of the parameter to be processed, and then uses <code>reinterpret_cast</code> to perform a type conversion on the value of <code>value</code>.</p><pre><code class="C++">Handle&lt;S&gt; at(int index) &#123;  Object** value = &amp;((*this)[index]);  // This cast checks that the object we&#39;re accessing does indeed have the  // expected type.  S::cast(*value);  return Handle&lt;S&gt;(reinterpret_cast&lt;S**&gt;(value));&#125;</code></pre><p>Here, the value is returned, but it does not explain why elements with string indices in arrays are ignored. As long as it is the same array, its values will be stored in a contiguous address space. Even if <code>reinterpret_cast</code> processes pointer variables, it should output everything normally.</p><h3 id="The-Truth"><a href="#The-Truth" class="headerlink" title="The Truth"></a>The Truth</h3><p>Finally, through Google, I found a question and answer about using string indices in arrays (<a href="https://stackoverflow.com/questions/10326635/string-index-in-js-array">String index in js array</a>), which explained why arrays with string indices are so special. This is because there are no associative arrays in JavaScript!</p><pre><code class="JavaScript">let arr1 = [], arr2 = []arr1[0] = 1arr2[&#39;a&#39;] = &#39;b&#39;arr1.length     // 1arr2.length     // 0</code></pre><p>When an array is assigned a value using a string as an index, the array length does not change, and the assigned value is not stored as an array element. The reason you can use strings as indices to get and set array values is that JavaScript stores the strings as properties of the array.</p><pre><code class="JavaScript">let arr = []arr[&#39;a&#39;] = &#39;b&#39;arr.hasOwnProperty(&#39;a&#39;)   // true</code></pre><p>Therefore, <code>JSON.stringify()</code> processes the contents of the array, and <code>reinterpret_cast</code> only performs type conversion based on pointers to the array content. Of course, properties will not be output!</p><h3 id="Follow-up"><a href="#Follow-up" class="headerlink" title="Follow-up"></a>Follow-up</h3><ol><li><p>Why can <code>console.log()</code> output array properties? How is the content to be output defined?</p></li><li><p>Why is the value of <code>typeof []</code> in JavaScript <code>&quot;object&quot;</code>, meaning that the type of an array is an object, but the properties of an object are processed, while an array is not?</p></li></ol>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;If you have worked with PHP, you are certainly familiar with associative arrays. In C or Java, array indices start from 0, whereas in</summary>
        
      
    
    
    
    
    <category term="Programming Language" scheme="https://en.smallyu.net/tags/Programming-Language/"/>
    
  </entry>
  
  <entry>
    <title>Exception Handling Mechanisms in Mainstream Programming Languages</title>
    <link href="https://en.smallyu.net/2019/04/24/Exception%20Handling%20Mechanisms%20in%20Mainstream%20Programming%20Languages/"/>
    <id>https://en.smallyu.net/2019/04/24/Exception%20Handling%20Mechanisms%20in%20Mainstream%20Programming%20Languages/</id>
    <published>2019-04-24T02:19:04.000Z</published>
    <updated>2025-08-06T10:38:27.655Z</updated>
    
    <content type="html"><![CDATA[<p>When learning a programming language, it is important to start with its features rather than the language itself. Here, we attempt a simple, horizontal understanding of the exception and error handling mechanisms of various programming languages. The languages involved include C, C++, Go, Java, Scala, Kotlin, Ruby, Rust, JavaScript, PHP, Python, and Lisp.</p><h3 id="C"><a href="#C" class="headerlink" title="C"></a>C</h3><p>The C language does not have an exception handling mechanism. When an error occurs, a global error code <code>errno</code> is set. C provides the <code>perror()</code> and <code>strerror()</code> functions to display the description related to <code>errno</code>. The <code>perror()</code> function can be called directly, with a string parameter, and outputs <code>parameter: error text</code>. The <code>strerror()</code> function takes a number (error code) as a parameter and returns a pointer to the corresponding error text.</p><pre><code class="C">#include &lt;stdio.h&gt;#include &lt;errno.h&gt;#include &lt;string.h&gt;void main ()&#123;  // Opening a non-existent file will cause an error  fopen (&quot;unexist.txt&quot;, &quot;rb&quot;);  // 2  printf(&quot;%d\n&quot;, errno);  // No such file or directory  perror(&quot;&quot;);  // No such file or directory  printf(&quot;%s\n&quot;, strerror(errno));&#125;</code></pre><h3 id="C-1"><a href="#C-1" class="headerlink" title="C++"></a>C++</h3><p>C++ supports exception handling mechanisms. C++ can throw or catch two types of content: int or char* types, which can be caught and thrown by the program. This differs from Java, which does not support directly throwing basic types:</p><pre><code class="C++">#include &lt;iostream&gt;#include &lt;exception&gt;using namespace std;int main () &#123;    try    &#123;        throw &quot;error&quot;;    &#125;    catch(const char* msg)    &#123;        cout &lt;&lt; msg &lt;&lt; endl;    &#125;&#125; // error</code></pre><p>Another type is classes, which can be built-in standard exception classes or custom exception classes:</p><pre><code class="C++">#include &lt;iostream&gt;#include &lt;exception&gt;using namespace std;int main () &#123;    try    &#123;        throw exception();    &#125;    catch(std::exception&amp; e)    &#123;        cout &lt;&lt; e.what() &lt;&lt; endl;    &#125;&#125; // std::exception</code></pre><h3 id="Go"><a href="#Go" class="headerlink" title="Go"></a>Go</h3><p>Go, as a non-OOP language, does not support try-catch syntax but still has similar throw and catch features. Go has three error-related keywords: <code>panic()</code>, <code>recover()</code>, and <code>defer</code>. <code>panic()</code> throws an exception, <code>recover()</code> catches the exception, and the <code>defer</code> keyword defines what will be executed last, similar to <code>finally</code>:</p><pre><code class="Go">package mainimport &quot;fmt&quot;func main() &#123;  defer func() &#123;    err := recover()    fmt.Println(err)  &#125;()  panic(&quot;error&quot;)&#125;// error</code></pre><h3 id="Java"><a href="#Java" class="headerlink" title="Java"></a>Java</h3><p>Java, being a pure OOP language, only supports throwing and catching objects:</p><pre><code class="Java">public class ErrorTest &#123;    public static void main(String[] args) &#123;        try &#123;            throw new Exception();        &#125; catch (Exception e) &#123;            System.out.println(e);        &#125;    &#125;&#125;// java.lang.Exception</code></pre><h3 id="Scala"><a href="#Scala" class="headerlink" title="Scala"></a>Scala</h3><p>Scala and Java belong to the same category, supporting only throwing and catching objects. The syntax is slightly different from Java, but the concept is fundamentally the same:</p><pre><code class="Scala">object ErrorTest &#123;  def main(args: Array[String]): Unit = &#123;    try &#123;      throw new Exception()    &#125; catch &#123;      case e: Exception =&gt; print(e)    &#125;  &#125;&#125;// java.lang.Exception</code></pre><p>Moreover, Scala throws Java exceptions. Scala might not be considered an independent programming language but rather one that provides syntax sugar for Java. This point is worth deeper thinking and exploration.</p><h3 id="Kotlin"><a href="#Kotlin" class="headerlink" title="Kotlin"></a>Kotlin</h3><p>Kotlin is similar to Scala in nature, also throwing Java exceptions by default:</p><pre><code class="Kotlin">fun main(args: Array&lt;String&gt;) &#123;  try &#123;    throw Exception()  &#125; catch (e: Exception) &#123;    print(e)  &#125;&#125;// java.lang.Exception</code></pre><h3 id="Ruby"><a href="#Ruby" class="headerlink" title="Ruby"></a>Ruby</h3><p>Ruby uses the <code>raise</code> and <code>rescue</code> keywords instead of <code>try</code> and <code>catch</code> to implement throwing and catching exceptions. Ruby also supports the try-catch keywords, but they are not discussed here as I haven’t figured out their usage yet.</p><pre><code class="Ruby">begin  raise &quot;error&quot;   rescue Exception =&gt; e    puts eend// error</code></pre><h3 id="Rust"><a href="#Rust" class="headerlink" title="Rust"></a>Rust</h3><p>Rust does not have try-catch syntax or Go-like error handling functions. Instead, it uses <code>Option&lt;T&gt;</code> or the enhanced <code>Result&lt;T, E&gt;</code> for error handling. Rust’s pattern matching is similar to Scala’s:</p><pre><code class="Rust">fn main() &#123;  match find() &#123;    None =&gt; println!(&quot;none&quot;),    Some(i) =&gt; println!(&quot;&#123;&#125;&quot;, i),  &#125;&#125;fn find() -&gt; Option&lt;usize&gt; &#123;  if 1 == 1 &#123;    return Some(1);  &#125;  None&#125;// 1</code></pre><h3 id="JavaScript"><a href="#JavaScript" class="headerlink" title="JavaScript"></a>JavaScript</h3><p>Scripting languages do not enforce type constraints on variables, so exceptions cannot be distinguished by type. The content of the thrown error is relatively free:</p><pre><code class="JavaScript">try &#123;  throw 1&#125; catch (e) &#123;  console.log(e)&#125;// 1try &#123;  throw new Error(&#39;&#39;)&#125; catch (e) &#123;  console.log(e)&#125;// Error</code></pre><h3 id="PHP"><a href="#PHP" class="headerlink" title="PHP"></a>PHP</h3><p>PHP’s try-catch is similar to Java, with no special features:</p><pre><code class="PHP">&lt;?php  try &#123;      throw new Exception(&quot;error&quot;);  &#125; catch (Exception $e) &#123;      echo $e-&gt;getMessage();  &#125;</code></pre><h3 id="Python"><a href="#Python" class="headerlink" title="Python"></a>Python</h3><p>Python’s syntax shows the influence of Ruby. <code>raise</code> triggers an exception, and <code>except</code> catches it:</p><pre><code class="Python">try:  raiseexcept:  print(&quot;error&quot;)</code></pre><h3 id="Lisp"><a href="#Lisp" class="headerlink" title="Lisp"></a>Lisp</h3><p>Lisp is generally more complex. The content of Lisp’s exception handling is temporarily left as an open question. The following is one of the situations in Common Lisp that triggers an error. <code>declare</code> declares the type of function parameters, and passing the wrong parameters will cause an error:</p><pre><code class="Lisp">(defun df (a b)  (declare (double-float a b))  (* a b))  (df &quot;1&quot; 3)// *** - *: &quot;1&quot; is not a number</code></pre><h3 id="Future-Discussion"><a href="#Future-Discussion" class="headerlink" title="Future Discussion"></a>Future Discussion</h3><p>Initially, I wanted to sort out most of the concepts related to exceptions and error handling in these languages. However, I found it quite difficult and also failed to distinguish between “exception” and “checked exception,” leading to potential deviations in intention, title, and content. This time, I’ll just mention “exception,” and discuss “checked exception” in future content.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;When learning a programming language, it is important to start with its features rather than the language itself. Here, we attempt a</summary>
        
      
    
    
    
    
    <category term="Programming Languages" scheme="https://en.smallyu.net/tags/Programming-Languages/"/>
    
  </entry>
  
  <entry>
    <title>Design Flaws in Elevator Floor Display Screens</title>
    <link href="https://en.smallyu.net/2019/03/27/Design%20Flaws%20in%20Elevator%20Floor%20Display%20Screens/"/>
    <id>https://en.smallyu.net/2019/03/27/Design%20Flaws%20in%20Elevator%20Floor%20Display%20Screens/</id>
    <published>2019-03-27T14:29:49.000Z</published>
    <updated>2025-08-06T10:38:27.643Z</updated>
    
    <content type="html"><![CDATA[<p>Every time I take the elevator, I feel confused. There is an issue I’ve noticed for a long time.</p><h3 id="Elevator"><a href="#Elevator" class="headerlink" title="Elevator"></a>Elevator</h3><p>It’s not a big deal, but currently, the elevator in a certain building has this situation. When the elevator descends to the 1st floor, the floor display screen shows a downward arrow <code>↓</code>. When the elevator reaches the 1st floor and the door opens, the arrow still points downward. At this point, many people assume that the elevator is about to go down to the basement.</p><img src="f1.png" width="50%" height="50%"><p>This assumption is understandable because there’s another design flaw in the elevator. If someone is waiting for the elevator to go from the 10th floor to the 1st floor, and at the same time someone is riding the elevator from the 1st floor to the 20th floor, the elevator will stop and open the door on the 10th floor. Regardless of whether the person on the 10th floor gets on the elevator, it will continue to the 20th floor. The door opens on the 10th floor simply because the person who wants to go to the 1st floor pressed the elevator button.</p><img src="f10.png" width="50%" height="50%"><p>Due to this upward movement behavior of the elevator, it’s easy to infer that the elevator might behave similarly when going down. Seeing the arrow pointing down on the 1st floor, people might think the elevator is going to the basement, and because they pressed the button or someone just exited the elevator on this floor, the door opens. However, the truth is, the arrow merely retains the previous state of the elevator’s movement (downward), and whether it goes up or down next depends on which floor the first person to enter the elevator presses.</p><p>Not all elevators are like this. The correct approach should be that when the elevator has no tasks, the display screen should not show any arrows or display something like (–).</p><h3 id="Program"><a href="#Program" class="headerlink" title="Program"></a>Program</h3><p>When a task is completed (elevator operation ends), the task flag should be reset to its initial state (arrow cleared). This logic is very common in programming. Whether it’s UI or memory, users are not trustworthy, and neither is GC; manual recycling is the way to go. I encountered a pitfall today :(</p><p>The pitfall is simple and can be expressed in one sentence: executing an SQL statement in a loop without closing the Statement object.</p><p>Although the pitfall is simple, it affected normal business operations in the production environment. The default limit for DB2 is 1400- statements, after which errors occur. Be careful during development and pay attention to large data scenarios during self-testing. Hopefully, such errors won’t happen again in the future!</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Every time I take the elevator, I feel confused. There is an issue I’ve noticed for a long time.&lt;/p&gt;
&lt;h3 id=&quot;Elevator&quot;&gt;&lt;a</summary>
        
      
    
    
    
    
    <category term="Design" scheme="https://en.smallyu.net/tags/Design/"/>
    
  </entry>
  
  <entry>
    <title>Basic Syntax of Go Language</title>
    <link href="https://en.smallyu.net/2019/03/15/Basic%20Syntax%20of%20Go%20Language/"/>
    <id>https://en.smallyu.net/2019/03/15/Basic%20Syntax%20of%20Go%20Language/</id>
    <published>2019-03-15T13:18:11.000Z</published>
    <updated>2025-08-06T10:38:27.635Z</updated>
    
    <content type="html"><![CDATA[<p>Although Go language is not highly regarded in terms of language design by Wang Yin, its concise code structure is indeed captivating.</p><h3 id="Statements"><a href="#Statements" class="headerlink" title="Statements"></a>Statements</h3><p>Go language statements do not require a <code>;</code> at the end.</p><h3 id="Variables-and-Constants"><a href="#Variables-and-Constants" class="headerlink" title="Variables and Constants"></a>Variables and Constants</h3><p>Use <code>var</code> to declare variables. When variables need to be initialized, you can use the assignment symbol <code>:=</code> instead of <code>=</code> to omit the <code>var</code> keyword.</p><pre><code class="go">var a intvar b stringvar c int = 10var d = &quot;golang&quot;  // The compiler automatically infers the typed := 10</code></pre><p>Unlike C or Java, Go language’s type declaration is on the right side of the variable. Note that if declared variables in the program are not used, the program will not compile. Go is an engineering-oriented language, so some of its features might seem unreasonable but will improve efficiency in actual engineering.</p><p>Go’s variable assignment supports some cool writing styles, such as swapping the values of variables x and y using this counter-intuitive method:</p><pre><code class="go">x, y = y, x</code></pre><p>In Go, <code>const</code> is used to define constants. <code>true</code>, <code>false</code>, and <code>iota</code> are predefined constants. Among them, <code>iota</code> is a bit special. <code>iota</code> resets to 0 each time the <code>const</code> keyword appears, and before the next <code>const</code> appears, the value of <code>iota</code> increments by 1 each time it appears.</p><pre><code class="go">const a = iota   // 0const b = iota   // 0const (  c = iota       // 0  d = iota       // 1)</code></pre><h3 id="Arrays-and-Slices"><a href="#Arrays-and-Slices" class="headerlink" title="Arrays and Slices"></a>Arrays and Slices</h3><p>Declare an array of 3 elements and initialize it:</p><pre><code class="go">array := [3]int&#123;0, 1, 2&#125;array[0] = 3fmt.Println(array)</code></pre><p>Like other languages, Go cannot change the size of an array after declaration. Therefore, Go provides slices similar to Python. Slices can be created from arrays or using the <code>make()</code> function.</p><pre><code class="go">array := [3]int&#123;0, 1, 2&#125;slice1 := array[:2]       // Created from an arrayslice2 := make([]int, 3)  // Created directlyfmt.Println(slice1)       // [0 1]fmt.Println(slice2)       // [0 0 0]</code></pre><p>In addition to slices, maps are also created using the <code>make</code> function. The full type declaration of a map is <code>var myMap map[string]int</code>, meaning the variable <code>myMap</code> has a key of type <code>string</code> and a value of type <code>int</code>.</p><h3 id="Control-Flow"><a href="#Control-Flow" class="headerlink" title="Control Flow"></a>Control Flow</h3><p>Go allows <code>if-else</code> statements without parentheses around the condition, although adding them is also fine.</p><pre><code class="go">a := 1if a == 1 &#123;  print(1)&#125; else if (a == 2) &#123;  print(2)&#125; else &#123;  print(3)&#125;</code></pre><p><code>switch</code> statements do not require parentheses around the condition, nor do they require a <code>break</code>. Other matches will not execute, similar to Scala. Optimizing <code>switch</code> statements seems to be a common practice.</p><pre><code class="go">i := 0switch i &#123;case 0:  print(0)case 1:  print(1)&#125;</code></pre><p>Loop conditions also do not require parentheses. Go only supports <code>for</code> loops and has optimized for infinite loops, no longer requiring the <code>for(;;)</code> syntax.</p><pre><code class="go">for &#123;  print(1)&#125;</code></pre><h3 id="Functions"><a href="#Functions" class="headerlink" title="Functions"></a>Functions</h3><p>Go language originates from the C language faction, so from the beginning, Go is not an OOP or FP language and does not have the concept of classes or objects. Functions are first-class citizens in the program. Like in C, the <code>main</code> function (under the <code>main</code> package) is the entry point of the entire program.</p><pre><code class="go">func add(a int, b int) (int, int) &#123;  return a + b, a - b&#125;func main() &#123;  x, y := add(1, 2)  print(x, y)&#125;</code></pre><p>Go statements are concise and efficient, with the first parenthesis after the function name for parameters and the second for return values. Functions support multiple return values. If parameter types are the same, their type declarations can be combined, such as <code>(a, b int)</code>.</p><h3 id="Structs"><a href="#Structs" class="headerlink" title="Structs"></a>Structs</h3><p>Although Go does not have classes or objects, it does have powerful structs similar to those in C. Here, we define a <code>Person</code> struct with two properties <code>name</code> and <code>age</code>, and add a method <code>getInfo</code> to <code>Person</code> to output information about a <code>Person</code> object:</p><pre><code class="go">type Person struct &#123;  name string  age int&#125;func (p Person) getInfo() &#123;  print(p.name, p.age)&#125;func main() &#123;  smallyu := new(Person)  smallyu.name = &quot;smallyu&quot;  smallyu.age = 1  smallyu.getInfo()&#125;</code></pre><p>Understanding such a program with OOP thinking is not inappropriate. In addition to structs, Go also retains the concept of pointers. Java programmers might be a bit unfamiliar with pointers. Regarding the application of pointers in struct methods, a simple example can help understand:</p><pre><code class="go">type Person struct &#123;  name string&#125;func (p Person) setName() &#123;  p.name = &quot;set name&quot;&#125;func (p *Person) setName2() &#123;  p.name = &quot;set name&quot;&#125;func main() &#123;  smallyu := &amp;Person&#123;&quot;smallyu&quot;&#125;  smallyu.setName()  fmt.Println(smallyu)        // &amp;&#123;smallyu&#125;  bigyu := &amp;Person&#123;&quot;bigyu&quot;&#125;  bigyu.setName2()  fmt.Println(bigyu)          // &amp;&#123;set name&#125;&#125;</code></pre><p>Methods defined with value types have parameters as formal parameters; methods defined with reference types have parameters as actual parameters. <code>&amp;&#123;&#125;</code> is one way to initialize objects, equivalent to <code>new()</code>.</p><h3 id="Anonymous-Composition"><a href="#Anonymous-Composition" class="headerlink" title="Anonymous Composition"></a>Anonymous Composition</h3><p>The concept of anonymous composition in Go is equivalent to inheritance in OOP languages. A struct can inherit the properties and methods of another struct, roughly like this.</p><pre><code class="go">type Father struct &#123;  name string&#125;func (f Father) getName() &#123;  print(f.name)&#125;type Son struct &#123;  Father&#125;func main() &#123;  smallyu := &amp;Son&#123;&#125;  smallyu.name = &quot;smallyu&quot;  smallyu.getName()       // smallyu&#125;</code></pre><p><code>Son</code> does not define the <code>name</code> property or the <code>getName()</code> method; they are inherited from <code>Father</code>.</p><h3 id="Interfaces"><a href="#Interfaces" class="headerlink" title="Interfaces"></a>Interfaces</h3><p>Go’s interfaces are non-intrusive. As long as a struct implements all the methods in an interface, the program will consider the struct to have implemented that interface.</p><pre><code class="go">type IPerson interface &#123;  getName()&#125;type Person struct &#123;  name string&#125;func (p Person) getName() &#123;  print(p.name)&#125;func main() &#123;  var smallyu IPerson = &amp;Person&#123;&quot;smallyu&quot;&#125;  smallyu.getName()&#125;</code></pre><h3 id="Goroutines"><a href="#Goroutines" class="headerlink" title="Goroutines"></a>Goroutines</h3><p>The keyword for using goroutines is <code>go</code>. The naming itself reflects the importance of goroutines to Go. Goroutines are lightweight threads, and starting a goroutine is very simple:</p><pre><code class="go">func f(msg string) &#123;  println(msg)&#125;func main() &#123;  f(&quot;direct call&quot;)  go f(&quot;goroutine call&quot;)&#125;</code></pre><p>Running the program, you will find it only prints “direct call”. Does this seem familiar? <code>go</code> starts another “thread” to print the message, while the main thread has already ended. Adding <code>fmt.Scanln()</code> at the end of the program to prevent the main thread from ending will show all the print content.</p><h3 id="Channels"><a href="#Channels" class="headerlink" title="Channels"></a>Channels</h3><p>Channels are the means of communication between goroutines.</p><pre><code class="go">func main() &#123;  message := make(chan string)  go func() &#123;    message &lt;- &quot;ping&quot;  &#125;()  msg := &lt;-message  println(msg)&#125;</code></pre><p>The <code>make</code> function returns a <code>chan string</code> type channel. In the anonymous function, the string “ping” is sent into the channel, and then the data in the channel is output to the variable <code>msg</code>, finally printing the value of <code>msg</code> as “ping”.</p><h3 id="Error-Handling"><a href="#Error-Handling" class="headerlink" title="Error Handling"></a>Error Handling</h3><p>In Go, two functions are commonly used for error handling: the <code>panic</code> function and the <code>defer</code> function. The <code>panic</code> function prints an error message and terminates the entire program, similar to Java’s Throw Exception; the <code>defer</code> function will execute before the current context ends, similar to finally after try-catch; although the <code>panic</code> function terminates the entire program, it does not terminate the execution of the <code>defer</code> function, which can be used to print logs. Here is a simple example:</p><pre><code class="go">func main() &#123;  println(&quot;beginning&quot;)  defer func() &#123;    println(&quot;defer&quot;)  &#125; ()  println(&quot;middle&quot;)  panic(&quot;panic&quot;)  println(&quot;ending&quot;)&#125;</code></pre><p>Let’s analyze the program’s execution result. First, <code>beginning</code> is printed; then <code>defer</code> is encountered and not printed yet; <code>middle</code> is printed before <code>defer</code>; encountering <code>panic</code>, the program will terminate, printing <code>defer</code> and <code>panic</code>.</p><p>Note that <code>defer</code> is executed before the program ends, not</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Although Go language is not highly regarded in terms of language design by Wang Yin, its concise code structure is indeed</summary>
        
      
    
    
    
    
    <category term="Programming Language" scheme="https://en.smallyu.net/tags/Programming-Language/"/>
    
  </entry>
  
  <entry>
    <title>Basics of Scala Syntax</title>
    <link href="https://en.smallyu.net/2018/12/17/Basics%20of%20Scala%20Syntax/"/>
    <id>https://en.smallyu.net/2018/12/17/Basics%20of%20Scala%20Syntax/</id>
    <published>2018-12-17T03:06:03.000Z</published>
    <updated>2025-08-06T10:38:27.635Z</updated>
    
    <content type="html"><![CDATA[<p>The syntax of Scala is relatively complex. In the spirit of incremental software development, learning a programming language should start with finding an expressive way that one can master and then gradually build upon. Scala supports both object-oriented and functional programming, which is one reason for its complex syntax. Some tutorials are very comprehensive, but this comprehensiveness can make it difficult to distill the main points.</p><p>The following content focuses on the simplest basic syntax, hoping that based on this content, one can try to write object-oriented style Scala code.</p><h3 id="Statements"><a href="#Statements" class="headerlink" title="Statements"></a>Statements</h3><p>Scala allows statements to end without a <code>;</code>, similar to JavaScript.</p><h3 id="Variable-Definition"><a href="#Variable-Definition" class="headerlink" title="Variable Definition"></a>Variable Definition</h3><p><code>val</code> defines immutable variables (constants), <code>var</code> defines mutable variables:</p><pre><code class="Scala">val msg1 = &quot;Hello World&quot;var msg2 = &quot;Hello Wrold&quot;val msg3: String = &quot;Hello World&quot;</code></pre><p>When defining variables, type declarations are on the right side of the variable and are optional; they can be omitted as the compiler will automatically infer the type. Basic types in Scala include:</p><blockquote><p>Byte, Short, Int, Long, Char, String, Float, Double, Boolean</p></blockquote><h3 id="Function-Definition"><a href="#Function-Definition" class="headerlink" title="Function Definition"></a>Function Definition</h3><p>Functions are methods. Below is an example of defining a function:</p><pre><code class="Scala">def max(x: Int, y: Int): Int = &#123;  if (x &gt; y) &#123;    return x  &#125; else &#123;     return y  &#125;&#125;</code></pre><p>The significant differences from Java in method definitions are: first, using the <code>def</code> keyword to define functions; second, type declarations are on the right side of the variable; third, an <code>=</code> connects the function declaration and the function body.</p><p>Note that function parameters must have explicitly defined types; the compiler cannot automatically infer parameter types. The return type is optional unless the function uses recursion. Additionally, the <code>return</code> keyword is also optional; if there is no explicit return statement, the program will return the last computed result.</p><p>If the statement after <code>if</code> is a single statement, braces can be omitted. Therefore, the function can also be written like this:</p><pre><code class="Scala">def max2(x: Int, y: Int) = if (x &gt; y) x else y</code></pre><h3 id="Conditional-Structures"><a href="#Conditional-Structures" class="headerlink" title="Conditional Structures"></a>Conditional Structures</h3><p>The above example has already used an <code>if</code> statement. Scala’s <code>if</code> statement is not special, but compared to other languages, Scala uses pattern matching to replace the traditional <code>switch</code> structure:</p><pre><code class="Scala">val a = 1a match &#123;  case 1 =&gt; println(1)  case 2 =&gt; println(2)  case _ =&gt;&#125;</code></pre><p>The <code>_</code> wildcard matches all values and is used to capture the default case. In match expressions, cases never fall through to the next case, so no <code>break</code> or <code>return</code> is needed (if <code>_</code> is placed first, the program will not continue executing). However, be careful, if the program does not match any case, it will throw a <code>MatchError</code>.</p><h3 id="Loop-Structures"><a href="#Loop-Structures" class="headerlink" title="Loop Structures"></a>Loop Structures</h3><p>The <code>while</code> loop is not the recommended style of code in Scala:</p><pre><code class="Scala">var i = 0while (i &lt; 5) &#123;  println(i)  i += 1&#125;</code></pre><p>This is a typical <code>while</code> loop. Compared to imperative languages, Scala does not have the <code>++</code> operator; one must use statements like <code>i += 1</code>.</p><p>Mentioning <code>while</code> will inevitably bring up <code>for</code>. The <code>for</code> loop in Scala has some differences from imperative languages. In the following example, the program will print from 0 to 4:</p><pre><code class="Scala">for (i &lt;- 0 until 5) &#123;  println(i)&#125;</code></pre><p>Scala does not recommend <code>while</code> loops and prefers a functional programming style. The <code>foreach</code> method is one of them:</p><pre><code class="Scala">&quot;abc&quot;.foreach(c =&gt; println(c))</code></pre><p>The program will print the characters <code>a</code>, <code>b</code>, <code>c</code> each on a new line. If the function body has only one statement and one parameter, the code can be more concise:</p><pre><code class="Scala">&quot;abc&quot;.foreach(println)</code></pre><h3 id="Arrays"><a href="#Arrays" class="headerlink" title="Arrays"></a>Arrays</h3><p>Scala’s arrays are not implemented at the language level and can be used by instantiating the <code>Array</code> class. Correspondingly, array subscripts are represented using parentheses (i.e., method parameters):</p><pre><code class="Scala">val greet  = new Array greet(0) = &quot;a&quot;greet(1) = &quot;b&quot;greet(2) = &quot;c&quot;greet.foreach(println)</code></pre><p>When instantiating objects, default parameters can be directly passed. Array is indeed just a regular class; the following way of writing does not involve any black magic, it just uses a case class, which will be mentioned later.</p><pre><code class="Scala">val greet2 = Array(&quot;a&quot;, &quot;b&quot;, &quot;c&quot;)greet2.foreach(println)</code></pre><h3 id="Classes"><a href="#Classes" class="headerlink" title="Classes"></a>Classes</h3><p>Classes are defined using the <code>class</code> keyword, and classes contain fields and methods, i.e., typical object-oriented features. Unlike Python, Scala still supports access control:</p><pre><code class="Scala">class Accumulator &#123;  private var sum = 0  def add(b: Byte): Unit = &#123;    sum += b    println(sum)  &#125;&#125;</code></pre><h3 id="Singleton-Objects"><a href="#Singleton-Objects" class="headerlink" title="Singleton Objects"></a>Singleton Objects</h3><p>Singleton objects are equivalent to static classes in Java and are defined using the <code>object</code> keyword instead of <code>class</code>. Singleton objects are shared by the program and can be called directly. Singleton objects can serve as the entry point of the program by defining the <code>main</code> method within the singleton object. The following program instantiates an object <code>a</code> from the previously defined <code>Accumulator</code> class and calls its <code>add</code> method, ultimately printing <code>1</code>:</p><pre><code class="Scala">object Run &#123;  def main(args: Array[String]): Unit = &#123;    val a = new Accumulator    a.add(1)  &#125;&#125;</code></pre><p>In the same source file, when a singleton object and a class have the same name, the singleton object is called the companion object of the class, and the class is the companion class of the singleton object. A class can access the private properties and methods of its companion object.</p><h3 id="Constructors"><a href="#Constructors" class="headerlink" title="Constructors"></a>Constructors</h3><p>Scala’s rules for constructors are stricter than Java’s. Scala implements constructors through the concept of class parameters:</p><pre><code class="Scala">class Accumulator(a: Int, b: Int)</code></pre><p>If the class has no body, braces can be omitted. When instantiating this class, parameters need to be passed. In Java, overloaded constructors correspond to auxiliary constructors in Scala, which look like this:</p><pre><code class="Scala">class Accumulator(a: Int, b: Int) &#123;  def this(c: Int) = this(c, 1)&#125;</code></pre><p>This class now has two constructors:</p><pre><code class="Scala">val a1 = new Accumulator(1)val a2 = new Accumulator(1, 2)</code></pre><p>The strictness of Scala constructors lies in the fact that the second constructor can only leverage the first constructor or the superclass constructor.</p><h3 id="Inheritance-and-Overriding"><a href="#Inheritance-and-Overriding" class="headerlink" title="Inheritance and Overriding"></a>Inheritance and Overriding</h3><p>Scala’s inheritance is not significantly different from Java’s, except that method overriding must use the <code>override</code> keyword:</p><pre><code class="Scala">class A(a: Int) &#123;  def test = println(&quot;a&quot;)&#125;class B(b: Int) extends A(b) &#123;  override def test = println(&quot;b&quot;)&#125;</code></pre><h3 id="Traits"><a href="#Traits" class="headerlink" title="Traits"></a>Traits</h3><p>Traits are similar to singleton objects, except for the keyword used during definition. Traits, like regular classes, can contain fields and methods. The significance of traits lies in supporting mixins and allowing multiple traits to be mixed in. This feature is often compared with multiple inheritance.</p><pre><code class="Scala">trait A &#123;  def aMethod = println(&quot;A&quot;)&#125;trait B &#123;  def bMethod = println(&quot;B&quot;)&#125;class C extends A with B</code></pre><p>This way, an instance of <code>C</code> can call <code>aMethod</code> and <code>bMethod</code>:</p><pre><code class="Scala">val c = new Cc.aMethodc.bMethod</code></pre><h3 id="Case-Classes"><a href="#Case-Classes" class="headerlink" title="Case Classes"></a>Case Classes</h3><p>Case classes are defined by adding the <code>case</code> keyword before the <code>class</code>. This modifier allows the Scala compiler to automatically add some convenient settings to the class: 1. Instances can be created without the <code>new</code> keyword; 2. Parameters are automatically treated as class fields; 3. The class automatically has <code>toString</code>, <code>hashCode</code>, and <code>equals</code> methods:</p><pre><code class="Scala">case class A(a: Int) &#123;  def aMethod = println(a)&#125;object Run &#123;  def main(args: Array[String]): Unit = &#123;    val a = A(1)    a.aMethod     // 1    println(a)    // A(1)    println(a.a)  // 1  &#125;&#125;</code></pre><h3 id="Other"><a href="#Other" class="headerlink" title="Other"></a>Other</h3><p>Compared to Java, Scala supports abstract classes but not interfaces. Abstract classes are defined using <code>abstract</code>, and interfaces are replaced by traits. Scala also supports generics, annotations, and other syntax.</p><h3 id="Follow-Up"><a href="#Follow-Up" class="headerlink" title="Follow-Up"></a>Follow-Up</h3><p>The above content is not comprehensive and may not be sufficient. To use a programming language, in addition to mastering its basic syntax, one should also be familiar with its idiomatic usage, especially for multi-paradigm languages like Scala. This content will be continuously updated and improved, and other features of Scala will be discussed further.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;The syntax of Scala is relatively complex. In the spirit of incremental software development, learning a programming language should</summary>
        
      
    
    
    
    
    <category term="Programming Language" scheme="https://en.smallyu.net/tags/Programming-Language/"/>
    
  </entry>
  
  <entry>
    <title>Using Scala to Reimplement Java: A Shallow Practice</title>
    <link href="https://en.smallyu.net/2018/12/14/Using%20Scala%20to%20Reimplement%20Java:%20A%20Shallow%20Practice/"/>
    <id>https://en.smallyu.net/2018/12/14/Using%20Scala%20to%20Reimplement%20Java:%20A%20Shallow%20Practice/</id>
    <published>2018-12-14T04:36:36.000Z</published>
    <updated>2025-08-06T10:38:28.717Z</updated>
    
    <content type="html"><![CDATA[<h3 id="Origin"><a href="#Origin" class="headerlink" title="Origin"></a>Origin</h3><p>I wanted to implement a Markdown parser using Java, and I have currently completed the parsing of multi-level headings. Essentially, it involves using regular expressions to match and replace the corresponding content. The program is relatively simple at this stage, and the main process is as follows:</p><p><img src="/mainProcess.png" alt="main process"></p><h3 id="Reimplementation"><a href="#Reimplementation" class="headerlink" title="Reimplementation"></a>Reimplementation</h3><p>Following the same process, I used Scala to implement this functionality, and I will continue to develop it using Scala. First, let’s read the file content. For IO operations, I referred to the “Scala Cookbook,” and it can be done in a single line of code:</p><pre><code class="scala">var srcLines = Source.fromFile(srcFile).getLines().toList</code></pre><p>Compared to verbose Java, Scala is indeed more concise. This is the method I previously used to read files in Java:</p><pre><code class="java">/**  * Read file content  *  * @param src File path to read  * @return File content  */private static String readFile(String src) throws IOException &#123;    StringBuffer content = new StringBuffer();    InputStream is = null;    BufferedReader reader = null;    is = new FileInputStream(src);    reader = new BufferedReader(new InputStreamReader(is));    String line = reader.readLine();    while (line != null) &#123;        content.append(line);        content.append(&quot;\n&quot;);        line = reader.readLine();    &#125;    if (reader != null) &#123;        reader.close();    &#125;    if (is != null) &#123;        is.close();    &#125;    return content.toString();&#125;</code></pre><p>The reason for converting the string to list operations in the Scala version is that there are differences between Scala and Java in using regex matching and replacement APIs. Java uses the Matcher object for iteration, which has methods for finding and replacing:</p><p><img src="/replaceProcess.png" alt="replace process"></p><p>In contrast, Scala’s Regex object has methods like findAllMatchIn and replaceAllIn, but the find method’s object is only for searching, and the replace method cannot locate the matched content. Therefore, in Scala, the file is read into a list, and the text content is traversed with indexes as follows:</p><pre><code class="scala">List.range(0, srcLines.size).foreach(index =&gt; &#123;  srcLines = srcLines.updated(index, regexReplace)&#125;)</code></pre><p>Whether or not there are matches, the loop performs an updated operation on the list, updating the original content to the content after regex replacement. This approach may be slightly inadequate, and I will continue to monitor and rectify performance issues. It can be seen that the programming philosophy of Scala differs somewhat from the typical OOP in Java.</p><p>Finally, regarding file writing, the SDK does not provide a specialized operation object, so you can use the PrintWriter from JDK:</p><pre><code class="scala">val pw = new PrintWriter(new File(outFile))pw.write(outString)pw.close()</code></pre><h3 id="Future-Work"><a href="#Future-Work" class="headerlink" title="Future Work"></a>Future Work</h3><p>“Scala is a language that grows with developers,” and I will use it to complete my graduation project.</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;h3 id=&quot;Origin&quot;&gt;&lt;a href=&quot;#Origin&quot; class=&quot;headerlink&quot; title=&quot;Origin&quot;&gt;&lt;/a&gt;Origin&lt;/h3&gt;&lt;p&gt;I wanted to implement a Markdown parser using Java,</summary>
        
      
    
    
    
    
    <category term="Programming Languages" scheme="https://en.smallyu.net/tags/Programming-Languages/"/>
    
  </entry>
  
  <entry>
    <title>Getting One Piece Update Information with Python</title>
    <link href="https://en.smallyu.net/2018/12/02/Getting%20One%20Piece%20Update%20Information%20with%20Python/"/>
    <id>https://en.smallyu.net/2018/12/02/Getting%20One%20Piece%20Update%20Information%20with%20Python/</id>
    <published>2018-12-02T10:08:00.000Z</published>
    <updated>2025-08-06T10:38:27.655Z</updated>
    
    <content type="html"><![CDATA[<p>December 2nd, sunny, One Piece is on hiatus.</p><h3 id="Problem"><a href="#Problem" class="headerlink" title="Problem"></a>Problem</h3><p>As a dedicated otaku, I must watch One Piece and Fairy Tail every week. Both of these anime are available on iQIYI and are VIP content. Every weekend, I look for anime resources on YouTube or other websites. The problem is that these resource websites are often not updated in a timely manner, and I frequently need to Google “anime name + latest episode number,” such as “One Piece 864.”</p><p>Remembering the exact latest episode number of an anime each week is not something a normal otaku would do, especially for two series. This means that every time before searching for resources, I need to go to iQIYI, search for One Piece, see the latest episode number, close the page, and then go to Google to search. The same steps are needed for Fairy Tail.</p><p>Moreover, seeing the latest episode number on iQIYI does not tell me if the show is on hiatus. I still need to find the “update time” tag on the complicated PC page to check the update status. As for the mobile page or app, there is no way to check the update status.</p><p>Another way to get the latest episode number is to search the anime name directly on Baidu, which shows the latest episodes in reverse order on the homepage (Baidu is better than Google in this regard), but it still does not indicate whether the updates are normal. Furthermore, my browser defaults to Google, so searching on Baidu requires typing “baidu,” pressing TAB to switch to the Baidu search engine, entering the search content, and hitting enter. This process is equally cumbersome.</p><h3 id="Solution"><a href="#Solution" class="headerlink" title="Solution"></a>Solution</h3><p>Write a simple Python script to fetch information from the iQIYI page so I can directly access the program to know the anime update status. First, import the necessary packages:</p><pre><code class="python">import urllib.requestfrom bs4 import BeautifulSoupfrom wsgiref.simple_server import make_server# One Piece page URLurl = &quot;http://www.iqiyi.com/a_19rrhb3xvl.html?vfm=2008_aldbd&quot;</code></pre><p><code>urllib</code> is used to send HTTP requests and receive page data; <code>bs4</code> (BeautifulSoup) is used to parse the page and easily retrieve content; <code>wsgiref</code> is used to set up an HTTP server to provide web services. The URL is a global variable storing the link to the One Piece page.</p><pre><code class="python"># Get data from the pagedef reciveData(url):    # Fetch page content    response = urllib.request.urlopen(url)    html = response.read()    # Parser    soup = BeautifulSoup(html, &quot;html.parser&quot;, from_encoding=&quot;utf-8&quot;)    # Update time    p = soup.find(&#39;p&#39;, class_=&quot;episodeIntro-update&quot;)    # Latest episode number    i = soup.find(&#39;i&#39;, class_=&quot;title-update-num&quot;)    return p, i</code></pre><p>These lines of code send a request and retrieve information from the page. Here, the update time and the latest episode number are obtained. Next, create an HTTP server to output the content to the page:</p><pre><code class="python"># Server environment handler functiondef application(environ, start_response):    # Get data    p, i = reciveData(url)    # Construct the page content    start_response(&#39;200 OK&#39;, [(&#39;Content-Type&#39;, &#39;text/html&#39;)])    content = (&#39;&lt;h3&gt;One Piece&lt;/h3&gt;&#39;               + &#39;msg: &#39; + p.contents[2].get_text().strip()                + &#39;&lt;br&gt;&#39;               + &#39;num: &#39; + i.get_text())    return [bytes(content, encoding=&quot;utf-8&quot;)]</code></pre><p>Finally, start a local server, and visit port 8010 to see the page. You can deploy the program to a server and then directly access it:</p><pre><code class="python"># Start the serverhttpd = make_server(&#39;&#39;, 8010, application) httpd.serve_forever()</code></pre><p>The result is shown as follows:</p><img src="preview.png" width="30%"><h3 id="Expansion"><a href="#Expansion" class="headerlink" title="Expansion"></a>Expansion</h3><p>Based on this idea, the program can be expanded. One approach is to get comprehensive anime update information from various websites and provide the service proactively; another is to offer customized anime update information based on user input; or combine both to offer a comprehensive, bookmarkable, and customizable service. Although this idea is somewhat pointless.</p><h3 id="Correction"><a href="#Correction" class="headerlink" title="Correction"></a>Correction</h3><p>There was a simple mistake in the previous code. The program only makes a network request the first time it runs, and since the web service remains running, the returned page content is always the initial data. Solving this problem is easy: encapsulate the network request operation in a function and call that function in the application function. (The code has been corrected. To keep it concise, the Fairy Tail part of the code and console log output have been removed.)</p>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;December 2nd, sunny, One Piece is on hiatus.&lt;/p&gt;
&lt;h3 id=&quot;Problem&quot;&gt;&lt;a href=&quot;#Problem&quot; class=&quot;headerlink&quot;</summary>
        
      
    
    
    
    
    <category term="Programming Language" scheme="https://en.smallyu.net/tags/Programming-Language/"/>
    
  </entry>
  
  <entry>
    <title>PHP 7, Making Code More Elegant (Translation)</title>
    <link href="https://en.smallyu.net/2018/11/01/PHP%207,%20Making%20Code%20More%20Elegant%20(Translation)/"/>
    <id>https://en.smallyu.net/2018/11/01/PHP%207,%20Making%20Code%20More%20Elegant%20(Translation)/</id>
    <published>2018-11-01T14:19:31.000Z</published>
    <updated>2025-08-06T10:38:27.726Z</updated>
    
    <content type="html"><![CDATA[<p>PHP 7 has been released for a long time, and it can make code more concise. Let’s take a look at its features.</p><h3 id="Scalar-Type-Declarations"><a href="#Scalar-Type-Declarations" class="headerlink" title="Scalar Type Declarations"></a>Scalar Type Declarations</h3><p>Scalars refer to string, int, float, and bool. Before PHP 7, to validate a function’s parameter types, you needed to manually check and throw exceptions:</p><pre><code class="php">&lt;?phpfunction add($num1, $num2) &#123;    if (!is_int($num1)) &#123;        throw new Exception(&quot;$num1 is not an integer&quot;);    &#125;    if (!is_int($num2)) &#123;        throw new Exception(&quot;$num2 is not an integer&quot;);    &#125;    return ($num1 + $num2);&#125;echo add(2, 4);     // 6echo add(1.5, 4);   // Fatal error: Uncaught Exception</code></pre><p>Now, you can directly declare the parameter types:</p><pre><code class="php">&lt;?phpfunction add(int $num1, int $num2) &#123;    return ($num1 + $num2);&#125;echo add(2, 4);     // 6echo add(&quot;2&quot;, 4);   // 6echo add(&quot;something&quot;, 4);   // Fatal error: Uncaught TypeError</code></pre><p>Since PHP runs in coercive mode by default, “2” is successfully parsed as 2. You can enable strict mode using the declare function:</p><pre><code class="php">&lt;?phpdeclare(strict_types=1);function add(int $num1, int $num2) &#123;    return ($num1 + $num2);&#125;echo add(2, 4);     // 6echo add(&quot;2&quot;, 4);   // Fatal error: Uncaught TypeError</code></pre><h3 id="Return-Type-Declarations"><a href="#Return-Type-Declarations" class="headerlink" title="Return Type Declarations"></a>Return Type Declarations</h3><p>Just like parameters, return values can now have specified types:</p><pre><code class="php">&lt;?phpfunction add($num1, $num2): int &#123;    return ($num1 + $num2);&#125;echo add(2, 4);     // 6echo add(2.5, 4);   // 6</code></pre><p>2.5 + 4 returns the int type 6, which is implicit type conversion. To avoid implicit conversion, you can use strict mode to throw exceptions:</p><pre><code class="php">&lt;?phpdeclare(strict_types=1);function add($num1, $num2): int &#123;    return ($num1 + $num2);&#125;echo add(2, 4); // 6echo add(2.5, 4); // Fatal error: Uncaught TypeError</code></pre><h3 id="Null-Coalescing-Operator"><a href="#Null-Coalescing-Operator" class="headerlink" title="Null Coalescing Operator"></a>Null Coalescing Operator</h3><p>In PHP 5, to check a variable and assign a default value if it’s not defined, you needed lengthy code:</p><pre><code class="php">$username = isset($_GET[&#39;username&#39;]) ? $_GET[&#39;username&#39;] : &#39;&#39;;</code></pre><p>In PHP 7, you can use the new “??” operator:</p><pre><code class="php">$username = $_GET[&#39;username&#39;] ?? &#39;&#39;;</code></pre><p>This is just syntactic sugar but it makes our code much simpler.</p><h3 id="Spaceship-Operator"><a href="#Spaceship-Operator" class="headerlink" title="Spaceship Operator"></a>Spaceship Operator</h3><p>Also called the combined comparison operator, it compares two expressions. It returns -1, 0, or 1 when $a is less than, equal to, or greater than $b, respectively.</p><pre><code class="php">echo 1 &lt;=&gt; 1;   // 0echo 1 &lt;=&gt; 2;   // -1echo 2 &lt;=&gt; 1;   // 1</code></pre><h3 id="Grouped-Namespace-Declarations"><a href="#Grouped-Namespace-Declarations" class="headerlink" title="Grouped Namespace Declarations"></a>Grouped Namespace Declarations</h3><p>Classes, functions, and constants within the same namespace can now be imported using a single use expression:</p><pre><code class="php">&lt;?php// Before PHP 7use net\smallyu\ClassA;use net\smallyu\ClassB;use net\smallyu\ClassC as C;use function net\smallyu\funA;use function net\smallyu\funB;use function net\smallyu\funC;use const net\smallyu\ConstA;use const net\smallyu\ConstB;use const net\smallyu\ConstC;// PHP 7use net\smallyu\&#123;ClassA, ClassB, ClassC&#125;;use function net\smallyu\&#123;funA, funB, funC&#125;;use const net\smallyu\&#123;ConstA, ConstB, ConstC&#125;;</code></pre><h3 id="Generator-Features"><a href="#Generator-Features" class="headerlink" title="Generator Features"></a>Generator Features</h3><p>Generators in PHP have the same form as regular functions. Generators are used in foreach iterations and are more memory-efficient than arrays. Here is an example of a generator:</p><pre><code class="php">&lt;?php// Returns a generatorfunction getValues($max) &#123;    for ($i = 0; $i &lt; $max; $i++) &#123;        yield $i * 2;    &#125;&#125;// Using the generatorforeach(getValues(99999) as $value) &#123;    echo &quot;Values: $value \n&quot;;&#125;</code></pre><p>In the code, the yield expression appears, which acts like return, returning a value from the function once and resuming from where it left off.</p><p>Before PHP 7, generators couldn’t use return to return a value. Now, they can, and return doesn’t affect yield’s normal iteration. The return value can also be retrieved using $gen-&gt;getReturn():</p><pre><code class="php">&lt;?php$gen = (function() &#123;    yield &quot;First Yield&quot;;    yield &quot;Second Yield&quot;;    return &quot;return Value&quot;;&#125;)();foreach ($gen as $val) &#123;    echo $val, PHP_EOL;&#125;echo $gen-&gt;getReturn();</code></pre><p>PHP 7 also supports generator delegation, allowing one generator to call another generator:</p><pre><code class="php">&lt;?phpfunction gen() &#123;    yield &quot;yield 1 from gen1&quot;;    yield &quot;yield 2 from gen1&quot;;    yield from gen2();&#125;function gen2() &#123;    yield &quot;yield 3 from gen2&quot;;    yield &quot;yield 4 from gen2&quot;;&#125;foreach (gen() as $val) &#123;    echo $val, PHP_EOL;&#125;</code></pre><h3 id="Anonymous-Classes"><a href="#Anonymous-Classes" class="headerlink" title="Anonymous Classes"></a>Anonymous Classes</h3><p>PHP 7 also introduces anonymous classes.</p><h3 id="Closures"><a href="#Closures" class="headerlink" title="Closures"></a>Closures</h3><p>PHP 7 offers better support for closures:</p><pre><code class="php">&lt;?phpclass A &#123; private $x = 1; &#125;// Before PHP 7$getAFun = function() &#123; return $this-&gt;x; &#125;;$getA = $getAFun-&gt;bindTo(new A, &#39;A&#39;); // Intermediate closureecho $getA();// PHP 7 and later$getA = function() &#123; return $this-&gt;x; &#125;;echo $getA-&gt;call(new A);</code></pre><h3 id="Nullable-Types"><a href="#Nullable-Types" class="headerlink" title="Nullable Types"></a>Nullable Types</h3><p>Nullable types are one of the new features in PHP 7.1. By adding a question mark before a type declaration, the parameter can be of the specified type or NULL. This can be used for return types:</p><pre><code class="php">&lt;?phpfunction testReturn(): ?string &#123;    return &#39;testing&#39;;&#125;var_dump(testReturn());     // string(7) &quot;testing&quot;function testReturn2(): ?string &#123;    return null;&#125;var_dump(testReturn2());    // NULL</code></pre><p>It can also be used for parameter types:</p><pre><code class="php">&lt;?phpfunction test(?string $name) &#123;    var_dump($name);&#125;test(&#39;testing&#39;);    // string(7) &quot;testing&quot;test(null);         // NULLtest();     // Fatal error: Uncaught ArgumentCountError</code></pre><h3 id="Array-Destructuring"><a href="#Array-Destructuring" class="headerlink" title="Array Destructuring"></a>Array Destructuring</h3><p>Simplified list() syntax:</p><pre><code class="php">&lt;?php$records = [    [1, &#39;smallyu&#39;],    [2, &#39;bigyu&#39;],];// list() stylelist($firstId, $firstName) = $records[0];// [] style, PHP 7.1[$firstId, $firstName] = $records[0];var_dump($firstId);     // int(1)var_dump($firstName);   // string(7) &quot;smallyu&quot;</code></pre><p>Another new feature is that both list() and [] now support keys:</p><pre><code class="php">&lt;?php$records = [    [&quot;id&quot; =&gt; 1, &quot;name&quot; =&gt; &#39;smallyu&#39;],    [&quot;id&quot; =&gt; 2, &quot;name&quot; =&gt; &#39;bigyu&#39;],];// list() stylelist(&quot;id&quot; =&gt; $firstId, &quot;name&quot; =&gt; $firstName) = $records[0];// [] style, PHP 7.1[&quot;id&quot; =&gt; $firstId, &quot;name&quot; =&gt; $firstName] = $records[0];var_dump($firstId);     // int(1)var_dump($firstName);   // string(7) &quot;smallyu&quot;</code></pre><h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><ul><li><p>“Building RESTful Web Services with PHP 7” Chapter 2: PHP 7, To Code It Better</p></li><li><p><a href="http://php.net/manual/en/migration70.new-features.php">PHP: New Features - Manual</a></p></li></ul>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;PHP 7 has been released for a long time, and it can make code more concise. Let’s take a look at its features.&lt;/p&gt;
&lt;h3</summary>
        
      
    
    
    
    
    <category term="Programming Languages" scheme="https://en.smallyu.net/tags/Programming-Languages/"/>
    
  </entry>
  
  <entry>
    <title>Java 11 Tutorial (Translation)</title>
    <link href="https://en.smallyu.net/2018/10/31/Java%2011%20Tutorial%20(Translation)/"/>
    <id>https://en.smallyu.net/2018/10/31/Java%2011%20Tutorial%20(Translation)/</id>
    <published>2018-10-31T02:20:56.000Z</published>
    <updated>2025-08-06T10:38:27.717Z</updated>
    
    <content type="html"><![CDATA[<p>Java 11 has been released, and many people are still using Java 8. This tutorial covers some important language features and APIs.</p><h3 id="Local-Variable-Type-Inference"><a href="#Local-Variable-Type-Inference" class="headerlink" title="Local Variable Type Inference"></a>Local Variable Type Inference</h3><p>Local variables are those declared within the method body. Java 10 introduced a new keyword <code>var</code> to replace type declarations when declaring local variables.</p><p>Before Java 10, you had to declare a variable like this:</p><pre><code class="java">String text = &quot;Hello Java 9&quot;;</code></pre><p>Now you can use <code>var</code> instead of <code>String</code>. The compiler will automatically infer the correct type from the variable’s assignment. For instance, the type of <code>text</code> is inferred as <code>String</code>:</p><pre><code class="java">var text = &quot;Hello Java 10&quot;;</code></pre><p>Variables declared with <code>var</code> are still static and cannot be assigned a different type after declaration:</p><pre><code class="java">var text = &quot;Hello Java11&quot;;text = 23;  // Compilation error: incompatible types</code></pre><p>You can also use <code>final</code> to declare constants:</p><pre><code class="java">final var text = &quot;Banana&quot;;text = &quot;Joe&quot;;   // Compilation error</code></pre><p>However, <code>var</code> cannot be used when the compiler cannot infer the type, such as in these cases:</p><pre><code class="java">var a;var nothing = null;var lambda = () -&gt; System.out.println(&quot;Pity!&quot;);var method = this::someMethod;</code></pre><p>When variable declarations involve generics, <code>var</code> proves particularly advantageous. The following example uses <code>var</code> to replace the verbose <code>Map&lt;String, List&lt;Integer&gt;&gt;</code>:</p><pre><code class="java">var myList = new ArrayList&lt;Map&lt;String, List&lt;Integer&gt;&gt;&gt;();for (var current : myList) &#123;    // The type of &#39;current&#39; is inferred as Map&lt;String, List&lt;Integer&gt;&gt;    System.out.println(current);&#125;</code></pre><p>The <code>var</code> keyword in Java 11 also supports use in lambda expression parameters, and you can add annotations to these parameters:</p><pre><code class="java">Predicate&lt;String&gt; predicate = (@Nullable var a) -&gt; true;</code></pre><blockquote><p>Tip: In Intellij IDEA, hold down the CTRL key to see the inferred type of a variable.</p></blockquote><h2 id="HTTP-Client"><a href="#HTTP-Client" class="headerlink" title="HTTP Client"></a>HTTP Client</h2><p>Java 9 introduced a new API, HttpClient, for handling HTTP requests experimentally. Now, Java 11 standardizes it, and it can be accessed from the <code>java.net</code> module.</p><p>The new HttpClient can be used in both synchronous and asynchronous scenarios. Synchronous requests block the thread until a response is received. BodyHandlers define the type of response data (e.g., <code>String</code>, <code>Byte[]</code>, <code>File</code>).</p><pre><code class="java">var request = HttpRequest.newBuilder()        .uri(URI.create(&quot;https://blog.smallyu.net&quot;))        .GET()        .build();var client = HttpClient.newHttpClient();var response = client.send(request, HttpResponse.BodyHandlers.ofString());System.out.println(response.body());// Remember to import the java.net.http module in module-info.java</code></pre><p>You can also make asynchronous requests. Calling <code>sendAsync</code> will not block the current thread; it constructs an asynchronous operation chain and executes the corresponding action upon receiving a response:</p><pre><code class="java">var request = HttpRequest.newBuilder()        .uri(URI.create(&quot;https://blog.smallyu.net&quot;))        .build();var client = HttpClient.newHttpClient();client.sendAsync(request, HttpResponse.BodyHandlers.ofString())        .thenApply(HttpResponse::body)        .thenAccept(System.out::println);// Sleep the thread to prevent it from ending before receiving the responseThread.sleep(3000);</code></pre><blockquote><p>The <code>.GET()</code> method is the default request method.</p></blockquote><p>The next example demonstrates how to send a request using the POST method to a specified URL. Similar to <code>BodyHandlers</code>, <code>BodyPublishers</code> defines the type of data to be sent:</p><pre><code class="java">var request = HttpRequest.newBuilder()        .uri(URI.create(&quot;https://postman-echo.com/post&quot;))        .header(&quot;Content-Type&quot;, &quot;text/plain&quot;)        .POST(HttpRequest.BodyPublishers.ofString(&quot;Hi there!&quot;))        .build();var client = HttpClient.newHttpClient();var response = client.send(request, HttpResponse.BodyHandlers.ofString());System.out.println(response.statusCode());      // 200</code></pre><p>The last example shows how to perform authentication using BASIC-AUTH:</p><pre><code class="java">var request = HttpRequest.newBuilder()    .uri(URI.create(&quot;https://postman-echo.com/basic-auth&quot;))    .build();var client = HttpClient.newBuilder()    .authenticator(new Authenticator() &#123;        @Override        protected PasswordAuthentication getPasswordAuthentication() &#123;            return new PasswordAuthentication(&quot;postman&quot;, &quot;password&quot;.toCharArray());        &#125;    &#125;)    .build();var response = client.send(request, HttpResponse.BodyHandlers.ofString());System.out.println(response.statusCode());      // 200</code></pre><h3 id="Collections-Framework"><a href="#Collections-Framework" class="headerlink" title="Collections Framework"></a>Collections Framework</h3><p>Collections frameworks like List, Set, and Map have new methods added. <code>List.of</code> creates an immutable list from the given parameters, and <code>List.copyOf</code> creates a copy of an existing list.</p><pre><code class="java">var list = List.of(&quot;A&quot;, &quot;B&quot;, &quot;C&quot;);var copy = List.copyOf(list);System.out.println(list == copy);   // true</code></pre><p>Since the list is immutable, the copied list and the original list are the same instance. If a mutable list is copied, the copied list will be a new instance without affecting the original list:</p><pre><code class="java">var list = new ArrayList&lt;String&gt;();var copy = List.copyOf(list);System.out.println(list == copy);   // false</code></pre><p>To create an immutable map, simply alternate the keys and values as parameters:</p><pre><code class="java">var map = Map.of(&quot;A&quot;, 1, &quot;B&quot;, 2);System.out.println(map);    // &#123;B=2, A=1&#125;</code></pre><blockquote><p>The immutable lists in Java 11 use the same interface as lists in older versions, but modifying an immutable list (e.g., adding or removing elements) will throw a <code>java.lang.UnsupportedOperationException</code>. Fortunately, when you try to modify an immutable list, Intellij IDEA will check and warn you.</p></blockquote><h3 id="Streams"><a href="#Streams" class="headerlink" title="Streams"></a>Streams</h3><p>Streams, introduced in Java 8, now have three new methods. <code>Stream.ofNullable</code> creates a stream from a single element:</p><pre><code class="java">Stream.ofNullable(null)    .count()   // 0</code></pre><p><code>dropWhile</code> and <code>takeWhile</code> methods are used to discard some elements in the stream:</p><pre><code class="java">Stream.of(1, 2, 3, 2, 1)    .dropWhile(n -&gt; n &lt; 3)    .collect(Collectors.toList());  // [3, 2, 1]Stream.of(1, 2, 3, 2, 1)    .takeWhile(n -&gt; n &lt; 3)    .collect(Collectors.toList());  // [1, 2]</code></pre><h3 id="Strings"><a href="#Strings" class="headerlink" title="Strings"></a>Strings</h3><p>The <code>String</code> class also has several new methods:</p><pre><code class="java">&quot; &quot;.isBlank();                // true&quot; Foo Bar &quot;.strip();          // &quot;Foo Bar&quot;&quot; Foo Bar &quot;.stripTrailing();  // &quot; Foo Bar&quot;&quot; Foo Bar &quot;.stripLeading();   // &quot;Foo Bar &quot;&quot;Java&quot;.repeat(3);             // &quot;JavaJavaJava&quot;&quot;A\nB\nC&quot;.lines().count();    // 3</code></pre><h3 id="Other-JVM-Features"><a href="#Other-JVM-Features" class="headerlink" title="Other JVM Features"></a>Other JVM Features</h3><p>Java 11 includes many new features; the above are just the tip of the iceberg. There is much more to explore…</p><h3 id="References"><a href="#References" class="headerlink" title="References"></a>References</h3><ul><li><a href="https://winterbe.com/posts/2018/09/24/java-11-tutorial/">Java 11 Tutorial</a></li></ul>]]></content>
    
    
      
      
        
        
    <summary type="html">&lt;p&gt;Java 11 has been released, and many people are still using Java 8. This tutorial covers some important language features and</summary>
        
      
    
    
    
    
    <category term="Programming Language" scheme="https://en.smallyu.net/tags/Programming-Language/"/>
    
  </entry>
  
</feed>
